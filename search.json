[{"title":"使用Hexo+Next搭建个人博客","url":"/2022/03/17/093375c998745d381f00dcaac184ef81/","content":"分享一下个人博客搭建，本人是有一个个人的私有仓库，然后呢私有仓库内有些感觉写的可以文章会分享到自己的博客上，但是用Hexo+Next主题吧，发现哇使用起来比较麻烦，还需要copy来copy去的，所以自己写了一些脚本方便使用和操作！主要是为了傻瓜式的使用！同时帮助换个工作电脑可能就跑不起来了，所以写一篇文章记录下！同时本文也会分享一些Hexo的插件，比如支持流程图和UML，以及一些优化，比如使用gulp压缩代码！\n\n\n1. 环境\n环境： Linux or Mac （后期会增加Windows环境，主要是不会写windows的脚本！）\n创建一个账号：GitHub 个人账号，例如我的个人账号是 Anthony-Dong\n创建一个仓库：GitHub仓库，例如我的仓库名是 anthony-dong.github.io，格式就是&#123;个人账号名称&#125;.github.io，注意都要小写，仓库地址 https://github.com/Anthony-Dong/anthony-dong.github.io\n下载我的博客模版到本地，项目地址: https://github.com/Anthony-Dong/blog_template\n\nwget https://github.com/Anthony-Dong/blog_template/archive/refs/heads/master.zipunzip master.zip\n\n\n启动项目\n\n\n配置参数( 如果你本地有docker且已经启动起来了，直接 make init run 起来了，下面可以不看了！)\n\n\n如果你的环境依赖本地都有，只需要把 EXEC_TYPE := docker 改成 EXEC_TYPE := 即可\n\n注意: 如果你用环境依赖指的是 node+hexo环境，需要注意的是你需要安装 node.js 16.3 版本 + hexo 4.3.0 版本，可以参考下面的安装方式！\n\n# 安装 node.js，如果你是mac环境完全可以下面这样安装brew install node@16# 其他环境，需要下载 https://nodejs.org/dist/v16.3.0/ 源码进行安装！# 安装 hexo, 这里配置taobao的源，比较快！npm config set registry https://registry.npm.taobao.orgnpm install hexo-cli@4.3.0 -g# 安装gulp 压缩html/js/cssnpm install gulp-cli -g  # cli-version: 2.3.0, local-version: 4.0.2\n\n\n初始化环境: 执行 make init run 即可！\n具体帮助命令\n\n➜  note-master git:(master) ✗ make push                  push项目到远程 create                创建博客文件的头部信息 init                  初始化整个项目[第一次执行会比较慢] build                 重新构建网站 run                   启动网站 deploy                发布到个人网站 help                  帮助\n\n2. 快速修改配置\n修改配置文件hexo-home/_config.yml ， 只需要修改我下面标注的！\n\n# Sitetitle: 技术小白  # 网站标题subtitle: &#x27;技术小白的技术博客&#x27; # 网站介绍keywords: # 网站关键词  - Hexo  - Node.js  - Flinkdescription: &#x27;每天进步一点点!&#x27; # 个性签名author: xiao-bai # 作者名称# URL## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;url: https://xiao-bai.github.io/ # 你的博客地址，一般你部署在github的话## Docs: https://hexo.io/docs/one-command-deploymentdeploy:  type: git  repo: git@github.com:xiao-bai/xiao-bai.github.io.git # 你仓库的地址  branch: master\n\n\n修改配置文件 hexo-home/themes/next/_config.yml , 简单使用只需要替换以下的配置文件，高级使用请看官方文档: https://github.com/iissnan/hexo-theme-next\n\n# 下面的联系地址可以改成你的！你也可以根据配置文件添加social:  GitHub: https://github.com/anthony-dong || fab fa-github  E-Mail: mailto:fanhaodong516@gmail.com || fa fa-envelope  掘金: https://juejin.cn/user/4248168663101320 || fas fa-book  国内邮箱: mailto:fanhaodong516@163.com || fa fa-envelope  # 这个替换成的话术就行了，不需要的话可以 enable: false 关闭reward_settings:  # If true, reward will be displayed in every article by default.  enable: true  animation: false  comment: 本人坚持原创技术分享，如果你觉得文章对您有用，请随意打赏! 如果有需要咨询的请发送到我的邮箱! # 你的收款码，不需要的话可以注释掉！reward:  wechatpay: /images/wechatpay.png  alipay: /images/alipay.png# 这个替换成你的github就行了，不需要的话可以  enable: false 关闭github_banner:  enable: true  permalink: https://github.com/Anthony-Dong  title: Follow me on GitHub\n\n\n修改以下路径的图片，替换成你的图片\n\nhexo-home/themes/next/source/images/alipay.png   你的支付宝收款码hexo-home/themes/next/source/images/wechatpay.png  你的微信收款码hexo-home/themes/next/source/images/avatar.png  你的头像hexo-home/themes/next/source/images/favicon.ico 你网站的icon\n\n\n修改个人简介，可以修改此文件: hexo-home/source/about/index.md 即可！\n如果开启百度统计，只需要修改hexo-home/themes/next/_config.yml此文件即可!  appid是hm.src = &quot;https://hm.baidu.com/hm.js?&#123;app_id&#125;&quot;; 最后那个ID！\n\n# Baidu Analyticsbaidu_analytics: # &lt;app_id&gt;\n\n3. 添加评论插件\n首先前往链接: Register a new OAuth application 创建一个 Auth APP , 申请页面如下，可以根据我的注释进行填写\n\n\n\n申请完成后可以在页面上查看  client-id 和 secret-id\n\n\n\n然后修改hexo-home/themes/next/_config.yml添加 gitalk 评论系统\n\n# Gitalk# For more information: https://gitalk.github.io, https://github.com/gitalk/gitalkgitalk:  enable: true  # 是否开启  github_id: xiao-bai # 你的GitHub用户名  repo: xiao-bai.github.io # 你仓库的地址  client_id: xxxx # 上面申请拿到的 client-id  client_secret: xxxxxx  # 上面申请拿到的 secret-id  admin_user: xiao-bai  # 你的GitHub名称，注意大小写  distraction_free_mode: true # 设置为true  language: #不用动！\n\n同时注意一下看一下是否存在hexo-home/themes/next/layout/_custom/sidebar.swig以下内容，不存在可以复制一下\n&#123;% if page.comments and config.gitalk.enable %&#125;&#123;% endif %&#125;\n\n\n搞完以后记得重新build下 make build 下，然后 make run 启动就行了\n打开页面会遇到这种情况 Related Issues not found , 这时候你其实已经成功了，make deploy发布就行了！\n\n\n这时候需要你登陆你的GitHub账号，然后他就会自动帮你初始化issues!  \n注意： \n\n你每发布一篇文章都需要你打开页面初始化下一Issues！\n你本地http://localhost:4000 访问无法创建Issues的！\n\n\n打开你的仓库的Issues页面就可以看到创建 issues 了！\n\n\n4. 支持mermain(流程图)\n在目录 hexo-home 执行 npm install hexo-filter-mermaid-diagrams --save ， 我安装的是1.0.5^版本\n修改配置文件hexo-home/themes/next/_config.yml \n\n# Mermaid tagmermaid:  enable: true  # Available themes: default | dark | forest | neutral  theme: forest\n\n注意更多配置可以参考: mermaid-js 文档 , 需要配合一起修改 hexo-home/themes/next/layout/_third-party/tags/mermaid.swig 文件！\n\n修改css样式，在文件 hexo-home/themes/next/source/css/_colors.styl 末尾添加\n\n.mermaid &#123; background: transparent; text-align: center;&#125;\n\n\n切记一定要关闭 pjax, 需要修改配置文件hexo-home/themes/next/_config.yml，原因是切换页面需要重新渲染流程图，如果开启切换页面的时候不会帮你渲染！！\n\n# Easily enable fast Ajax navigation on your website.# Dependencies: https://github.com/theme-next/theme-next-pjaxpjax: false\n\n5. 支持flowchart (流程图)\n在目录hexo-home 执行 npm install --save hexo-filter-flowchart  ，我安装的版本是1.0.4！\n修改配置文件 hexo-home/_config.yml , 默认的sdk版本过低，可能支持不太好，所以需要更换一下！\n\n# flowchart使用 hexo-filter-flowchart https://github.com/bubkoo/hexo-filter-flowchartflowchart:  raphael: &quot;https://cdnjs.cloudflare.com/ajax/libs/raphael/2.3.0/raphael.min.js&quot;  # optional, the source url of raphael.js  flowchart: &quot;https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.17.1/flowchart.min.js&quot; # optional, the source url of flowchart.js  options: # options used for `drawSVG`    scale: 1    line-width: 2    line-length: 50    text-margin: 10    font-size: 12\n\n\n具体更多配置可以参考文档: hexo-filter-flowchart\n\n6. 压缩HTML、JS、CSS目前hexo生成的代码，全部都是未压缩，目前前端主流的方式都是使用webpack和gulp进行压缩，但是webpack这块本人也未搜索到相关资料，所以用的gulp进行压缩！\n\n安装 gulp，执行 npm install --global gulp-cli\n安装其他插件\n\n\ngulp:  核心框架\ngulp-clean-css: 压缩css代码\ngulp-uglify: 压缩js代码，这个不支持es6\n**gulp-uglify-es**：压缩js代码，支持es6\ngulp-htmlclean：压缩html代码，清除空格和换行符\ngulp-htmlmin：压缩html的js/css代码等，但是支持度不是特别好，比如js代码无法压缩成行！\ngulp-html-minifier-terser： 压缩html的js/css代码，支持压缩js(兼容es6)\n\n\n安装依赖\n\nnpm install gulp gulp-clean-css gulp-uglify-es gulp-html-minifier-terser\n\n\n配置文件\n\nvar gulp = require(&#x27;gulp&#x27;)var minifycss = require(&#x27;gulp-clean-css&#x27;);const uglify = require(&#x27;gulp-uglify-es&#x27;).default;const htmlmin = require(&#x27;gulp-html-minifier-terser&#x27;);gulp.task(&#x27;compress_css&#x27;, function () &#123;    return gulp.src(&#x27;./public/**/*.css&#x27;)        .pipe(minifycss(&#123; compatibility: &#x27;ie8&#x27; &#125;)) // 兼容到IE8        .pipe(gulp.dest(&#x27;./public&#x27;));&#125;);gulp.task(&#x27;compress_js&#x27;, function () &#123;    return gulp.src(&#x27;./public/**/*.js&#x27;)        .pipe(uglify())        .pipe(gulp.dest(&#x27;./public&#x27;))&#125;)// 注意报错可以排出目录！防止生成失败！// 可接受参数的文档：https://github.com/terser/html-minifier-terser#options-quick-referencegulp.task(&#x27;compress_html&#x27;, function () &#123;    return gulp.src([&#x27;./public/**/*.html&#x27;, &#x27;!./public/2022/03/27/583186f06a088dc9967a483e3876b2a2/index.html&#x27;])        .pipe(htmlmin(            &#123;                removeComments: true, // 移除注释                removeEmptyAttributes: true, // 移除值为空的参数                removeRedundantAttributes: true, // 移除值跟默认值匹配的属性                collapseBooleanAttributes: true, // 省略布尔属性的值                collapseWhitespace: true, // 移除空格和空行                                minifyJS: true, // 压缩HTML中的JS                minifyCSS: true, // 压缩HTML中的CSS                minifyURLs: true, // 压缩HTML中的链接            &#125;        ))        .pipe(gulp.dest(&#x27;./public&#x27;))&#125;)// 默认任务，不带任务名运行gulp时执行的任务gulp.task(&#x27;default&#x27;, gulp.parallel(    &#x27;compress_css&#x27;, &#x27;compress_js&#x27;, &#x27;compress_html&#x27;));\n\n\n参考文章\n\nhttps://blog.inkuang.com/2021/405/\n7. 其他BUG修复1. 图片设置 style=&quot;zoom: 50%;&quot; 导致图片放大展示失败背景：目前typora其实可以缩放图片，导致使用 medium-zoom 可能出现bug，参考 issues#164 我大概改了一版本！\n\n修改文件: hexo-home/themes/next/source/js/next-boot.js\n\n// 修改此行代码// CONFIG.mediumzoom &amp;&amp; window.mediumZoom(&#x27;.post-body :not(a) &gt; img, .post-body &gt; img&#x27;);// 为这个CONFIG.mediumzoom &amp;&amp; NexT.utils.mediumZoomFunc();\n\n\n修改文件: hexo-home/themes/next/source/js/utils.js , 添加mediumZoomFunc 方法！\n\nmediumZoomFunc: function () &#123;  const zoom = mediumZoom(&#x27;.post-body :not(a) &gt; img, .post-body &gt; img&#x27;);  // 开启的时候取消掉 style.zoom  zoom.on(&#x27;open&#x27;, event =&gt; &#123;    var curentNodeAlt = event.target.alt;    document.querySelectorAll(&#x27;.medium-zoom-image&#x27;).forEach(elem =&gt; &#123;      if (elem.style.zoom == &#x27;&#x27;) &#123;        return;      &#125;      if (elem.alt != curentNodeAlt) &#123;        return;      &#125;      elem.alt = elem.alt + &#x27;|&#x27; + elem.style.zoom      elem.style.zoom = &#x27;&#x27;    &#125;);  &#125;)  // 关闭的时候 重新set style.zoom  zoom.on(&#x27;closed&#x27;, event =&gt; &#123;    var curentNodeAlt = event.target.alt;    document.querySelectorAll(&#x27;.medium-zoom-image&#x27;).forEach(elem =&gt; &#123;      if (elem.alt != curentNodeAlt) &#123;        return;      &#125;      var elemAltLastIndex = elem.alt.lastIndexOf(&#x27;|&#x27;)      if (elemAltLastIndex == -1) &#123;        return;      &#125;      elem.style.zoom = elem.alt.substring(elemAltLastIndex + 1)      elem.alt = elem.alt.substring(0, elemAltLastIndex)    &#125;);  &#125;)&#125;\n\n8. 配置 Tool 一起使用1. 创建一篇文章 or 标注一篇文章\n执行下面命令make create ，会生成一个页眉，你只需要把这个东西 copy 到你的文章中去！\n\n\n\n找到你的文章，写一些描述信息，例如我这篇文章就是这么写的！\n\n\n2. 发布到网站上\n本地构建一下make run，看看详情信息\n\n➜  note-master git:(master) ✗ make runbin/go-tool hexo --dir ./ --target_dir ./hexo-home/source/_posts2022/03/17 21:53:00.668245 api.go:63: [INFO] [hexo] command load config:....13:53:40.106 DEBUG Processed: layout/_third-party/search/localsearch.swig13:53:40.366 DEBUG Generator: page13:53:40.367 DEBUG Generator: post13:53:40.367 DEBUG Generator: category13:53:40.367 DEBUG Generator: archive13:53:40.367 DEBUG Generator: json13:53:40.368 DEBUG Generator: index13:53:40.368 DEBUG Generator: tag13:53:40.371 DEBUG Generator: asset13:53:40.403 INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.13:53:40.425 DEBUG Database saved13:53:59.402 DEBUG Rendering HTML index: index.html\n\n\n然后访问 http://localhost:4000 即可！看到网页\n\n\n\n最后没问题，执行make deploy 即可发布到远程网站了！\n\nmake deploy\n\n3. 高级功能1. 敏感关键字过滤这个我们都知道，公司会有安全团队扫描开源仓库，假如你涉及到公司敏感字眼也比较恶心，比如把你个人信息暴露了！但是要知道不能发布公司内部的文章上传出去，或者公司内部的代码，这个是任何公司的红线！切记，这个插件主要就是过滤一些公司的名字而已！\n配置文件在: 你只需要列出敏感词即可！在KeyWord地方！\nHexo:  KeyWord:    - &quot;敏感词&quot;    - &quot;敏感词2&quot;  Ignore:    - hexo-home\n\n2. 图片上传目前我使用的是我自己写的工具上传图片，主要是用的阿里云的OSS，基本上一年花个不到几块钱就可以搞定！\n具体可以参考 Upload 插件\n你在你本地的 .config/.go-tool.yaml 文件，配置一下配置即可！\nUpload:  Bucket:    default:      AccessKeyId: xxxx      AccessKeySecret: ihDP2HkiTQGYwMY1udCtq8cBQNKP5N      Endpoint: oss-accelerate.aliyuncs.com      UrlEndpoint: xxx.oss-accelerate.aliyuncs.com      Bucket: xxxx      PathPrefix: image    pdf:      AccessKeyId: xxxxx      AccessKeySecret: xxxxx      Endpoint: oss-accelerate.aliyuncs.com      UrlEndpoint: xxxx.oss-accelerate.aliyuncs.com      Bucket: xxxx      PathPrefix: pdf\n\n然后Typora配置下: \n\n3. 修改个人主页修改本地文件hexo-home/source/about/index.md  即可\n","categories":["工具"],"tags":["工具","Hexo","Next","Mermaid","Gulp"]},{"title":"Docker资源限制和如何监控","url":"/2021/01/28/1041c14319d758f789b79049f9abedad/","content":"​    容器比较强大的地方就是使用方便，强大的隔离性，但是生产上往往需要做到保护，比如a容器不能对于b容器造成任何影响，比如a容器资源占用太高，导致b容器无法响应，获取a容器down机影响宿主机或其他容器等等，都是不允许的，所以容器隔离技术就解决了这些问题！\n\n\n1、cgroup简介cgroup是Control Groups的缩写，是Linux 内核提供的一种可以限制、记录、隔离进程组所使用的物理资源(如 cpu、memory、磁盘IO等等) 的机制，被LXC、docker等很多项目用于实现进程资源控制。cgroup将任意进程进行分组化管理的 Linux 内核功能。cgroup本身是提供将进程进行分组化管理的功能和接口的基础结构，I/O 或内存的分配控制等具体的资源管理功能是通过这个功能来实现的。这些具体的资源管理功能称为cgroup子系统，有以下几大子系统实现：\n\nblkio：设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。\ncpu：使用调度程序为cgroup任务提供cpu的访问。\ncpuacct：产生cgroup任务的cpu资源报告。\ncpuset：如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。\ndevices：允许或拒绝cgroup任务对设备的访问。\nfreezer：暂停和恢复cgroup任务。\nmemory：设置每个cgroup的内存限制以及产生内存资源报告。\nnet_cls：标记每个网络包以供cgroup方便使用。\nns：命名空间子系统。\nperf_event：增加了对每group的监测跟踪的能力，即可以监测属于某个特定的group的所有线程以及运行在特定CPU上的线程。\n\n目前docker只是用了其中一部分子系统，实现对资源配额和使用的控制。\n2、docker如何限制的使用的是stress镜像压测 ：https://hub.docker.com/r/jfusterm/stress\ndocker pull jfusterm/stress\n\n1、内存限制\n\n\n选项\n描述\n\n\n\n-m,--memory\n内存限制，格式是数字加单位，单位可以为 b,k,m,g。最小为 4M\n\n\n--memory-swap\n内存+交换分区大小总限制。格式同上。必须必-m设置的大\n\n\n--memory-reservation\n内存的软性限制。格式同上\n\n\n--oom-kill-disable\n是否阻止 OOM killer 杀死容器，默认没设置\n\n\n--oom-score-adj\n容器被 OOM killer 杀死的优先级，范围是[-1000, 1000]，默认为 0\n\n\n--memory-swappiness\n用于设置容器的虚拟内存控制行为。值为 0~100 之间的整数\n\n\n--kernel-memory\n核心内存限制。格式同上，最小为 4M\n\n\n为了压测我们选择一个容器\n1、只设置 -m 参数，可以发现当限制内存在 128m时，我们还是可以分配128m的，所以-m并不是全部的限制\n➜  ~ docker run -it --rm -m 128m  jfusterm/stress --vm 1 --vm-bytes 128m -t 5sstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: info: [1] successful run completed in 5s\n\n当我们继续增加到原来的两倍，发现运行失败\n➜  ~ docker run -it --rm -m 128m  jfusterm/stress --vm 1 --vm-bytes 256m -t 5sstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: FAIL: [1] (415) &lt;-- worker 6 got signal 9stress: WARN: [1] (417) now reaping child worker processesstress: FAIL: [1] (421) kill error: No such processstress: FAIL: [1] (451) failed run completed in 1s\n\n当我们设置为 250m,发现运行成功\n➜  ~ docker run -it --rm -m 128m  jfusterm/stress --vm 1 --vm-bytes 250m -t 5sstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: info: [1] successful run completed in 5s\n\n2、设置--memory 和--memory-swap 参数\n设置 128 &amp; 128 ，分配 127时OK的，\n➜  ~ docker run -it --rm --memory 128m  --memory-swap 128m jfusterm/stress --vm 1 --vm-bytes 127m -t 5sstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: info: [1] successful run completed in 5s\n\n设置128 &amp; 128 ，分配128 失败\n➜  ~ docker run -it --rm --memory 128m  --memory-swap 128m jfusterm/stress --vm 1 --vm-bytes 128m -t 5sstress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hddstress: FAIL: [1] (415) &lt;-- worker 7 got signal 9stress: WARN: [1] (417) now reaping child worker processesstress: FAIL: [1] (421) kill error: No such processstress: FAIL: [1] (451) failed run completed in 1s\n\n2、如何查看容器真实内存[root@centos-linux ~]# docker run --rm -it -m 128m alpine /bin/sh/ # free -m              total        used        free      shared  buff/cache   availableMem:           1980         266        1143          21         569        1559Swap:             0           0           0\n\n经常遇到这种问题，容器内的内存和真实内存其实不一致的，原因是啥？ \n这是由于docker产生的容器的隔离性不足造成的。docker创建容器时，会为容器提供一些必要的目录和文件，比如/proc下的若干文件。其中/proc/meminfo文件docker并没有直接提供其生成，而是将宿主机的/proc/meminfo挂载给了容器。因此容器看到的/proc/meminfo与宿主机的/proc/meminfo的内容是一样的。而free命令也不过是查看该文件的信息而已。如果想增强其隔离性，可以使用lxcfs的方式。\n那如何解决了？\ndocker其实本身使用 cgroup进行隔离，其实它监控也只能监控cgroup，本机是 CentOS Linux release 7.9.2009 (Core)\n[root@centos-linux ~]# ls /sys/fs/cgroup/memory/docker/9fc278a2cab2bde9f2aa10fb8eb58732f4d1f3ce0f988ed64cac4b4616a585f1/cgroup.clone_children           memory.kmem.tcp.max_usage_in_bytes  memory.oom_controlcgroup.event_control            memory.kmem.tcp.usage_in_bytes      memory.pressure_levelcgroup.procs                    memory.kmem.usage_in_bytes          memory.soft_limit_in_bytesmemory.failcnt                  memory.limit_in_bytes               memory.statmemory.force_empty              memory.max_usage_in_bytes           memory.swappinessmemory.kmem.failcnt             memory.memsw.failcnt                memory.usage_in_bytesmemory.kmem.limit_in_bytes      memory.memsw.limit_in_bytes         memory.use_hierarchymemory.kmem.max_usage_in_bytes  memory.memsw.max_usage_in_bytes     notify_on_releasememory.kmem.slabinfo            memory.memsw.usage_in_bytes         tasksmemory.kmem.tcp.failcnt         memory.move_charge_at_immigratememory.kmem.tcp.limit_in_bytes  memory.numa_stat\n\n\n\n\n文件名称\n含义\n\n\n\nmemory.usage_in_bytes\n已使用的内存量(包含cache和buffer)(字节)，相当于linux的used_meme\n\n\nmemory.limit_in_bytes\n限制的内存总量(字节)，相当于linux的total_mem\n\n\nmemory.failcnt\n申请内存失败次数计数\n\n\nmemory.memsw.usage_in_bytes\n已使用的内存和swap(字节)\n\n\nmemory.memsw.limit_in_bytes\n限制的内存和swap容量(字节)\n\n\nmemory.memsw.failcnt\n申请内存和swap失败次数计数\n\n\nmemory.stat\n内存相关状态\n\n\n查看\n[root@centos-linux ~]# docker stats 9fc278a2cab2bde9f2aa10fb8eb58732f4d1f3ce0f988ed64cac4b4616a585f1 --no-streamCONTAINER ID   NAME            CPU %     MEM USAGE / LIMIT   MEM %     NET I/O       BLOCK I/O   PIDS9fc278a2cab2   elated_panini   0.00%     560KiB / 128MiB     0.43%     1.01kB / 0B   0B / 0B     1[root@centos-linux 9fc278a2cab2bde9f2aa10fb8eb58732f4d1f3ce0f988ed64cac4b4616a585f1]# cat memory.usage_in_bytes573440\n\n所以可以看到俩数据基本一致，具体逻辑：https://github.com/opencontainers/runc/blob/v0.1.1/libcontainer/cgroups/fs/memory.go#L148\n参考：Docker容器内存监控\n","categories":["云原生"],"tags":["Docker","监控"]},{"title":"Thrift 协议讲解","url":"/2022/03/20/1fbc1901406195cf47c58e7436468f2e/","content":"​        目前我在字节工作，字节这边服务端基本上都是Thrift-RPC和http服务（序列化有 json/pb），内部基础设施建设也比较给力，比如我在职的部门就是做API相关的，主要是做API管理和API网关的，对于接口协议这块也是有比较深入的了解！本文主要是介绍 Thrift协议，以thrift 协议发展历史和发展背后的故事，以及在service mesh 下 thrift 的发展！再其次就是介绍基于PB/Thrift IDL打造API管理和API网关的部分核心能力！如果你也想了解PB，可以看我写的这篇文章: PB协议讲解！\n\n\n整体介绍\nthrift 协议整体设计比较复杂，但是呢语法支持度也比较高，能满足大部分业务需求，完全可以通过编写IDL把所有接口定义能做的事情都做了！这个是区别于pb的，但是PB压缩率更高！再其次就是thrift的代码产物体积要大于PB，因为PB是使用反射实现的序列化和反序列化，thrift使用的是更具代码生成实现的序列化反序列化，不过这些其实和脚手架实现有关，但是现状确实如此！所以NA侧都喜欢用PB，存储侧也喜欢用PB定义，如果想要了解PB的协议介绍可以看我写的这篇文章：PB协议讲解\n\nthrift 即包含了RPC的协议层、传输层！PB只能解决协议层，需要GRPC/其他rpc框架进行传输！\n\n\n\n这里提到的协议层指的是例如 HTTP1.1 需要基于 TCP进行传输，那么HTTP1.1是协议层，TCP是传输层！这里说的是一个相对的概念！\n\n\n架构图就不聊了，网上一堆，就一个rpc通信框架其实架构图都一样！下文主要介绍： 消息协议（协议层） + 传输协议（传输层），有兴趣可以看下字节开源的 Kitex！\nthrift 是 facebook 开源的一个rpc协议，诞生时间比较早，应该是10年之前了，所以国内互联网公司基本上都用的thrift协议，原因就是出来的比较早的成熟的RPC框架！但是也存在一个问题就是，古老的协议往往不满足现在的服务架构，所以后期也做了进一步的升级，但是老的业务还在跑，升级比较麻烦，也就导致很多公司thrift并没有用到新特性！例如字节这边thrift主要是用的 binary 协议！\n由于本人主写Go，然后大家可以看下 https://github.com/apache/thrift/tree/master/lib/go go的实现，协议上！\nthrift 语法丰富，详细可以看文档：https://thrift.apache.org/docs/ !\n\ntypedef string Birthdayconst Birthday NationalDay=&#x27;1949-10-01&#x27;// 其他类型 i64 i32 i16 byte double bool binarystruct TestRequest &#123;     1: string Field_name = &#x27;default value&#x27; (api.tag=&#x27;xxxx&#x27;);    2: required string F_string_required;    3: optional string F_string_optional;    4: list&lt;string&gt; F_list_default;    5: map&lt;string,string&gt; F_map_default;    6: set&lt;string&gt; F_set_default;    7: optional Numberz F_enum = Numberz.Unknown,&#125;enum Numberz&#123;  Unknown = 0  ONE = 1  TWO&#125;struct TestResponse &#123; &#125;service ThriftTest&#123;\t\tTestResponse Test (1: TestRequest req),&#125;\n\n消息协议 (Protocol  or Framed协议)主要是详细介绍了消息传输的时候协议的主要编解码方式，注意thrift采用的是大端编码！\n1. TBinaryProtocol (原始协议)消息协议介绍，有两种协议格式！主要是由于历史原因，导致有两种协议并存！下面介绍基本来自于官方文档: thrift-binary-protocol\n1. 消息协议一（新编码，严格模式）Binary protocol Message, strict encoding, 12+ bytes:+--------+--------+--------+--------+--------+--------+--------+--------+--------+...+--------+--------+--------+--------+--------+|1vvvvvvv|vvvvvvvv|unused  |00000mmm| name length                       | name                | seq id                            |+--------+--------+--------+--------+--------+--------+--------+--------+--------+...+--------+--------+--------+--------+--------+\n\n\n前两个字节表示版本号：**高位第一个bit固定为1(因为为了区分下面协议二)**，其他17个bit(vvvvvvvvvvvvvvv)表示版本。\n第三个字节为无用字节：unused是一个被忽略的字节。\n第四个字节为消息类型： mmm是消息类型，一个无符号的 3 位整数，同时高位5bit必须为0(有些SDK会校验)。\n\n// 取头部四个字节: size = readInt32()// 取消息类型: size &amp; (1&lt;&lt;8)-1// 取版本号:  siez &amp; 0xffff0000, 版本基本就是1,直接硬编码比较就行了//  消息类型占用3bitCall: 1Reply: 2Exception: 3Oneway: 4\n\n\nname length：消息名长度，占用4字节！大端！（注意大小端只是针对于number类型，而且大小端转换基本无开销）\nname: 消息名，utf8编码\nseq id:  占用四字节，大端！（一般rpc多路复用都有，因为要并发发送请求么，不能同一个连接 发送接收完  A  再发送接收 B请求， 像Http1.1就是PingPong协议，HTTP2也是有一个seq id ，这东西做的简单点就全局自增一个id即可！）\n\n\n这里补充下位运算，位运算中 &amp;一般作用就是取值， |一般作用就是Set值！\n\n2. 消息协议二 （旧编码，非严格模式）\n这个假如客户端/server端开启了严格模式，则不能兼容次协议\n\nBinary protocol Message, old encoding, 9+ bytes:+--------+--------+--------+--------+--------+...+--------+--------+--------+--------+--------+--------+| name length                       | name                |00000mmm| seq id                            |+--------+--------+--------+--------+--------+...+--------+--------+--------+--------+--------+--------+\n\n\nname length(四字节): 这里为了兼容上面协议一，所以高位第一个bit必须为0！也就是name length必须要有符号的正数！\nname：消息名称\nmmm:  消息类型，同上\nseq id: 消息ID\n\n3. 结构体这个协议比较简单，就是个基本的编码协议！！！其实就是一个 tlv 编码！\n1. 结构体Binary protocol field header and field value:+--------+--------+--------+--------+...+--------+|tttttttt| field id        | field value         |+--------+--------+--------+--------+...+--------+Binary protocol stop field:+--------+|00000000|+--------+\n\n\ntttttttt字段类型，带符号的 8 位整数。一个字节！\nfield idfield-id，一个大端序的有符号 16 位整数。两个字节！\nfield-value编码的字段值！\n\n# 字段类型BOOL, encoded as 2I8, encoded as 3DOUBLE, encoded as 4I16, encoded as 6I32, encoded as 8I64, encoded as 10BINARY, used for binary and string fields, encoded as 11STRUCT, used for structs and union fields, encoded as 12MAP, encoded as 13SET, encoded as 14LIST, encoded as 15\n\n2. list / setBinary protocol list (5+ bytes) and elements:+--------+--------+--------+--------+--------+--------+...+--------+|tttttttt| size                              | elements            |+--------+--------+--------+--------+--------+--------+...+--------+\n\n\ntttttttt表示元素类型，编码为 int8\nsize 表示全部元素个数，编码为 int32，仅正值\nelements 全部元素，顺序排列\n\n3. mapBinary protocol map (6+ bytes) and key value pairs:+--------+--------+--------+--------+--------+--------+--------+...+--------+|kkkkkkkk|vvvvvvvv| size                              | key value pairs     |+--------+--------+--------+--------+--------+--------+--------+...+--------+\n\n\nkkkkkkkk是关键元素类型，编码为 int8\nvvvvvvvv是值元素类型，编码为 int8\nsize是 map的size，编码为 int32，仅正值\nkey value pairs是编码的键和值，意思就是先读key，再读value，再读key，再读value\n\n4. string/binaryBinary protocol, binary data, 4+ bytes:+--------+--------+--------+--------+--------+...+--------+| byte length                       | bytes                |+--------+--------+--------+--------+--------+...+--------+\n\n\nbyte length是字节数组的长度\nbytes是字节数组的字节\n\nstring 类型就是utf-8 编码为字节流，然后传输的时候用 binary 类型即可！ \n5. 其他类型基本类型就是占用固定字节！比如Bool一个字节，i64 8个字节之类的！！ 枚举等同于i32！\n2. TCompactProtocol （改进协议，和PB基本类似！）名字显而易见，就是用来压缩的，压缩算法和pb很像，就是 zigzag（处理负数）+ varint （正数）,这俩东西可以看我讲的PB协议的文章  ，不过也做了很多取巧的地方，下面内容基本来自官方文档: thrift-compact-protocol\n1. 消息协议Compact protocol Message (4+ bytes):+--------+--------+--------+...+--------+--------+...+--------+--------+...+--------+|pppppppp|mmmvvvvv| seq id              | name length         | name                |+--------+--------+--------+...+--------+--------+...+--------+--------+...+--------+\n\n这个协议也很简单，就是更紧凑\n\n第一个字节： 协议ID，TCompactProtocol ID为 130，二进制编码为 10000010\n第二个字节:  version + type， 其中version是低5bit，type是高3bit ， 其中 COMPACT_VERSION = 1\nseq id 4字节，var int 编码\nname len 为4字节，也是var int 编码\nname: 消息名称\n\n// 消息类型Call: 1Reply: 2Exception: 3Oneway: 4\n\n2. 结构体1. 结构体Compact protocol field header (short form) and field value:+--------+--------+...+--------+|ddddtttt| field value         |+--------+--------+...+--------+Compact protocol field header (1 to 3 bytes, long form) and field value:+--------+--------+...+--------+--------+...+--------+|0000tttt| field id            | field value         |+--------+--------+...+--------+--------+...+--------+Compact protocol stop field:+--------+|00000000|+--------+\n\n\ndddd是字段  delta，一个无符号的 4 位整数，严格正数。\ntttt是字段类型 id，一个无符号的 4 位整数。\nfield id字段 id，一个有符号的 16 位整数，编码为 zigzag int！\nfield-value编码的字段值。\n\n# 字段的类型，其中下面的 map/list 类型，也很简单就是可以把BOOLEAN_FALSE当作BOOL类型即可，就不重复写了！BOOLEAN_TRUE, encoded as 1BOOLEAN_FALSE, encoded as 2I8, encoded as 3I16, encoded as 4I32, encoded as 5I64, encoded as 6DOUBLE, encoded as 7BINARY, used for binary and string fields, encoded as 8LIST, encoded as 9SET, encoded as 10MAP, encoded as 11STRUCT, used for both structs and union fields, encoded as 12\n\n这里比较特殊的就是：bool类型是不占用field value 字节的，其次就是有两种编码协议，它的原理确实比pb 还要取巧，哈哈哈！\n首先我们在编码的时候，field_id 一般都是顺序自增的！也就是基本上是1,2,3…n ,这时候由于 type占用4bit，此时可以用剩余的4bit存储field_id的增量即可！这个就是为啥pb可以做到  field_id &lt; 15 的时候字节占用一个了！\n// start last_field_id=0// write fieldif field_id &gt; last_field_id &amp; field_id-last_field_id&lt;=15&#123;   // use delta&#125;else&#123;   // use normal&#125;last_field_id=field_id\n\n例如下面这个例子field_id： 1,2,3,4,5,30,31,32\n0000tttt, 1  # 10001tttt, #20001tttt, #30001tttt, #40001tttt, #50000tttt, 30 #300001tttt, #310001tttt, #32\n\n这里还有个细节点就是 bool 类型！bool 类型是不占用 field_value 的！\n2. list/setCompact protocol list header (1 byte, short form) and elements:+--------+--------+...+--------+|sssstttt| elements            |+--------+--------+...+--------+Compact protocol list header (2+ bytes, long form) and elements:+--------+--------+...+--------+--------+...+--------+|1111tttt| size                | elements            |+--------+--------+...+--------+--------+...+--------+\n\n\nssss是len(list/map)的大小，4 位无符号整数，值0-14\ntttt是元素类型，一个 4 位无符号整数\nsize是大小，var int (int32)，正值15或更高\nelements是编码元素\n\n这个其实我就不用说了，假如size&lt;=15的话那么可以使用第一种了！\n3. mapCompact protocol map header (1 byte, empty map):+--------+|00000000|+--------+Compact protocol map header (2+ bytes, non empty map) and key value pairs:+--------+...+--------+--------+--------+...+--------+| size                |kkkkvvvv| key value pairs     |+--------+...+--------+--------+--------+...+--------+\n\n\nsize是len(map)的大小，一个 var int (int32)，严格的正值\nkkkk是关键元素类型，一个 4 位无符号整数\nvvvv是值元素类型，一个 4 位无符号整数\nkey value pairs是编码的键和值\n\n其实这个更不用说了，就是当size等于0时，就写入第一种协议！\n4. binary、stringBinary protocol, binary data, 1+ bytes:+--------+...+--------+--------+...+--------+| byte length         | bytes               |+--------+...+--------+--------+...+--------+\n\n\nbyte length 采用varint， 四字节编码\nbytes body\n\nstring类型传输的时候是utf8编码的binary类型！\n5. 其他类型占用固定字节，采用varint编码\n传输协议 （Transport）其实上面部分讲到的消息协议已经是一个完整的协议，你直接基于tcp流发送请求响应协议即可！但是为啥这块还跑出个传输协议！对的上面协议其实是有问题！因此下列列出了几个传输协议！下面这块内容基本来自于官方文档: rpc 协议介绍\nBuffered（Unframed）协议也就是上面讲解的TBinaryProtocol 和 TCompactProtocol 协议！这个协议特点就是没有payload的总长度，导致做异步处理成为难点！\nFramed 协议现在问题就是异步比较流行，所以需要再发送数据的时候采用Framed编码，先写size，再写payload！当server端处理的时候可以根据frame_size来获取payload，然后交给 processs处理！官方的解释是为了支持 async 编程！其实我觉得就是为了更加高效罢了，不需要把整个包解析出来，也就是传输层可以节省很多性能开销！\n\n其实这个协议是有问题的，就是假如消息体过大的话！那么内存开销就比较大，因为需要先写到内存里，然后再头部加四个字节！\nTHeader 协议 （service mesh协议）​        但是随着后端的技术不断发展，传统的微服务架构不能满足发展，普通的传输协议不满足于现状，因此当出现服务网格service mesh的时候，出现问题了，因为需要做流量治理，我们需要在协议里注入一些服务信息进行流量治理等等，因此后来faceboot推出了THeaderProtocol。其实原来的老协议也能做，那就是可以在 message中定义一些 公共字段来注入流量信息，但是存在问题就是需要把整个包解出来，浪费性能！而header协议不需要，其实目前字节现在就是两种协议并存的现状！\n​        一般流量治理主要有几大块：全链路trace+log、acl鉴权、tls流量加密、染色分流、多机房（集群）调度+LB、限流、过载保护[自适应限流、服务优先级]等，还有一些功能型能力比如压缩之类的！如果没有这个协议做这块也太难了，哈哈哈！\n协议如下: \n  0 1 2 3 4 5 6 7 8 9 a b c d e f 0 1 2 3 4 5 6 7 8 9 a b c d e f+----------------------------------------------------------------+| 0|                          LENGTH                             |+----------------------------------------------------------------+| 0|       HEADER MAGIC          |            FLAGS              |+----------------------------------------------------------------+|                         SEQUENCE NUMBER                        |+----------------------------------------------------------------+| 0|     Header Size(/32)        | ...+---------------------------------                  Header is of variable size:                   (and starts at offset 14)+----------------------------------------------------------------+|         PROTOCOL ID  (varint)  |   NUM TRANSFORMS (varint)     |+----------------------------------------------------------------+|      TRANSFORM 0 ID (varint)   |        TRANSFORM 0 DATA ...+----------------------------------------------------------------+|         ...                              ...                   |+----------------------------------------------------------------+|        INFO 0 ID (varint)      |       INFO 0  DATA ...+----------------------------------------------------------------+|         ...                              ...                   |+----------------------------------------------------------------+|                                                                ||                              PAYLOAD                           ||                                                                |+----------------------------------------------------------------+\n\n\nLENGTH：（4字节大端） 整个消息的长度除了 len自身4字节，比如整个消息长度为69，那么 LENGTH=65\n\nHEADER MAGIC ：2字节，魔数\n\nFLAGS: 2字节，header  Flags\n\nSEQUENCE NUMBER (4字节): seq  id\n\nHeader Size:  头部字节 / 4\n\nHeader   头部介绍：（采用Compact编码）\n\nPROTOCOL ID:  表示协议ID，4字节\nNUM TRANSFORMS:  表示 len(TRANSFORMS)，4字节\nTRANSFORMS: 如果有的话才会传输，每个 transform  是一个4字节int类型，这个可以做 pyload的压缩！\nINFO是Theader 的核心功能，可以做很高的拓展！\n\n  info type: 4字节例如 InfoKeyValue 类型是 map&lt;string,string&gt; 的一个header类型，这里就是write一个map！例如字节这边拓展了InfoIDIntKeyValue:map&lt;int,string&gt; 和 InfoIDACLToken: string 等类型！\n\n\npadding  填充字节，头部字节数必须是4的倍数\n\n\nPAYLOAD  真实数据，具体分为 UnframedBinary  和  UnframedCompact 协议\n\n\n具体细节我就不讲了，其实就是可以携带一些header信息，在传输的时候可以携带上，然后头部有头部编码的协议！\nheader信息可以做些什么呢，它包含一些  log 、trace、acl、流量调度的信息、服务优先级之类的！！！做流量染色！\n其次就是mesh其实只需要关注于这些信息，payload部分它不关心，所以他不需要解pyload 部分！\n整体概述一下全部协议// Unframed 又成为 Buffered协议const (\tUnknownProto Protocol = 0\t// Unframed协议大改分为以下几类\tUnframedBinary  Protocol = 1\tUnframedCompact Protocol = 2\t// Framed协议分为以下几类\tFramedBinary  Protocol = 3\tFramedCompact Protocol = 4\t// Header 协议，默认是Unframed，也可以是Framed的，其实本身来说Header协议并不需要再包一层Framed协议\t// Header 协议的Protocol还会继续分为 Compact 和 Binary, 这里由于sdk会默认支持 Protocol 解析，所以就不写了  UnframedHeaderProto Protocol = 5\tFramedHeaderProto   Protocol = 6\t// Binary 非严格协议大改分为以下两种！其实还有一种是 Header+Binary这种协议，这里就不做细份了\tUnframedUnStrictBinary Protocol = 7\tFramedUnStrictBinary   Protocol = 8)\n\n如何创建协议\nimport (\t&quot;io&quot;\t&quot;github.com/apache/thrift/lib/go/thrift&quot;)func NewTProtocol(reader io.Reader, protocol Protocol) thrift.TProtocol &#123;\ttReader := thrift.NewStreamTransportR(reader)\tswitch protocol &#123;\tcase UnframedBinary, UnframedUnStrictBinary:\t\treturn thrift.NewTBinaryProtocolTransport(tReader)\tcase UnframedCompact:\t\treturn thrift.NewTCompactProtocol(tReader)\tcase FramedBinary, FramedUnStrictBinary:\t\treturn thrift.NewTBinaryProtocolTransport(thrift.NewTFramedTransport(tReader))\tcase FramedCompact:\t\treturn thrift.NewTCompactProtocol(thrift.NewTFramedTransport(tReader))\tcase UnframedHeaderProto:\t\treturn thrift.NewTHeaderProtocol(tReader)\tcase FramedHeaderProto:\t\treturn thrift.NewTHeaderProtocol(thrift.NewTFramedTransport(tReader))\t&#125;\treturn nil&#125;func NewProtocolEncoder(writer io.Writer, protocol Protocol) thrift.TProtocol &#123;\ttReader := thrift.NewStreamTransportW(writer)\tswitch protocol &#123;\tcase UnframedBinary:\t\treturn thrift.NewTBinaryProtocolTransport(tReader)\tcase UnframedUnStrictBinary:\t\treturn thrift.NewTBinaryProtocol(tReader, false, false)\tcase UnframedCompact:\t\treturn thrift.NewTCompactProtocol(tReader)\tcase FramedBinary:\t\treturn thrift.NewTBinaryProtocolTransport(thrift.NewTFramedTransport(tReader))\tcase FramedUnStrictBinary:\t\treturn thrift.NewTBinaryProtocol(thrift.NewTFramedTransport(tReader), false, false)\tcase FramedCompact:\t\treturn thrift.NewTCompactProtocol(thrift.NewTFramedTransport(tReader))\tcase UnframedHeaderProto:\t\treturn thrift.NewTHeaderProtocol(tReader)\tcase FramedHeaderProto:\t\treturn thrift.NewTHeaderProtocol(thrift.NewTFramedTransport(tReader))\t&#125;\treturn nil&#125;\n\n基于Thrift/PB IDL的API管理​         目前由于内部存在Thrift RPC 和 http服务并存，而且对外比如前端/客户端/OpenAPI，基本上都是需要Http形式暴露出去，因此对于字节这边建设了API网关去做协议转换！同样会存在一个问题，就是HTTP -&gt; RPC 直接协议转换，会涉及到 我是query、header、body、code等绑定到哪个字段的问题，所以有一套IDL注解规范去帮助通过写IDL来定义http接口！同时也更加有效的降低成本接入api网关！不过这个功能只是网关的协议转换模块！其实协议转换不光光http-&gt;thrift ，而且还存在 pb in http - &gt; thrift，因为字节核心的客户端很多都是用的PB定义的body，压缩率比较高，例如抖音和TikTok！\n​        基于IDL去定义API好处是，我们可以通过IDL实现多版本的接口管理，而且实现 rpc/http等接口的元数据管理，更加方便用户进行使用！同时对于rpc 服务我们提供了在线编辑+脚手架能力，业务可以在平台上编写完成idl后直接可以生成代码！对于调用方我们可以直接在接口管理平台查看代码生成产物进行更新依赖！\n​        其次就是我们有移动端网关的建设，主要是服务端NA (app)端，由于na端需要代码生成，因此我们也打通了多服务、裁剪接口的代码生成，idl可以是 pb / thrift 等！同时我们也在网关侧实现了API聚合的能力，基于GraphQL等能力建设的！\n​        再其次我们构建了接口测试、抓包、mock等其他功能，打通了内部的环境，使得抓包、mock可以做到在平台上一键/且无侵入式就可以实现等功能，更加方便了研发的使用！关键是可以去除tls加密，再也不需要用charles!\n​        还有我们打造了一个完整的API研发流程，帮助用户更加高效的接口定义、开发、测试、上线、发布网关！还有其他能力我也就不一一介绍了！\n参考\nthrift doc \ngo thrift\nthrift\npb 协议讲解\ngraphql\n\n","categories":["RPC"],"tags":["Thrift","GRPC","API"]},{"title":"聊一聊HTTP协议","url":"/2022/05/19/14ae618744ce995daa153156bee2d2e6/","content":"​     如今互联网已经与我们密不可分了，购物、金融、社交、娱乐等都依赖于互联网，其中主要依赖的几项技术就包含HTTP（HyperText Transfer Protocol， 超文本传输协议）。本文核心就是介绍HTTP发展历史以及HTTP/2协议！\n\n\nHTTP发展历史\nHTTP/0.9HTTP协议的第一个规范是1991年发布的0.9版本，此规范文档不足700个单词，其中规范中指出了通过TCP/IP （或类似的面向连接的服务）与服务器和端口建立连接！规范申明错误类型以可读文本显示HTML语法，以及请求是幂等的！\n\n目前已经没有网站和浏览器支持 http/0.9 协议了！\n\n请求格式：只有GET方法，报文如下：\nGET /doc/index.heml\n\n响应内容：只有HTML文本，所以无法传输其他类型文件！\n&lt;HTML&gt;这是一个非常简单的HTML页面&lt;/HTML&gt;\n\nHTTP/1.0在1991-1995年，人们由于不满足HTTP/0.9，于是搞了一些新扩展，但是这些新拓展并没有被引入到标准中。直到1996年11月，为了解决这些问题，一份新文档（RFC 1945）被发表出来，用以描述如何操作实践这些新扩展功能。\n主要新增内容如下：\n\n引入了 POST、HEAD方法\n请求与响应都引入了 HTTP 头/首部（Header），为此也支持了其他传输类型（图片等）\n引入响应状态码\n\n➜  ~ curl --http1.0 www.baidu.com -v*   Trying 220.181.38.149:80...* Connected to www.baidu.com (220.181.38.149) port 80 (#0)&gt; GET / HTTP/1.0&gt; Host: www.baidu.com&gt; User-Agent: curl/7.77.0&gt; Accept: */*&gt;* Mark bundle as not supporting multiuse* HTTP 1.0, assume close after body&lt; HTTP/1.0 200 OK&lt; Accept-Ranges: bytes&lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform&lt; Content-Length: 2381&lt; Content-Type: text/html# .... 省略\n\nHTTP/1.1HTTP/1.0 多种不同的实现方式在实际运用中显得有些混乱，自1995年开始，即HTTP/1.0文档发布的下一年，就开始修订HTTP的第一个标准化版本。于是在1997年初，HTTP1.1 标准发布。\n主要新增内容如下：（下列内容部分也在HTTP/1.0中有支持，所以和HTTP/1.1统称为HTTP/1.X）\n\n连接复用 (引入 Keep-Alive Header)\n增加管线化（管道化）技术，允许在第一个应答被完全发送之前就发送第二个请求，以降低通信延迟。\n支持响应分块(chunked编码)\n引入额外的缓存控制机制\n引入内容协商机制，包括语言，编码，类型等，并允许客户端和服务器之间约定以最合适的内容进行交换\n凭借Host头，能够使不同域名配置在同一个IP地址的服务器上，并且强制要求客户端请求必须携带Host。例如Nginx这种反向代理工具，可能根据Host进行反向代理，也就是一台服务器承载多个域名！\n支持包含GET、POST、PUT、PATCH、DELETE、HEAD、CONNECT、OPTIONS、TRACE 请求方法\n\n➜  ~ curl --http1.1 www.baidu.com -v*   Trying 220.181.38.149:80...* Connected to www.baidu.com (220.181.38.149) port 80 (#0)&gt; GET / HTTP/1.1&gt; Host: www.baidu.com&gt; User-Agent: curl/7.77.0&gt; Accept: */*&gt;* Mark bundle as not supporting multiuse&lt; HTTP/1.1 200 OK&lt; Accept-Ranges: bytes&lt; Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform&lt; Connection: keep-alive&lt; Content-Length: 2381&lt; Content-Type: text/html&lt; Date: Mon, 23 May 2022 09:57:28 GMT&lt; Etag: &quot;588604c8-94d&quot;&lt; Last-Modified: Mon, 23 Jan 2017 13:27:36 GMT&lt; Pragma: no-cache&lt; Server: bfe/1.0.8.18&lt; Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/\n\n由于HTTP协议的可扩展性 – 创建新的头部和方法是很容易的 – 即使 HTTP/1.1 协议进行过两次修订，RFC 2616 发布于 1999 年 6 月，而另外两个文档 RFC 7230-RFC 7235 发布于 2014 年 6 月（在 HTTP/2 发布之前）。HTTP/1.1 协议已经稳定使用超过 15 年了。\n1. HTTP/1.1 修订记录HTTP/1.1 协议发布于1997年的1月份，后面经过三次修订！最后一次修订时间是2014年6月份！具体修订内容可以点击下面链接进行查看！HTTP1.1的岁数和我差不多！\n\n首发 1997年 rfc2068\n第一次修订 1999年 rfc2616\n第二次修订 2014年 rfc7230 (想要详细了解HTTP协议编码可以看这个)\n第三次修订 2014年 rfc7235\n\n2. 服务端优化手段1. keep-alive引入keep-alive 可以有效的降低了TCP建立连接的开销（包含TCP握手和TCP流量控制），其次就是有效的降低了系统开销，如TCP连接数等！\n在HTTP/1.0中默认是关闭开启 keep-alive 的，必须在请求头部添加Connection: keep-alive才可以；但是在HTTP/1.1中默认是开启keep-alive，需要在响应头加入Connection: close才可以关闭！下图是两者的差异\n\n但是也会存在很多问题，原来是请求-&gt;响应直接关闭连接很容易拆包，但是出现了连接复用，那么如何拆包呢？HTTP/1.x中如果我们开启了keep-alive必须在请求头和响应头中加入content-length来标识请求体/响应体的大小！（chunked传输编码除外）\n\n 测试\n\n# HTTP/1.1，下图为HTTP/1.1的抓包图curl  --url http://localhost:8888/api/test/req1     --url http://localhost:8888/api/test/req2   --data-raw &#x27;hello world&#x27; -v# HTTP/1.0curl  --url http://localhost:8888/api/test/req1     --url http://localhost:8888/api/test/req2   --data-raw &#x27;hello world&#x27;  -H &#x27;Connection: keep-alive&#x27; --http1.0 -v\n\n\n\n关于如何实现HTTP的 keep-alive，一般server端设置读超时即可，client端维护就比较麻烦，可以阅读一些源码看一下即可，其次就是用的连接池！\n目前字节内部的TLB做代理的时候维护单个请求连接的时间过长，导致连接不会被销毁，也就是经常会出现后端服务（up stream）出现大量的 TCP ESTABLISHED ，其主要原因也是因为client侧不断开连接，server侧一般也不会直接断开，这也就是为什么后面HTTP/2做了自己的keep-alive机制了！\nkeep-alive 另外还是额外的两个配置，一个是 timeout 一个是max，例如Keep-Alive: timeout=5, max=1000 ， 具体可以看： https://tools.ietf.org/id/draft-thomson-hybi-http-timeout-01.html ！可以参考Nginx的实现!\n如果响应头里申明 Connection=close ，则会关闭连接！\n\n2. 请求体压缩一般压缩是根据 Content-Encoding 进行区分Body体使用哪种压缩方式，请求的时候会携带Accept-Encoding来标识支持的压缩方式！ 常见就是 gzip、tr、deflate 压缩，字节内部也有一些压缩率比较高的压缩算法，比如 ttzip 基于zstd优化后的！\nGET /api/test HTTP/1.1Host: localhost:8888Connection: keep-aliveAccept: */*Accept-Encoding: gzip, deflate, brHTTP/1.1 200 OKContent-Encoding: gzipDate: Wed, 11 May 2022 14:39:27 GMTContent-Length: 343...............!...Y..@.....[Z...........b......zP.1&#125;.JjFKw.......g....oO.Z......./.\tOXwJ..S..%.......7...F3.pF.|B.*....E.-o..ObpT2..6J..5.S....0.u.R.&#x27;Ce....,.......&gt;C..(|.8D=.:_...X..$.=....l..1..m.P..s.%.....s....)T.wiyN9_^p.|la@.D/.t.@.&gt;...._/$..=Sz&#125;k.O.......Al..m...j......M..,. ..:g...:.6Q.......T..c..z..jU...u...jWn.J..N.?............\n\n3. Chunked 编码（分块传输）分块编码是HTTP/1.1新增的传输报文格式，响应会携带Transfer-Encoding: chunked，其次响应体是不会有content-length的，因为chunked编码长度部分记录在一个 16进制编码单独的文本行上，然后再写响应内容，如果仍然有内容继续重复操作即可！终止符是 0\\r\\n\\r\\n！下图是chunked编码的抓包图，其中12其实表示0x12也就是为十进制的18!\n\n使用场景:  其中分块编码可以节约用户首屏加载时间，先加载一部分渲染！实际业务中可以做一些 实时进度条展示、日志展示、流式拉取、大文件传输等！比如抖音的首屏预测方案就是基于chunked编码实现的，具体可以看文章尾部的参考文章！\n注意1:  假如你使用Go语言默认HTTP Server，当响应体大于2KB的时候就会默认升级为 chunked 编码！你也可以手动添加响应header Transfer-Encoding: chunked!\n注意2：对于L7 Proxy来说，chunked编码处理不得当很可能造成业务的OOM，所以可以参考一些chunked包转发和抓取的优化手段，尽可能的降低内存拷贝次数和维护的buffer大小！\n上面第二、第三节讲完了，可以发现会存在两个Header， Content-Encoding 和 Transfer-Encoding， 这里可以根据句面意思，可以知道 Content-Encoding 是表示内容编码格式，Transfer-Encoding 表示传输格式！ 两者是可以同时使用的！\n3. 客户端优化手段1. 合并资源合并资源这个我理解大部分都或多多少的了解过，因为请求3个资源的耗时一般都会大于合并成一个资源的请求耗时！例如前端也有很多静态资源（js/css）的打包工具，比如webpack、gulp 等资源合并工具！其次一些小的Image可以使用精灵图！\n这个东西有利也有弊端，比如我原来20个文件，合并成了一个，我改动一个，那么全部资源都是需要重新reload，浏览器缓存的效果就丢失了，不过这个目前也有解决方案！\n\n2. 域名分片浏览器其实有同域名请求的最大并发数限制，例如主流的浏览器Chrome 其实会对于同域名下最大并发数限制在6个！\n\n域名分片就是讲一个域名划分为多个，比如 www.google.com,  www.gstatic.com, 这样就可以很好的解决浏览器的限制！\n3. 管道化下图是使用管道化和未使用的差别，可以发现他可以解决http/1.x 请求阻塞，但是并不能解决响应阻塞的问题！这个主要还是由于服务端HTTP请求处理是串行的！注意只有支持幂等的请求且开启keep-alive才会支持管道化！其次这个技术主要在浏览器侧实现！但是由于keep-alive持久连接实现上并不可靠，所以管道化也需要支持重试等，所以这也就是为什么只允许幂等请求了！\n\n4. 长连接​        这个放在这里，感觉也不合理，主要是目前也存在这种场景，比如在线编辑、在线聊天等一些在线软件对于实时性要求比较高，轮训的话也不太好，因为HTTP建连开销比较大，其次对于服务器压力也比较大，所以在这条路上诞生了很多的技术，这里我们这里就简单介绍下WebSocket！\n  WebSocket是HTML5开始提供的一种在单个TCP连接上进行全双工通讯的协议，位于OSI模型的应用层。WebSocket协议在2008年诞生，于2011年由IETF标准化为 [RFC 6455](https://tools.ietf.org/html/rfc6455) ，后由 [RFC 7936](https://tools.ietf.org/html/rfc7936) 补充规范。\n\n注意：WebSocket 和 HTTP同为应用层协议！WebSocket是利用HTTP协议进握手的！\n\nHTTPS这个并不是HTTP协议，只是在HTTP发展路上遇到的问题，随着互联网发展，越来越多的人注意到数据安全，比如用户敏感信息需要加密，一些恶意软件的攻击，以及恶意拦截等！所以HTTPS就诞生了！这里我们只是引入而已，不会深入讲解！HTTPS（Hypertext Transfer Protocol Secure） 是 HTTP  协议外面包裹了一层 TLS/SSL！\nSSL（Secure Sockets Layer，安全套接字层），它是由网景公司(Netscape)设计的主要用于Web的安全传输协议，目的是为网络通信提供机密性、认证性及数据完整性保障。如今，SSL已经成为互联网保密通信的工业标准。SSL最初的几个版本(SSL 1.0、SSL2.0、SSL 3.0)由网景公司设计和维护，从3.1版本开始，SSL协议由因特网工程任务小组(IETF)正式接管，并更名为TLS(Transport Layer Security)，发展至今已有TLS 1.0、TLS1.1、TLS1.2、TLS1.3 这几个版本。\n如TLS名字所说，SSL/TLS协议仅保障传输层安全。同时，由于协议自身特性(数字证书机制)，SSL/TLS不能被用于保护多跳(multi-hop)端到端通信，而只能保护点到点通信。\nSSL/TLS发展历程如下图：\n\n\n\n\n协议\n使用情况\n\n\n\nSSLv3.0以下\n有安全问题，且已被废弃，不建议使用\n\n\nTLSv1.0/v1.1\n过渡版本，不建议使用\n\n\nTLSv1.2\n目前绝大多数都在使用\n\n\nTLSv1.3\n最新的更快更安全的协议（变更最大的一次协议，可以实现1RTT）\n\n\n其次TLS加解密会非常的消耗CPU，其次加密也会额外消耗带宽，不过主要开销都在TLS握手这块，因为现在主流CPU都会对常见加密算法做硬件加速，所以传输过程中数据包这块开销不大！目前一般内网都会卸载掉TLS！其次TLS握手过程也会很长，主要包含证书认证和确认加密算法！其中TLS发展过程中也经历了不断的迭代，发展方向主要是为了更加安全、效率更高！下图是现在主流TLSv1.2的握手流程，相比于裸TCP，会多两倍的时间开销！\n\n注: TLS握手中很多流程是可选的，上图并不完全正确，其次就是还会分为全完握手和简化握手！\n对于TLS来说也是一个协议规范，具体我们在使用的过程中需要在应用程序中设置或者需要程序来支持！常见开源实现主要有  OpenSSL（主流）、JSSE（Java版实现）、NSS（浏览器中广泛使用），下图是些常见软件以及它们所使用的SSL/TLS开源实现的情况！对于安全（TLS/SSL）来说也是不断在进步中，同时也有漏洞不断挖出！\n\nHTTP/2  &amp; HTTP/3随着近20年来互联网的高速发展，页面愈加复杂，有些甚至演变成了独立的应用，一个页面会加载大量的资源，增进交互的脚本大小也增加了许多，更多的数据通过HTTP请求被传输。HTTP/1.1链接需要请求以正确的顺序发送，理论上可以用一些并行的链接，带来的成本和复杂性堪忧。比如，HTTP管线化（pipelining）就成为了Web开发的负担。\n在2009年到2015年，谷歌通过实践了一个实验性的SPDY协议（2011年Google的全部服务就添加了SPDY），证明了一个在客户端和服务器端交换数据的另类方式。其收集了浏览器和服务器端的开发者的焦点问题。明确了响应数量的增加和解决复杂的数据传输，SPDY成为了HTTP/2协议的基础。在2015年5月HTTP/2正式标准化后，取得了极大的成功！目前来看SPDY已经完全被HTTP/2所取代！然后Google其实早起已经对于TCP做了优化，叫做QUIC，所以就考虑把HTTP运行在QUIC上，于是诞生了后面的HTTP/3！\nHTTP/2 相比HTTP/1.1 比较最大的特点就是多路复用，有点类似于我们web server由HTTP服务升级为RPC服务，带来的提升！从浏览器视角看的话，下图是169张图渲染一张图浏览器加载的耗时，结果是HTTP/2 为1.53s， HTTP1.1为 2.47s！\n\nHTTP/2 介绍主要特性\n\n二进制协议 (frame帧)\n多路复用 (stream 流)\n流量控制\n数据流优先级\n首部压缩（HPACK）\n服务端推送 （Push）\n\n虽然有这么多特性，对于HTTP的语义来说，其实并没有太大的变更！\n理解流对于HTTP/1.x协议来说一个连接上的请求、响应是串行的处理，但是HTTP/2引入流的概念，把请求、响应的过程抽象成流，一个连接上可以有多个流，把数据包抽象成帧，帧在建立的连接上传输！\n一个流的生命周期只是一次请求、响应，不存在复用（即另外一个请求不能复用之前的流，关闭即销毁），具体可以看流的生成周期！\n\n流的生命周期\n下图是一个状态机，对于一个普通的请求、响应来说，一般经历有四个阶段\n\n\n空闲(idle): 这里可以理解为初始化一个stream后的状态，这个状态可以理解为很短！\n开启(open) : 当客户端开始写header的时候（包含服务端读header），会流转到这个状态！ 这里也就是\n半关闭状态(half closed): 客户端写完数据，发送END_STREAM   flags时（写完请求时）就会变成这个状态，此时客户端的流不能再写数据！对于服务端而言就是收到客户端发送的END_STREAM flags，就处于此状态！\n关闭(closed): 对于客户端而言，收到服务端响应发来的END_STREAM 会变为此状态；对于服务器而言发送END_STREAM 也会变为此状态！\n\n\n只要客户端、服务端发送或者接收到 RST_STREAM 帧时就会直接变为 closed 状态！\n对于服务端推送来说我们后文会讲到！\nGRPC双向流（stream msg）实现原理其实也就是一个普通的请求、响应模型，根据上面四个阶段也能大概了解它是如何实现的！即客户端发完请求并没有直接发送 END_STREAM，而是一直处于open状态，且服务端也是！只有客户端/服务端主动关闭才可以关闭stream，或者双方通过自定义协议约定才可以！\n\n                         +--------+                 send PP |        | recv PP                ,--------|  idle  |--------.               /         |        |         \\              v          +--------+          v       +----------+          |           +----------+       |          |          | send H /  |          |,------| reserved |          | recv H    | reserved |------.|      | (local)  |          |           | (remote) |      ||      +----------+          v           +----------+      ||          |             +--------+             |          ||          |     recv ES |        | send ES     |          ||   send H |     ,-------|  open  |-------.     | recv H   ||          |    /        |        |        \\    |          ||          v   v         +--------+         v   v          ||      +----------+          |           +----------+      ||      |   half   |          |           |   half   |      ||      |  closed  |          | send R /  |  closed  |      ||      | (remote) |          | recv R    | (local)  |      ||      +----------+          |           +----------+      ||           |                |                 |           ||           | send ES /      |       recv ES / |           ||           | send R /       v        send R / |           ||           | recv R     +--------+   recv R   |           || send R /  `-----------&gt;|        |&lt;-----------&#x27;  send R / || recv R                 | closed |               recv R   |`-----------------------&gt;|        |&lt;----------------------&#x27;                         +--------+   send:   endpoint sends this frame   recv:   endpoint receives this frame   H:  HEADERS frame (with implied CONTINUATIONs)   PP: PUSH_PROMISE frame (with implied CONTINUATIONs)   ES: END_STREAM flag   R:  RST_STREAM frame\n\n如何建立HTTP/2连接首先建立连接需要客户端和服务端都支持HTTP/2协议，才可以使用HTTP/2！\n使用HTTPS协商 (h2)例如下面这个curl 请求其实是模拟了一个使用HTTPS发送HTTP/2 协议的请求\n➜  ~ curl --http2 https://www.toutiao.com/ -v -o s/dev/null*   Trying 240e:b1:9801:407:3::3f6:443...* Connected to www.toutiao.com (240e:b1:9801:407:3::3f6) port 443 (#0)* ALPN, offering h2* ALPN, offering http/1.1* successfully set certificate verify locations:*  CAfile: /etc/ssl/cert.pem*  CApath: none* TLSv1.2 (OUT), TLS handshake, Client hello (1):* TLSv1.2 (IN), TLS handshake, Server hello (2):* TLSv1.2 (IN), TLS handshake, Certificate (11):* TLSv1.2 (IN), TLS handshake, Server key exchange (12):* TLSv1.2 (IN), TLS handshake, Server finished (14):* TLSv1.2 (OUT), TLS handshake, Client key exchange (16):* TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1):* TLSv1.2 (OUT), TLS handshake, Finished (20):* TLSv1.2 (IN), TLS change cipher, Change cipher spec (1):* TLSv1.2 (IN), TLS handshake, Finished (20):* SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256* ALPN, server accepted to use h2* Server certificate:*  subject: CN=*.toutiao.com*  start date: Jul 23 00:00:00 2021 GMT*  expire date: Aug 23 23:59:59 2022 GMT*  subjectAltName: host &quot;www.toutiao.com&quot; matched cert&#x27;s &quot;*.toutiao.com&quot;*  issuer: C=US; O=DigiCert Inc; CN=RapidSSL TLS DV RSA Mixed SHA256 2020 CA-1*  SSL certificate verify ok.* Using HTTP2, server supports multi-use* Connection state changed (HTTP/2 confirmed)* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0* Using Stream ID: 1 (easy handle 0x7f7d21011e00)&gt; GET / HTTP/2&gt; Host: www.toutiao.com&gt; user-agent: curl/7.77.0&gt; accept: */*&gt;* Connection state changed (MAX_CONCURRENT_STREAMS == 128)!&lt; HTTP/2 200&lt; server: Tengine&lt; content-type: text/html&lt; content-length: 72772&lt; date: Sun, 15 May 2022 10:30:06 GMT.... \n\n上面我们只需要核心关注\n## ALPN客户端支持列表* ALPN, offering h2* ALPN, offering http/1.1## 服务端选择* ALPN, server accepted to use h2\n\n\n\n这里其实利用了TLS的  ALPN (Application-Layer Protocol Negotiation 应用层协议协商) 扩展字段以及识别 HTTP/2 over TLS ！其中HTTP/2 就是 ALPN 最佳实践！\n其中原理就是ALNP给Client hello 和 Server hello 消息加了个拓展功能，客户端可以来申明我支持的应用层协议（嗨，我支持h2和http/1，你用哪个都行），服务端可以用它来确认在HTTPS协商后的应用层协议（好吧，我们用h2吧）！\n更多ALPN可以参考文章: https://datatracker.ietf.org/doc/html/rfc7301#section-3 ！\n另外其实在 ALPN 协议之前，有一个NPN（Next Protocol Negotiation 下一代协议协商）其实作用和ALPN一样，但是呢过程不一样，其中我这里直接拍照吧，就是它分为三步，选择权利在客户端，其中选择的协议是加密的！所以这么一看其实NPN更加安全可靠！但是想一想增加这几步有必要吗？其实没有必要，所以ALPN成为了规范！\n\n本图片引用自 &lt;HTTP/2 in Action&gt;, 有兴趣可以看一下！\n注意这里有一种情况就是假如服务器不支持HTTP2但是客户端支持，那么根据上面流程选择HTTP/1.1就可以了，例如下面这个图，最后选择的是HTTP/1.1。 \n\n但是还有一种情况就是如果 server hello中不返回ALNP，比如举个例子服务端TLS版本过低不支持ANLP，所以此时目前大部分浏览器做法就是默认降级成HTTP/1.1！具体可以看：https://stackoverflow.com/questions/47758705/http-2-h2-with-no-alpn-support-in-server！\n注意: 上面讲诉的过程是基于TLS/1.2的，其中1.3会有部分差异！\n使用 h2c 协商我们知道HTTP协议是可以做协议协商的，那么h2c的建立流程和这个大同小异！目前h2c的主要使用场景就是后端服务希望HTTP/2来带来性能提升，而且大部分场景也不需要tls加密，所以h2c就诞生了！\n注意h2c 有两种实现，一种是基于HTTP/1.1协议升级，一种就是h2的流程但是移除了tls！\n1. 方式一(HTTP/1.1升级)\n 目前主流浏览器都不支持h2c，所以这个基本上没办法测试，如果想要测试可以看一下我写的测试用例: h2c_example\n\n\n\n浏览器发起请求\n\nGET / HTTP/1.1Host: server.example.comConnection: Upgrade, HTTP2-SettingsUpgrade: h2cHTTP2-Settings: &lt;base64url encoding of HTTP/2 SETTINGS payload&gt;\n\n\n如果服务端支持则会响应如下报文，如果不支持正常返回即可！其中下面可以看到会携带 HTTP/2首帧！这里后面会讲解！\n\nHTTP/1.1 101 Switching ProtocolsConnection: UpgradeUpgrade: h2c[ HTTP/2 connection ...\n\n\n关于 HTTP2-Settings 需要了解HTTP/2涉及到的基本概念，一个核心的就是 SETTTINGS 帧, 必须在建连的时候发送，这个header也就是 SETTTINGS 帧 的内容，理解这个就很简单了，它本质上就是把 SETTTINGS 帧 base64编码了一下！用于发送客户端建立的初始化设置！\n[ HTTP/2 connection ... 后续流程是客户端会先发送连接前奏、但是不需要发送SETTINGS帧了，其他就和h2流程差不多！\n这里我们不能抓包了，所以直接看我写的测试用例输出吧\n\n➜  h2c_client git:(master) ✗ go run main.goHTTP/1.1 101 Switching ProtocolsConnection: UpgradeUpgrade: h2c[FrameHeader SETTINGS len=24][FrameHeader WINDOW_UPDATE len=4][FrameHeader HEADERS flags=END_HEADERS stream=1 len=49][FrameHeader DATA flags=END_STREAM stream=1 len=12][FrameHeader RST_STREAM stream=1 len=4]\n\n2. 方式二(h2c)这种是grpc(without tls)采用的方式，就是我们已经知道对面是HTTP/2服务器了，所以不需要使用h2c那种通过 http/1.1升级为http/2这个流程！它的过程和h2的过程一模一样！ 具体可以自行抓包查看！\n帧介绍下图是一个HTTP2 over https（h2） 的整个流程，可以看到HTTP2 主要包含有几个特殊标识\n\nMagic\nSettings\nWindows_Update\nHeaders\nData\n\n那么我们下面会依次介绍！我们把这些都成为帧，这些帧都有着不同的作用！\n\n如果你用 nghttp2, 可以执行以下命令： nghttp -vo https://www.toutiao.com | more\n连接前奏 （Magic帧）根据上图可以看到在 h2 或者 h2c 升级完成，下面紧接着就跟着一个 连接前奏（客户端向服务端发送的），这个内容是固定的，主要是有24个字节组成，16进制标识法如下，展示成字符串就是 PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n !  \n0000   50 52 49 20 2a 20 48 54 54 50 2f 32 2e 30 0d 0a   PRI * HTTP/2.0..0010   0d 0a 53 4d 0d 0a 0d 0a                           ..SM....\n\n注意: 具体这么设计的原因也是有的，比如向一个不支持HTTP2的服务器（HTTP/1.x）接收到这个报文，是可以正常解析为HTTP请求报文的，如果不支持就直接返回异常不支持了！\n帧格式介绍Magic帧紧跟着就是 SETTINGS 帧了, 下图就是一个HTTP SETTINGS 帧的报文。在这里我们先补充体下帧的报文格式，也方便后续的理解！这也就是为什么HTTP/2是二进制协议了，同时也能避免HTTP/1.x协议通过纯文本等进行协议分帧的尴尬了！\n\n帧报文如下：\n# 帧格式, 头部固定9字节, 所以 9+ bytes:+-----------------------------------------------+|                 Length (24)                   |+---------------+---------------+---------------+|   Type (8)    |   Flags (8)   |+-+-------------+---------------+-------------------------------+|R|                 Stream Identifier (31)                      |+=+=============================================================+|                   Frame Payload (0...)                      ...+---------------------------------------------------------------+\n\n\nLength: 固定为3字节，所以帧最大长度为 1 &lt;&lt; 24 -1 ， 注意这个长度=len(frame_content)\nType: 即帧的类型，主要分为以下几种，例如 SETTINGS帧就是 0x04，其中这个类型目前仍然在不断拓展中！常见的就是这9种！\n\n+---------------+------+--------------+| Frame Type    | Code | Section      |+---------------+------+--------------+| DATA          | 0x0  | Section 6.1  || HEADERS       | 0x1  | Section 6.2  || PRIORITY      | 0x2  | Section 6.3  || RST_STREAM    | 0x3  | Section 6.4  || SETTINGS      | 0x4  | Section 6.5  || PUSH_PROMISE  | 0x5  | Section 6.6  || PING          | 0x6  | Section 6.7  || GOAWAY        | 0x7  | Section 6.8  || WINDOW_UPDATE | 0x8  | Section 6.9  || CONTINUATION  | 0x9  | Section 6.10 |+---------------+------+--------------+\n\n\nFlags: 即标志位，这个不太方便理解，你可以理解为 帧的特殊标记！例如 SETTINGS帧 会有一个 ACK Falgs！ 多个falgs通过 bitmap 进行设置！\n\nR: 这个是保留位（reserved bit），占用1bit，必须是0\n\nStream Identifier:  即流ID，占用31bit，为无符号整数！顾名思义和RPC的seq id 很像！这里注意客户端发起的stream_id必须为奇数，服务端发起的为偶数！例如上面那个case，客户端发起的stream_id=13!  \n\nFrame Payload 即 payload，允许为空！\n\n\nSETTINGS 帧在建立请求过程中，Magic帧后面就会立马跟一个SETTINGS 帧！如下图，这个帧主要作用就是为了初始化连接的配置信息！\n\n其中SETTINGS 帧就是一对对KV组成，如下图，多个KV的话，顺序写即可！\n+-------------------------------+|       Identifier (16)         |+-------------------------------+-------------------------------+|                        Value (32)                             |+---------------------------------------------------------------+\n\n\nIdentifier：标识符，主要分为以下几类，可以理解为key \n\nSETTINGS_HEADER_TABLE_SIZE (0x1): 设置HPACK中动态表的大小，默认是4096个字节SETTINGS_ENABLE_PUSH (0x2): 是否允许服务端推送，默认为0表示关闭，1表示开启SETTINGS_MAX_CONCURRENT_STREAMS (0x3): 表示一个连接上最大的并发数量，无默认值，例如头条主站就是设置的128SETTINGS_INITIAL_WINDOW_SIZE (0x4): 初始化窗口的大小，用于流量控制，默认值是65535, 最大为 2&lt;&lt;31 - 1SETTINGS_MAX_FRAME_SIZE (0x5): 最大的帧大小，默认值是 16384，最大为2&lt;&lt;24 - 1SETTINGS_MAX_HEADER_LIST_SIZE (0x6): 这里表示请求header的最大长度\n\n\nValue： 值，四个字节，都是int值\n\n注意：\n\n如果一个端需要发起设置，那么它需要标记 falgs Ack=0, 然后携带上配置，另外一端接收后会响应一个falgs Ack=1，且 payload 为空！ 例如下面流程：\n\n## 收到settings帧[  0.083] recv SETTINGS frame &lt;length=18, flags=0x00, stream_id=0&gt;          (niv=3)          [SETTINGS_MAX_CONCURRENT_STREAMS(0x03):128]          [SETTINGS_INITIAL_WINDOW_SIZE(0x04):65536]          [SETTINGS_MAX_FRAME_SIZE(0x05):16777215]## 发送ack帧          [  0.083] send SETTINGS frame &lt;length=0, flags=0x01, stream_id=0&gt;          ; ACK          (niv=0)\n\n\nSETTINGS 帧的 stream_id 固定为0 ！\n\nWINDOW_UPDATE 帧 （流量控制）WINDOW_UPDATE 帧 主要是用于流量控制（Flow Control），这个名词在TCP也有！不过 HTTP/1.x 并未包含流控机制，依靠 TCP 的流控也工作得很好，那为什么 HTTP/2 需要添加呢？原因很明显，因为 HTTP/2 引入了 stream（流） 和 multiplexing(多路复用) ，想让众多 stream 协同工作，就需要一种控制机制，防止某个流阻塞其他流！\n具体原理如下：sender发送数据会降低窗口大小，需要receiver方通知sender来恢复窗口，这就需要WINDOW_UPDATE 帧 了!  其中流控算法官方并没有提出实现规范！注意 sender 指的数据发送方（可以是server、也可以是client）。 整体总结就是：接收者来提供控制！\n\n具体HTTP/2如何实现流控的，主要是由于HTTP/2 的流控分为了两类，stream flow-control window(sfw) 和 connection flow-control window (cfw)， 其中每个stream会维护自己的sfw，所有的stream共用一个cfw ！发送多少包窗口就减少多少，cfw和sfw都会减少！那么增加呢是单独增加！要么是cfw、要么是sfw！其次cfw、sfw只针对于DATA帧的内容！\n例如：GRPC中在当接收的包的总大小(自己做的receive flow-control)大于cfw/sfw大小的1/4的时候，就会发送window_update帧，然后重置receive size，或者发送PING包的时候也会携带发送window_update 帧！具体逻辑可以看: sender逻辑 、  server 端receiver逻辑 、 client receiver逻辑，有兴趣的可以看一下！目前HTTP/2应用比较广泛的应该是GRPC、Nginx(L7)、浏览器！\nWINDOW_UPDATE帧 协议包比较简单，主要就是传输Window Size Increment，这个值是增加cfw  or sfw的大小！ 如果调整 sfw则需要传递 stream_id ！\n+-+-------------------------------------------------------------+|R|              Window Size Increment (31)                     |+-+-------------------------------------------------------------+\n\n说到这里，可能还得知道，初始化窗口： 当一个连接初始化的时候，sfw和cfw都是65535，如果需要调整sfw 的初始化窗口大小则需要需要发送Setting帧 （这个是针对所有stream），如果需要调整cfw大小（所以初始化时候cfw一定是65535）需要发送window_update帧!\nHEADERS 帧一个HTTP/2 请求从 HEADERS 帧 开始发送的！例如这个是一个HTTP/2 Headers 帧的抓包图：\n\n其中header的编码比较复杂，后续我们会讲解HPACK，所以这里只要知道有这个header帧主要包含哪些内容即可！\n+---------------+|Pad Length? (8)|+-+-------------+-----------------------------------------------+|E|                 Stream Dependency? (31)                     |+-+-------------+-----------------------------------------------+|  Weight? (8)  |+-+-------------+-----------------------------------------------+|                   Header Block Fragment (*)                 ...+---------------------------------------------------------------+|                           Padding (*)                       ...+---------------------------------------------------------------+\n\n\nPad Length： 表示尾部Padding的长度，为可选字段（注意标记?的为可选字段）\nE：1bit，表示当前流是否排他的 (与 PRIORITY 帧有关)\nStream Dependency： 表示依赖于哪个流  (与 PRIORITY 帧有关)\nWeight：流的权重  (与 PRIORITY 帧有关)\nHeader Block Fragment： 请求的首部，使用HPACK编码\nPadding：补齐内容，用0填充\n\n例如报文如下：\n0000   00 00 1f 01 05 00 00 00 01 82 84 87 41 8b f1 e3   ............A...0010   c2 f3 1c f3 50 55 c8 7a 7f 7a 88 25 b6 50 c3 ab   ....PU.z.z.%.P..0020   ba ea e0 53 03 2a 2f 2a                           ...S.*/*\n\n\n00 00 1f 01 05 00 00 00 01:  前9个字段为Frame的头部，payload长度为31，为Headers帧，flag为5，stream_id=1\n其中后面31个字节就是头部的header内容了， 这里采用了 HPACK 编码！所以需要了解下HPACK编码，这里也能看出来下文是Header的内容，一共是100个字节，但是使用HPACK编码后只占用了31个字节！ 整整节约了70%的编码！\n\n:method: GET:path: /:scheme: https:authority: www.google.comuser-agent: curl/7.77.0accept: */*\n\n这里我们要解码者31个字节需要直接跳转到 HPACK那一节吧！\n注意：\n\nHTTP/2 和 HTTP/1.x 协议有些header是不兼容的，比如Keep-Alive 和 Connection 等在HTTP/2中直接没有！\nHTTP的header是支持 header: v1;v2表示多个 ，同时也支持 header: k1,header:k2 ，在HTTP/2中在编码的时候会使用后者！同时header name推荐全部小写（看完HPACK就会理解）！\n\nDATA 帧data帧对应着 HTTP的Body，如果没有响应体的话是不需要传输的！\n+---------------+|Pad Length? (8)|+---------------+-----------------------------------------------+|                            Data (*)                         ...+---------------------------------------------------------------+|                           Padding (*)                       ...+---------------------------------------------------------------+\n\n\nPad Length： 表示padding长度， 只有存在 PADDED flags才有这个值！\nData： 真正的数据\nPadding : 表示padding数据，并没有强制的padding算法，也就是你发出的数据可以不padding！\n\n这里 DATA 帧会有两个标识，一个是 END_STREAM 、一个是 PADDED\nHPACK 编码我们知道HTTP/1.x其实可以对Body部分进行压缩，但是头部部分是无法压缩的！所以HTTP/2中引入了HPACK 主要是用来压缩HTTP的头部的，主要是采用静态表+动态表+压缩算法组成！然后就是HTTP/2中把请求行/响应行部分移到了全部转移到了Header部分！对照关系是:\nmethod -&gt; :methodpath -&gt; :pathstatus -&gt; :status\n\n静态表静态表（Static Table），一共61对，应该很好理解，比如 method=GET，那么会把它转换成一个数字，例如:authority=www.google.com 会转换一个数字 + 字符串（不一定）！\n+-------+-----------------------------+---------------+| Index | Header Name                 | Header Value  |+-------+-----------------------------+---------------+| 1     | :authority                  |               || 2     | :method                     | GET           || 3     | :method                     | POST          || 4     | :path                       | /             || 5     | :path                       | /index.html   || 6     | :scheme                     | http          || 7     | :scheme                     | https         || 8     | :status                     | 200           || 9     | :status                     | 204           || 10    | :status                     | 206           || 11    | :status                     | 304           || 12    | :status                     | 400           || 13    | :status                     | 404           || 14    | :status                     | 500           || 15    | accept-charset              |               || 16    | accept-encoding             | gzip, deflate || 17    | accept-language             |               |............| 58    | user-agent                  |               || 59    | vary                        |               || 60    | via                         |               || 61    | www-authenticate            |               |+-------+-----------------------------+---------------+\n\n注意：这里虽然没有:method  且 Header Value 为空的这种情况，其实实际处理的时候:method=Delete 这种实际上 :method会编码为3，如果没有则取key相同最大的index！\n动态表动态表(Header Table)，顾名思义就是动态生成表，然后最终形式上和上面静态表差不多！它的生命周期是一个连接上（注意一个连接可以有多个请求/响应）！\n由于动态表时动态生成的，那么对于单机维护的连接数过多，此时动态表会很占内存，假如此时我们不进行内存限制，很容易被攻击导致内存OOM，那么所以动态表会有一个大小限制，可以通过 SETTINGS 帧下发HEADER_TABLE_SIZE=4096, 单位是字节，来实现动态表内存限制！那么一个Header的Key和Value的大小是多少了？计算公式是 len(key)+len(value)+32  , 为什么加32了，是因为大部分语言，存储string会额外消耗16字节用来存储数组指针和数组长度！\n那么假如动态表在我们写header的时候，发现大小超出了 HEADER_TABLE_SIZE 怎么办了，具体算法就是个FIFO模型，队列大小确定，所以大概流程就是下面这个：\n// 请求1// set max_size=32 + 4 + 32 + 4 + 32 + 4 + 32// 计算index(key,value)公式 = arr_index(key,value) + 61 + 1addHeader(&quot;k1&quot;, &quot;v1&quot;) // write k1-v1, arr=[k1-v1]addHeader(&quot;k2&quot;, &quot;v2&quot;) // write k2-v2, arr=[k2-v2, k1-v1]addHeader(&quot;k3&quot;, &quot;v3&quot;) // write k3-v3, arr=[k3-v3, k2-v2, k1-v1]addHeader(&quot;k4&quot;, &quot;v4&quot;) // write k4-v4, arr=[k4-v4, k3-v3, k2-v2]// 请求2addHeader(&quot;k3&quot;, &quot;v3&quot;) // write index=63addHeader(&quot;k1&quot;, &quot;v1&quot;) // write k1-v1, arr=[k1-v1, k4-v4, k3-v3]addHeader(&quot;k3&quot;, &quot;v3&quot;) // write index=64addHeader(&quot;k4&quot;, &quot;v4&quot;) // write index=63addHeader(&quot;k1&quot;, &quot;v1&quot;) // write index=62\n\n编码在HTTP/2中编码采用的算法主要是 varint编码 和  霍夫曼编码 （Huffman Coding 也叫做哈夫曼编码）\n概念：\n\nvarint 编码是数字压缩算法中常见的一种，主要是采用变长来存储数字，比如虽然值定义的是8字节，但是比如数字1可以用1个字节进行编码，主要原理就是利用 msb (the Most Significant Bit 最高有效位)!\n霍夫曼编码是文本压缩算法中常见的一种，是基于字符出现的次数为权重（墒编码）进行的构建字典，进而构建霍夫曼树，然后根据霍夫曼树来确定字符的二进制编码。但是如果字符不重复，且字符还很多，导致霍夫曼树很深，那么霍夫曼编码的意义就不大了！\n\n注意:\n\nHTTP/2 中采用的 varint 编码并不是标准的，因为他需要根据低位第一个字节标记falg, 所以解决思路就是减去第一个字节定义的最大值（区间是 1 到 1&lt;&lt;7-1），剩余的值用的varint编码，具体可以参考: https://datatracker.ietf.org/doc/html/rfc7541#section-5.1， 伪代码如下: \n\n# 伪代码if num &lt; max&#123;\t return num&#125;[Max,varint(num-max) ...]# case: # 例如max=1&lt;&lt;7-1, num=126(0b01111110), 那么输出 [0x7e]# 例如max=1&lt;&lt;7-1, num=127(0b01111111)，那么输出 [0x7f, 0x00]# 例如max=1&lt;&lt;7-1, num=127+128(0b10000000), 那么输出 [0x7f, 0x80, 0x01]# 下文中叫 (7+)varint 表示max=1&lt;&lt;7-1 也就是上面这个case, 例如(6+)varint 表示max=1&lt;&lt;6-1\n\n\nHTTP/2 中采用的 霍夫曼编码也不是按照标准的，它采用的是静态表，也就是它省去了动态生成霍夫曼树的过程（省略计算过程和Map过程），这个树就是个静态的！具体可以参考: https://datatracker.ietf.org/doc/html/rfc7541#section-5.2 !\n\n1. Indexed Header Field Representation采用这边编码情况是： header 的 key和value 都在中，然后可以拿到index（动态表index=静态表index+偏移量），比如method: GET\n+---+---+---+---+---+---+---+---+| 1 |        Index (7+)         |+---+---------------------------+\n\n\n1：标识符号，varint编码后第一个字节的高位8bit标识符是1\nindex (7+):  表示index值，采用 (7+)varint 算法\n\n2.1 Literal Header Field with Incremental Indexing - indexed Name表示:  name 在表中，value 不在表中，且需要添加到表中，比如 Host: www.google.com\n  0   1   2   3   4   5   6   7+---+---+---+---+---+---+---+---+| 0 | 1 |      Index (6+)       |+---+---+-----------------------+| H |     Value Length (7+)     |+---+---------------------------+| Value String (Length octets)  |+-------------------------------+\n\n\n01+ Index (6+) ，为index编码，主要是为了区分上面Indexed Header Field Representation 的case\nH： 为Value String 是否采用霍夫曼编码编码，H=1 表示采用霍夫曼编码\nValue Length(7+): 表示value string的长度，具体算法就是 (7+)varint  算法\nValue String：霍夫曼编码 or 原值\n\n2.2  Literal Header Field with Incremental Indexing - New Name表示： name 不在表中，value也不在表中，但是需要添加到表中！例如自定义header  X-Host: www.google.com，且我们允许 name 和 value 添加到表中！\n  0   1   2   3   4   5   6   7+---+---+---+---+---+---+---+---+| 0 | 1 |           0           |+---+---+-----------------------+| H |     Name Length (7+)      |+---+---------------------------+|  Name String (Length octets)  |+---+---------------------------+| H |     Value Length (7+)     |+---+---------------------------+| Value String (Length octets)  |+-------------------------------+\n\n这里我就不过多讲解了，通过上面的两个讲解，应该大家都有所了解！这个也就是第一个字节一定是 0x40\n3.1 Literal Header Field without （Never） Indexing - Indexed Name和上面的Literal Header Field with Incremental Indexing - indexed Name 的区别在于，这个不需要被添加到表中！\n其次就是 Literal Header Field without Indexing 和 Literal Header Field Never Indexing  主要区别在于首字节，前者是 0000xxxx，后者是0001xxxx！\n  0   1   2   3   4   5   6   7+---+---+---+---+---+---+---+---+| 0 | 0 | 0 | 0 |  Index (4+)   |+---+---+-----------------------+| H |     Value Length (7+)     |+---+---------------------------+| Value String (Length octets)  |+-------------------------------+\n\n3.2 Literal Header Field without（Never） Indexing - New Name和上面的Literal Header Field with Incremental Indexing - indexed Name 的区别在于，这个不需要被添加到表中！\n\t0   1   2   3   4   5   6   7+---+---+---+---+---+---+---+---+| 0 | 0 | 0 | 0 |       0       |+---+---+-----------------------+| H |     Name Length (7+)      |+---+---------------------------+|  Name String (Length octets)  |+---+---------------------------+| H |     Value Length (7+)     |+---+---------------------------+| Value String (Length octets)  |+-------------------------------+\n\n4. Dynamic Table Size Update我们知道 SETTINGS帧的 SETTINGS_HEADER_TABLE_SIZE 也是设置 tables size大小的，那么这个作用是什么？它的含义就是动态变更 size，但是这个max size 必须小于或者等于 SETTINGS_HEADER_TABLE_SIZE！\n0   1   2   3   4   5   6   7+---+---+---+---+---+---+---+---+| 0 | 0 | 1 |   Max size (5+)   |+---+---------------------------+\n\n5. 总结注意关于 Literal Header Field without Indexing 和 Literal Header Field Never Indexing   的区别在于哪里了？官方的解释差别就一句话  Intermediaries MUST use the same representation for encoding this header field., 意思就是假如我们请求中间有个HTTP/2代理（例如 nginx），那么如果是Never Indexed 那么代理也必须原封不动的转发 !\n但是目前看Nginx并不支持后端服务(up stream)是HTTP/2协议，只支持GRPC（注意GRPC处理模块可以处理一些通用的HTTP/2协议的请求，但是支持度并不好）！具体可以参考 https://trac.nginx.org/nginx/ticket/923 !\n服务器推送 PUSH_PROMISE首先要明白，HTTP/2为什么会有服务端推送，比如我们一个普通的加载网页的流程，会返回网页，然后再起请求一些静态资源，所以浏览器的整个流程是下面这个流程如下图左侧！但是如果有服务端推送的话后续加载n次资源就会减少n次RTT的时间，如下图右侧！那么HTTP/2是如何实现服务端推送的呢？\n\n首先在讲下面我们需要先说明一个问题：如果实现上面的功能，我们需要告诉浏览器要推送哪些资源，不然我们先返回html浏览器就渲染html直接发起请求加载静态文件了，那么我们推送就白做了，所以这里需要知道是哪个流发起的加载html的请求，然后通过这个流告诉浏览器我们要下发给你哪些资源在返回HTML之前！\n# 服务器推送从源服务器的 Link 标头的 rel=preload 参数提取 URI 引用，然后将这些额外 URI 提供给客户端Link: &lt;/images/image.png&gt;;rel=preload;Link: &lt;/css/main.css&gt;;rel=preload;\n\nPUSH_PROMISE 帧是服务器发起的请求，所以这里的stream_id是偶数！\n+---------------+|Pad Length? (8)|+-+-------------+-----------------------------------------------+|R|                  Promised Stream ID (31)                    |+-+-----------------------------+-------------------------------+|                   Header Block Fragment (*)                 ...+---------------------------------------------------------------+|                           Padding (*)                       ...+---------------------------------------------------------------+\n\n\nR: 保留位\nPromised Stream ID: 这个就是上面讲到的，其实就是Push stream id（承诺要发送的stream ID）\nHeader Block Fragment： 请求header，其实就是把推送的请求体发送过去了！\n\n注意：由于推送会涉及到幂等、安全等问题，所以一般就是推送静态资源！\n服务器推送的整体流程还是很简单，就是响应HTML之前发送 PUSH_PROMISE 帧，这个帧会携带push资源的请求内容！然后返回HTML，然后再用Promised Stream ID 写响应关闭流即可！\n服务端推送相比于HTTP/2不推送，前端页面整体的提升率大约在8%左右，具体可以看相关测评 ，同时开启后也会存在一定浪费带宽的问题，那就是假如浏览器有缓存不就不用返回了！目前主流的架构都是将静态资源基本放在CDN上，所以如果需要使用服务端推送，需要确定CDN厂商是否支持！\n下图来自于又拍云关于DNS 服务端推送相关的页面，具体可以点击链接查看：\n\nHTTP/3 介绍​    通过学习上面我们发现HTTP/2其实做了很多的优化，在整个传输层，不仅降低了数据包的大小，同时流和多路复用降低了连接上的开销，提高了页面的加载速度！但是这种优化也是有弊端的！现在移动互联网比较普及，大部分流量都来自于移动设备，而移动设备最大的特点就是网络问题！而HTTP/2依赖于TCP，在网络不稳定的情况下，TCP的流控会导致HTTP/2变慢，如果发生丢包，就会导致HoL (Head of Line Blocking 头部阻塞)， 导致一个连接上所有的流都需要等待！\n​    因此作为HTTP/2前身SPDY的发明者Google，毕竟走的路比较长，所以也提出了比较好的解决思路，那就是把TCP替换掉，随后就诞生了QUIC！QUIC ( Quick UDP Internet Connection) 是 Google 研发的一种基于 UDP 协议的低时延互联网传输协议。在2018年IETF会议中（主要原因还是TLS v1.3同年正式发布），HTTP-over-QUIC协议被重命名为HTTP/3，并成为 HTTP 协议的第三个正式版本，大概的关系就是： 运行在 QUIC 之上的 HTTP 协议被称为 HTTP/3！\n**QUIC 是传输层协议(4层协议)**，其中quic有两个版本一个是Google的叫做gquic, 另一种就是标准的 quic，注意两者差别还是蛮大的！其次QUIC也提供了如何使用TLS，有兴趣的可以看下QUIC 介绍，QUIC[RFC 8999-9002]，以及 TLS1.3[RFC 8446]，下图是一个大概的一个模型图：\n\n由于本文前面篇幅有点长了，而且从HTTP发展历史也可以看得出来会越来越复杂，所以如果有兴趣的想深入了解的可以查阅相关资料，上面已经提供了很多了，下面就列出来了QUIC的几大特点：\n\n降低了建连时间（注意a为TLS完全握手，b为TLS简化握手，可以实现0RTT 握手）\n\n\n\n根据第三方数据使用QUIC 0RTT率大约在55%左右，具体可以点击文章查看详情！\n\n\n提出了新的流量控制算法，提出了新的概念连接ID\n优化了拥塞控制算法（其实和TCP用的是一样的都是Cubic算法），好在QUIC走在用户态，好修改！\n用户态协议，不需要升级or修改内核，升级迭代容易\n\n目前外部对于QUIC的实现也比较多，比如字节的TTQUIC，快手的KQUIC, 以及微软的 msquic  。但是目前来看QUIC也有很多问题，主要问题还是UDP带来的问题，因为不同运营商会对UDP进行了一定的限制，其次就是多一层用户态协议的开销也是有一定的性能损耗，最后就是目前人们对于TCP优化做的太多了！不过相信这些问题都是可以用时间去解决的，所以QUIC ==? 未来！\n参考文章\nSSL/TLS发展历史和SSLv3.0协议详解\nHTTPS的性能消耗\n深入解读SSL/TLS的实现\nRFC7540\nHTTP2流量控制介绍\n技术干货：HTTP/2 之服务器推送 (Server Push) 最佳实践\n揭秘QUIC的五大特性及外网表现\nTCP流量控制、拥塞控制\nHTTP/3 原理实战\nQUIC with TLS1.3 简介\n\n","categories":["HTTP"],"tags":["HTTP"]},{"title":"关于容器化的思考","url":"/2020/10/06/33ea9e6f1ad28eb266559efefc7ac6a1/","content":"​    我最近半个月内一直在看docker，但是看完后发现，发现它对于我来说只是个cli的工具，cli提供了build，push，pull，run等功能，包含了构建镜像，打包发布，拉取，运行。其实不考虑这些，对于公司级别的cicd工具来说，也是这几个流程，比如说我一个git仓库地址，再通过Jenkins等ci工具构建，构建完成后发布到发布机器上，等我们去发布的时候，就是拉取这个zip包/或者镜像，解压/运行，程序去启动后不在考虑范围内，这个过程是最简单最常见的。\n​    所以docker只是提供了一个工具进行这个流程。换了一种承载方式。换句话说它确定了软件究竟应该通过什么样的方式进行交付。docker的创新就是将交付转变为容器/镜像，解决了开发人员的痛点。\n​    本篇不讨论，定义和管理容器技术的OpenStack &amp; kubernetes &amp; Docker Swarm &amp; Containerd等！\n​    ps：学习这些只是看看自己适不适合学习容器化方向的技术，每一个技术背后的技术都很多，如果只是使用，那么了解即可。为啥要学习容器化技术呢，虽然作为一个后端开发，不需要掌握容器化技术，但是了解只是为了思考和成长！\n\n\n1、什么是容器化容器化是应用程序级别的虚拟化，允许单个内核上有多个独立的用户空间实例（它是一个进程，但是进程内部确实一个完整的运行环境）。这些实例称为容器。\n那么虚拟化是什么？虚拟化是指硬件虚拟化，也就是在操作系统（OS）中创建虚拟机。\n虚拟化：虚拟机监视器（Hypervisor）是安装在物理硬件上的软件层，可以将物理机通过虚拟化分成许多虚拟机。这样多个操作系统可以在一个物理硬件上同时运行。安装在虚拟机上的操作系统称为虚拟操作系统，也称为实例。有虚拟机监视器运行的硬件称为主机。虚拟机管理控制台（也称为虚拟机管理员（VMM））是一种计算机软件，可以轻松管理虚拟机。关于虚拟机的分类：https://www.alibabacloud.com/zh/knowledge/what-is-hypervisor\n关于虚拟机的实现，相关讨论：https://www.zhihu.com/question/20848931 \n\n上图是虚拟机与容器的区别！，详细可以看：https://www.alibabacloud.com/zh/knowledge/difference-between-container-and-virtual-machine ， 可以发现每个虚拟机都有单独的操作系统，而容器是不需要的。但是容器真的不需要单独的操作系统吗，你还记得dockerfile中每一个镜像都需要制定一个运行环境。那么上面这个图是错误的吗？？？\n其实很多人应该注意到，这个链接有解释：https://stackoverflow.com/questions/32841982/how-can-docker-run-distros-with-different-kernels\n\nThere’s no kernel inside a container. Even if you install a kernel, it won’t be loaded when the container starts. The very purpose of a container is to isolate processes without the need to run a new kernel.\n\n容器内没有内核。即使您安装了内核，在容器启动时也不会加载该内核。容器的真正目的是在不运行新内核的情况下隔离进程。\n那么容器实现的技术，这里也不详细展开了，主要是依赖于linux系统本身自带的隔离功能！\n\n\n主要核心就是资源隔离(做到容器互不影响很关键)，使用技术就是 cgroup 对于cpu、memory的限制，以及namespace等，其实这些技术都是操作系统提供的，对于docker的作者也是基于这些进行实现的，所以docker的成功是可能就是机遇吧，而不是docker的技术！！docker公司前身就是个云服务提供商！\n有兴趣可以看看这篇文章：容器发展简史 以及 容器的隔离与限制， Cgroup介绍\n做云原生开发工程师，需要掌握Kubernetes，Docker，Service Mesh等领域相关的知识，并且有实践，交付经验，道阻且长，本人也是兴趣。\n2、容器化发展历史\n​    这一篇主要是介绍，容器化走过这么多年，难道真的是因为docker出生才火的吗，还是时代的趋势！虽然 docker 把容器技术推向了巅峰，但容器技术却不是从 docker 诞生的。\n\n1、容器化发展历史\n1、Chroot Jail就是我们常见的 chroot 命令的用法。它在 1979 年的时候就出现了，被认为是最早的容器化技术之一。它可以把一个进程的文件系统隔离起来。\n2、The FreeBSD JailFreebsd Jail 实现了操作系统级别的虚拟化，它是操作系统级别虚拟化技术的先驱之一。\n3、Linux VServer使用添加到 Linux 内核的系统级别的虚拟化功能实现的专用虚拟服务器。\n4、Solaris Containers它也是操作系统级别的虚拟化技术，专为 X86 和 SPARC 系统设计。Solaris 容器是系统资源控制和通过 “区域” 提供边界隔离的组合。\n5、OpenVZOpenVZ 是一种 Linux 中操作系统级别的虚拟化技术。 它允许创建多个安全隔离的 Linux 容器，即 VPS。\n6、Process ContainersProcess 容器由 Google 的工程师开发，一般被称为 cgroups。\n7、LXC2008年，通过将 Cgroups 的资源管理能力和 Linux Namespace 的视图隔离能力组合在一起，LXC（Linux Container）这样的完整的容器技术出现在了 Linux 内核当中。（0.9一下的低版本的docker就是利用的这个技术！！）\n8、Warden在最初阶段，Warden 使用 LXC 作为容器运行时。 如今已被 CloudFoundy （ VMware 公司于 2011 年宣布了这个项目的开源，第一次对 PaaS 的概念完成了清晰而完整的定义，PaaS 项目通过对应用的直接管理、编排和调度让开发者专注于业务逻辑而非基础设施）取代。\n9、LMCTFYLMCTY 是 Let me contain that for you 的缩写。它是 Google 的容器技术栈的开源版本。Google 的工程师一直在与 docker 的 libertainer 团队合作，并将 libertainer 的核心概念进行抽象并移植到此项目中。该项目的进展不明，估计会被 libcontainer 取代。（0.9以上的高版本的docker就是利用的libcontainer，其实就是对于lxc的封装，用go写的，开发起来比较方便）\n10、Docker\nDocker 是一个可以将应用程序及其依赖打包到几乎可以在任何服务器上运行的容器的工具。（dotCloud公司开源的自己的容器化技术，最后公司直接改名字叫为docker了）\n11、Docker-Swarm\nDocker公司在2014年12月的DockerCon上发布Swarm的举动，你可以很轻松的一个命令，就可以将容器调度在任意一台Swarm集群的机器上。docker的衰败也是因为在容器编排技术之争中跌落神坛的。\n12、Fig\ndocker的大紫大红，后来收购了Fig项目，他可以解决容器之间依赖的问题，也就是当前的docker-compose项目，前身就是Fig。\ndocker成功后，收购了很多好的项目，专门负责处理容器网络的SocketPlane项目，专门负责处理容器存储的Flocker项目，专门给Docker集群做图形化管理界面和对外提供云服务的Tutum项目。\n13、RKTRKT 是 Rocket 的缩写，它是一个专注于安全和开放标准的应用程序容器引擎。（原来docker的合作伙伴CoreOS公司，CoreOS公司自己研发的容器化工具）\n13、终结者Kubernetes\n​    2017年,  基础设施领域的翘楚Google公司突然发力，正式宣告了一个名叫Kubernetes项目的诞生。这个项目，不仅挽救了当时的CoreOS和RedHat，还如同当年Docker项目的横空出世一样，再一次改变了整个容器市场的格局。并将 CNCF 这个以“云原生”为关键词的组织和生态推向了巅峰。\n2、容器化的一些名词其实看到这里，我们发现容器化技术发展了这么多年，技术变更这么快的年代，最可怕的是，我学了一门技术，立马被淘汰了，所以docker也是，为了保障docker的标准化，做出了一系列的努力。\n1、Docker &amp; LXCDocker 的第一个执行环境是 LXC，但从版本 0.9 开始 LXC 被 libcontainer 取代。\n2、Docker &amp; libcontainerLibcontainer 为 docker 封装了 Linux 提供的基础功能，如 cgroups，namespaces，netlink 和 netfilter 等\n3、2015 - Docker ＆ runC\n2015 年，docker 发布了 runC，一个轻量级的跨平台的容器运行时。 这基本上就是一个命令行小工具，可以直接利用 libcontainer 运行容器，而无需通过 docker engine。runC 的目标是使标准容器在任何地方都可用。\n4、Docker &amp; The Open Containers Initiative(OCI)OCI 是一个轻量级的开放式管理架构，由 docker，CoreOS 和容器行业的其他领导厂商于 2015 年建立。它维护一些项目，如 runC ，还有容器运行时规范和镜像规范。OCI 的目的是围绕容器行业制定标准，比如使用 docker 创建的容器可以在任何其他容器引擎上运行。\n5、2016 - Docker &amp; containerd\n2016年，Docker 分拆了 containerd ，并将其捐赠给了社区。将这个组件分解为一个单独的项目，使得 docker 将容器的管理功能移出 docker 的核心引擎并移入一个单独的守护进程(即 containerd)。这个组件的剥离很好的实现了开发者可以以编程的方式管理容器！\n6、Docker Components分拆完 containerd 后，docker 各组件的关系如下图所示：\n\n7、Docker 如何运行一个容器？\n\nDocker 引擎创建容器镜像(oci规范)\n将容器映像传递给 containerd\ncontainerd 调用 containerd-shim\ncontainerd-shim 使用 runC 来运行容器\ncontainerd-shim 允许运行时(本例中为 runC)在启动容器后退出\n\n该模型带来的最大好处是在升级 docker 引擎时不会中断容器的运行。\n8、2017 - 容器成为主流\n2017 年是容器成为主流技术的一年，这就是为什么 docker 在 Linux 之外支持众多平台的原因（Docker for Mac，Docker for Windows，Docker for AWS，GCP 等）。\n当容器技术被大众接受后，Docker 公司意识到需要新的生产模型，这就是为什么它开始 Moby 项目。最为go语言开源项目的top3的项目，一开始我也不知道moby项目是做啥了。。。\n其实可以发现，在这个百花齐放的操作系统平台上，如何不进行case by case，重复造轮子，就是拆分，通用组件，现成的直接使用就行了。moby就是这个\n3、容器化做的一些转变主要还是开源出moby项目，https://github.com/moby/moby\n（1）ContainerdContainerd 是 docker 基于行业标准创建的核心容器运行时。它可以用作 Linux 和 Windows 的守护进程，并管理整个容器生命周期。\n（2）LinuxkitLinuxkit 是 Moby 项目中的另一个组件，它是为容器构建安全、跨平台、精简系统的工具。目前已经支持的本地 hypervisor 有 hyper-v 和 vmware。支持的云平台有 AWS、Azure 等。\n（3）InfrakitInfrakit 也是 Moby 项目的一部分。它是创建和管理声明式、不可变和自我修复基础架构的工具包。Infrakit 旨在自动化基础架构的设置和管理，以支持分布式系统和更高级别的容器编排系统。Infrakit 对于像 Docker Swarm 和 Kubernetes 这样的编排工具或跨越 AWS 等公共云创建自动缩放群集的用例很有用。\n（4）LibnetworkLibnetwork 是用 Go 语言实现的容器网络管理项目。它的目标是定义一个容器网络模型(CNM)，并为应用程序提供一致的编程接口以及网络抽象。这样就可以满足容器网络的 “可组合” 需求。\n（5）Docker &amp; Docker SwarmDocker Swarm 是一个在 docker 引擎中构建的编排工具。从 docker 1.12 开始它就作为一个独立的工具被原生包含在 docker engine 中。我们可以使用 docker cli 通过 docker swarm 创建群集，并部署和管理应用程序和服务。下图描述了 docker swarm 在 docker 体系中的作用(此图来自互联网)：\n（6）Docker＆Kubernetes在 docker swarm 与 kubernetes 的竞争中，显然是 kubernetes 占据了优势。所以 docker 紧急掉头，开始原生的支持与 kubernetes 的集成。这可是 2017 年容器界的一大新闻啊！至此，docker 用户和开发人员可以自由地选择使用 kubernetes 或是 swarm 执行容器的编排工作。我们可以认为 docker 与 kubernetes 联姻了。\n\n文章参考： https://www.cnblogs.com/along21/p/9183609.html\n茫茫的容器化技术，不是一篇文章能说清楚的，理解其本质也不知是说，我了解namespcae和cgropus就能说了解的。\n3、容器化技术解决了什么我想很多公司都在使用云服务商提供的虚拟机，其中资源浪费简直是不能看，基本资源利用率在80-90%之间，所以急需一个轻量级的运行时。容器提供了将应用程序的代码、运行时、系统工具、系统库和配置打包到一个实例中的标准方法。容器共享一个内核（操作系统），它安装在硬件上。\n好处：（我觉得很多人都知道）\n轻便容器占用的服务器空间比虚拟机少，通常只需几秒钟即可启动。\n\n弹性容器具有高弹性，不需要分配给定数量的资源。这意味着容器能够更有效地动态使用服务器中的资源。当一个容器上的需求减少时，释放额外的资源供其他容器使用。\n\n密度密度是指一次可以运行单个物理服务器的对象数。容器化允许创建密集的环境，其中主机服务器的资源被充分利用但不被过度利用。与传统虚拟化相比，容器化允许更密集的环境容器不需要托管自己的操作系统。\n\n性能当资源压力很大时，应用程序的性能远远高于使用虚拟机管理程序的容器。因为使用传统的虚拟化，客户操作系统还必须满足其自身的内存需求，从主机上获取宝贵的RAM。\n\n维护效率只有一个操作系统内核，操作系统级别的更新或补丁只需要执行一次，以使更改在所有容器中生效。这使得服务器的操作和维护更加高效。\n\n方便应用程序管理\n容器受益者，主要还是环境隔离，比如一个应用程序，1、需要supervise启动应用程序(守护程序)，2、需要logstash/Filebeat收集日志，3、需要nginx/其他Sadicar进行一些服务治理的功能，服务发现/限流/熔断等。4、还需要很多运行环境。所以对于快速发展的公司来说，sre如果还是手动的创建虚拟机，那么和容器带来的时间不是一个量级的。5、解决了开发人员不需要登陆到机子上查看物理机信息了。\n\n省钱，省机器\n虚拟机资源利用率太低了，但是配合k8s编排工具，很好的解决了资源的浪费。但是k8s技术对于公司也是一个挑战，玩不好服务不稳定，带来的损失还是不如走物理机/虚拟机。\n\n\n4、容器化/云原生的技术1、OCI（Open Container Initiative） 标准，隔离了容器镜像与runtine的关系，提供的规范标准，\n2、CNCF全称Cloud Native Computing Foundation（云原生计算基金会），成立于 2015 年7月21日，组织内技术栈：https://www.cncf.io/projects/，致力于：\n\n容器化包装。\n通过中心编排系统的动态资源管理。\n面向微服务。(核心还是切入到真实业务开发中)\n\n3、Linux资源隔离技术了解\n4、Kubernetes熟悉，有Operator扩展或相关产品研发经验优先\n5、 Docker的相关的网络和存储技术，有生产环境的实践\n6、云原生技术栈，Prometheus，Envoy等，更多的还是CNCF的毕业的项目的。\n7、更多的还是 Iass，Pass系统开发者经验，空谈技术不务实，就是最扯淡的。\n5、容器化技术面临的挑战​    作为一种轻量级的虚拟化技术，容器使用方便、操作便捷，大大提高开发人员的工作效率，并得到业内的广泛使用。但与此同时，容器安全事故频发，包括不安全的镜像源、容器入侵事件、运行环境的安全问题等等。\n1. 不安全的镜像源​    开发者通常会在 Docker 官方的 Docker Hub 仓库下载镜像，这些镜像一部分来源于开发镜像内相应软件的官方组织，还有大量镜像来自第三方组织甚至个人。从这些镜像仓库中获取镜像的同时，也带来潜在的安全风险。例如，下载镜像内软件本身是否就包含漏洞，下载的镜像是否被恶意植入后门，镜像在传输过程中是否被篡改。其次就是容器的构建全过程是对于开发者是可以看到的！\n2. 容器入侵事件​    由 docker 本身的架构与机制可能产生的问题，这一攻击场景主要产生在黑客已经控制了宿主机上的一些容器（或者通过在公有云上建立容器的方式获得这个条件），然后对宿主机或其他容器发起攻击来产生影响，这个也就是为什么外网服务不允许使用容器！\n3. 运行环境的安全​    除 docker 本身存在的问题外，docker 运行环境存在的问题同样给 docker 的使用带来风险。\n​    由于容器是介于基础设施和平台之间的虚拟化技术，因此面向基础设施虚拟化的传统云安全解决方案无法完全解决前述安全问题。如以容器为支撑技术构建 DevOps 环境，就需要设计涵盖从容器镜像的创建到投产上线的整个生命周期的容器安全方案。\n4、性能​    现在容器的宿主机往往都是 128G+64C 的组合还有更高的，但是单机的瓶颈还是有的，比如如何解决网络/磁盘IO的性能问题，合理的网络技术实现跨宿主机访问，实现可靠的cicd平台！\n6、总结​    最后记住，这些所有的一切，只是为了提高研发效率，保证产研质量！\n可以看看这个PPT：https://docs.qq.com/pdf/DU290V1dSU2NMTHlw\n参考云计算图志\n40 年回顾，一文读懂容器发展史\n为什么说 2019，是属于容器技术的时代？\nCNCF chinal\n命令式和声明式区别\n","categories":["云原生"],"tags":["Docker","容器化"]},{"title":"Golang的GC的回收","url":"/2021/04/01/3a1ab3f1f398e2c69489c00767a5a560/","content":"​    Golang Gc相关！\n\n\n程序启动\n​    Go程序启动，首先绝对是初始化一堆资源，关于如何启动需要看Go的转汇编代码了 ！\n\n// The bootstrap sequence is:////\tcall osinit//\tcall schedinit//\tmake &amp; queue new G//\tcall runtime·mstart//// The new G calls runtime·main.func schedinit() &#123;\t// raceinit must be the first call to race detector.\t// In particular, it must be done before mallocinit below calls racemapshadow.//...\tgcinit()//...&#125;\n\n首先在一个Go程序启动的时候会调用 https://golang.org/src/runtime/proc.go ，大致启动逻辑就和这个注释上一样，会先启动os，然后schedle，然后再启动\ngc初始化func gcinit() &#123;\tif unsafe.Sizeof(workbuf&#123;&#125;) != _WorkbufSize &#123;\t\tthrow(&quot;size of Workbuf is suboptimal&quot;)\t&#125;\t// No sweep on the first cycle.\tmheap_.sweepdone = 1\t// Set a reasonable initial GC trigger. 核心关注与这个！就是触发GC回收的阈值，默认是0.875\tmemstats.triggerRatio = 7 / 8.0\t// Fake a heap_marked value so it looks like a trigger at\t// heapminimum is the appropriate growth from heap_marked.\t// This will go into computing the initial GC goal.\tmemstats.heap_marked = uint64(float64(heapminimum) / (1 + memstats.triggerRatio))\t// Set gcpercent from the environment. This will also compute\t// and set the GC trigger and goal.\t_ = setGCPercent(readgogc())\twork.startSema = 1\twork.markDoneSema = 1&#125;\n\n1、triggerRatio Set a reasonable initial GC trigger. 核心关注与这个！就是触发GC回收的阈值，默认是0.875，含义是这次堆中存活的对象是上一次的 1+(7/0.8)值要大的时候就回收\n假如上次完成后堆内存是 100M 现在是 200M，此时 (200M-100M)/100M&gt;7/0.8的，所以需要进行回收！\n具体这个值可以根据GOGC/100  进行设置，根据具体业务来，GOGC = off 将完全禁用垃圾收集\n2、heapminimumheapminimum是触发GC的最小堆大小。 \n在初始化期间，此设置为4MB * GOGC / 100\nGC执行分类gogc 执行会分配下面大致几类 \n\ngcTriggerHeap\ngcTriggerTime\ngcTriggerCycle\n\n\nfunc (t gcTrigger) test() bool &#123;\tif !memstats.enablegc || panicking != 0 || gcphase != _GCoff &#123;\t\treturn false\t&#125;\tswitch t.kind &#123;\tcase gcTriggerHeap:\t\t// Non-atomic access to heap_live for performance. If\t\t// we are going to trigger on this, this thread just\t\t// atomically wrote heap_live anyway and we&#x27;ll see our\t\t// own write.    return memstats.heap_live &gt;= memstats.gc_trigger // heap中存活的对象大于gc需要触发的阈值(这个阈值时上一次gc设置的)\tcase gcTriggerTime:\t\tif gcpercent &lt; 0 &#123;\t\t\treturn false\t\t&#125;\t\tlastgc := int64(atomic.Load64(&amp;memstats.last_gc_nanotime))\t\treturn lastgc != 0 &amp;&amp; t.now-lastgc &gt; forcegcperiod // 当前时间与上次gc时间相差2分钟\tcase gcTriggerCycle:\t\t// t.n &gt; work.cycles, but accounting for wraparound.\t\treturn int32(t.n-work.cycles) &gt; 0\t&#125;\treturn true&#125;\n\n1、周期性GCfunc forcegchelper() &#123;\tforcegc.g = getg()\tfor &#123;\t\tlock(&amp;forcegc.lock)\t\tif forcegc.idle != 0 &#123;\t\t\tthrow(&quot;forcegc: phase error&quot;)\t\t&#125;\t\tatomic.Store(&amp;forcegc.idle, 1)\t\tgoparkunlock(&amp;forcegc.lock, waitReasonForceGGIdle, traceEvGoBlock, 1)\t\t// this goroutine is explicitly resumed by sysmon\t\tif debug.gctrace &gt; 0 &#123;\t\t\tprintln(&quot;GC forced&quot;)\t\t&#125;\t\t// Time-triggered, fully concurrent.\t\tgcStart(gcTrigger&#123;kind: gcTriggerTime, now: nanotime()&#125;)\t&#125;&#125;\n\n可以看到当调用的时候自己给自己加了把锁，然后把自己挂起等待别人唤醒去执行gc，然后看一下 sysmon函数,这个值一般不会改变！\n// forcegcperiod is the maximum time in nanoseconds between garbage// collections. If we go this long without a garbage collection, one// is forced to run.//// This is a variable for testing purposes. It normally doesn&#x27;t change.var forcegcperiod int64 = 2 * 60 * 1e9// Always runs without a P, so write barriers are not allowed.////go:nowritebarrierrecfunc sysmon() &#123;  // 。。。。。。。。\t\t// check if we need to force a GC  // 要求第一符合gc周期，第二 forcegc.idle 不为0\t\tif t := (gcTrigger&#123;kind: gcTriggerTime, now: now&#125;); t.test() &amp;&amp; atomic.Load(&amp;forcegc.idle) != 0 &#123;\t\t\tlock(&amp;forcegc.lock)\t\t\tforcegc.idle = 0\t\t\tvar list gList\t\t\tlist.push(forcegc.g)\t\t\tinjectglist(&amp;list)\t\t\tunlock(&amp;forcegc.lock)\t\t&#125;  ////。。。。。。。。&#125;\n\n2、malloc gc// Allocate an object of size bytes.// Small objects are allocated from the per-P cache&#x27;s free lists.// Large objects (&gt; 32 kB) are allocated straight from the heap.func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer &#123;\t// ........  // 是否需要gc\tshouldhelpgc := false\tif size &lt;= maxSmallSize &#123; // 小于32k\t\tif noscan &amp;&amp; size &lt; maxTinySize &#123; //小于16字节\t\t&#125; else &#123;\t\t&#125; else &#123;\t\tvar s *mspan\t\tshouldhelpgc = true\t\tsystemstack(func() &#123;\t\t\ts = largeAlloc(size, needzero, noscan)\t\t&#125;)\t\ts.freeindex = 1\t\ts.allocCount = 1\t\tx = unsafe.Pointer(s.base())\t\tsize = s.elemsize\t&#125;\t// 。。。。。。。\tif shouldhelpgc &#123;\t\tif t := (gcTrigger&#123;kind: gcTriggerHeap&#125;); t.test() &#123;\t\t\tgcStart(t)\t\t&#125;\t&#125;\treturn x&#125;\n\n这里可以看到需要判断是否需要执行gc，大致如果分配大于32k的对象时都会去check一下gc\n3、强制GC这个行为一般不推荐用户自己去执行，首先他会强制的阻塞程序！所以不推荐，第二个就是go的GC并不会回收实际分配的物理内存，所以依旧是依赖于系统去强制回收！\n// GC runs a garbage collection and blocks the caller until the// garbage collection is complete. It may also block the entire// program.func GC() &#123;\t// We consider a cycle to be: sweep termination, mark, mark\t// termination, and sweep. This function shouldn&#x27;t return\t// until a full cycle has been completed, from beginning to\t// end. Hence, we always want to finish up the current cycle\t// and start a new one. That means:\t//\t// 1. In sweep termination, mark, or mark termination of cycle\t// N, wait until mark termination N completes and transitions\t// to sweep N.\t//\t// 2. In sweep N, help with sweep N.\t//\t// At this point we can begin a full cycle N+1.\t//\t// 3. Trigger cycle N+1 by starting sweep termination N+1.\t//\t// 4. Wait for mark termination N+1 to complete.\t//\t// 5. Help with sweep N+1 until it&#x27;s done.\t//\t// This all has to be written to deal with the fact that the\t// GC may move ahead on its own. For example, when we block\t// until mark termination N, we may wake up in cycle N+2.\t// Wait until the current sweep termination, mark, and mark\t// termination complete.\tn := atomic.Load(&amp;work.cycles)\tgcWaitOnMark(n)\t// We&#x27;re now in sweep N or later. Trigger GC cycle N+1, which\t// will first finish sweep N if necessary and then enter sweep\t// termination N+1.\tgcStart(gcTrigger&#123;kind: gcTriggerCycle, n: n + 1&#125;)\t// Wait for mark termination N+1 to complete.\tgcWaitOnMark(n + 1)// .......&#125;\n\nGC测试1、内存扩容GC测试这里来测试一下 malloc 的方法\npackage mainimport (\t&quot;fmt&quot;\t&quot;time&quot;)var (\tappender = make([][]byte, 0, 100))// GODEBUG=gctrace=1func main() &#123;\tticker := time.NewTicker(time.Second * 1)\tcount := 0\talloc := 4 &lt;&lt; 20\tfor &#123;\t\t&lt;-ticker.C\t\tappender = append(appender, make([]byte, alloc))\t\tcount++\t\tfmt.Printf(&quot;第%d次分配空间: %dm\\n&quot;, count, alloc&gt;&gt;20)\t&#125;&#125;\n\n1、执行，配置 GOGC=100 GODEBUG=gctrace=1， 更多关于GODEBUG的配置是 https://golang.org/src/runtime/extern.go\n➜  gc git:(master) ✗ GOGC=100 GODEBUG=gctrace=1 bin/app第1次分配空间: 4mgc 1 @1.001s 0%: 0.010+0.19+0.023 ms clock, 0.12+0.11/0.060/0.11+0.28 ms cpu, 4-&gt;4-&gt;4 MB, 5 MB goal, 12 P第2次分配空间: 4mgc 2 @2.003s 0%: 0.003+0.082+0.024 ms clock, 0.040+0.060/0.019/0.059+0.29 ms cpu, 8-&gt;8-&gt;8 MB, 9 MB goal, 12 P第3次分配空间: 4m第4次分配空间: 4mgc 3 @4.005s 0%: 0.021+0.20+0.009 ms clock, 0.25+0.10/0.099/0.12+0.11 ms cpu, 16-&gt;16-&gt;16 MB, 17 MB goal, 12 P第5次分配空间: 4m第6次分配空间: 4m第7次分配空间: 4m第8次分配空间: 4mgc 4 @8.005s 0%: 0.005+0.19+0.008 ms clock, 0.061+0.10/0.074/0.086+0.10 ms cpu, 32-&gt;32-&gt;32 MB, 33 MB goal, 12 P第9次分配空间: 4m第10次分配空间: 4m第11次分配空间: 4m第12次分配空间: 4m第13次分配空间: 4m第14次分配空间: 4m第15次分配空间: 4m第16次分配空间: 4mgc 5 @16.005s 0%: 0.015+0.21+0.011 ms clock, 0.18+0.14/0.062/0.15+0.13 ms cpu, 64-&gt;64-&gt;64 MB, 65 MB goal, 12 P\n\n2、这里可以看到第一次分配就进行了GC，完全符合默认的设置，当内存第二次分配的时候，由于8/4&gt;1进行了gc，那么下一次触发的阈值就会是 16，假如我们将 GOGC=50，继续执行\n➜  gc git:(master) ✗ GOGC=50 GODEBUG=gctrace=1 bin/appgc 第1次分配空间: 4m1 @1.000s 0%: 0.011+0.18+0.016 ms clock, 0.13+0.10/0.024/0.16+0.19 ms cpu, 4-&gt;4-&gt;4 MB, 5 MB goal, 12 P第2次分配空间: 4mgc 2 @2.002s 0%: 0.006+0.27+0.010 ms clock, 0.078+0.12/0.12/0.12+0.12 ms cpu, 8-&gt;8-&gt;8 MB, 9 MB goal, 12 P第3次分配空间: 4mgc 3 @3.001s 0%: 0.006+0.21+0.010 ms clock, 0.083+0.10/0.12/0.11+0.12 ms cpu, 12-&gt;12-&gt;12 MB, 13 MB goal, 12 P第4次分配空间: 4m第5次分配空间: 4mgc 4 @5.005s 0%: 0.006+0.24+0.012 ms clock, 0.080+0.10/0.055/0.22+0.14 ms cpu, 20-&gt;20-&gt;20 MB, 21 MB goal, 12 P\n\n可以看到第3次gc的内存是12m，原因是上次gc后堆内存为8m,那么下一次就是 8m*1.5=12m，所以完全符合！\n3、假如关闭垃圾回收\n➜  gc git:(master) ✗ GOGC=off GODEBUG=gctrace=1 bin/app第1次分配空间: 4m第2次分配空间: 4m第3次分配空间: 4m第4次分配空间: 4m第5次分配空间: 4m\n\n关于gc日志学习gctrace: setting gctrace=1 causes the garbage collector to emit a single line to standarderror at each collection, summarizing the amount of memory collected and thelength of the pause. The format of this line is subject to change.Currently, it is:  gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-&gt;#-&gt;# MB, # MB goal, # Pwhere the fields are as follows:  gc #        the GC number, incremented at each GC  @#s         time in seconds since program start，距离程序的启动时间，单位s  #%          percentage of time spent in GC since program start，花费时间的百分比  #+...+#     wall-clock/CPU times for the phases of the GC， cpu花费的时间  #-&gt;#-&gt;# MB  heap size at GC start, at GC end, and live heap，gc开始-gc结束-存活的对象 （堆内存）  # MB goal   goal heap size （全局堆内存大小）  # P         number of processors used p的数量\n\n2、强制gcpackage mainimport (\t&quot;runtime&quot;\t&quot;time&quot;)// GOGC=100 GODEBUG=gctrace=1func main() &#123;\t_ = make([]byte, 0, 3&lt;&lt;20)\truntime.GC()\ttime.Sleep(time.Second * 100)&#125;\n\n执行\n➜  gc git:(master) ✗ GOGC=100 GODEBUG=gctrace=1 bin/appgc 1 @0.000s 2%: 0.003+0.11+0.006 ms clock, 0.037+0/0.089/0.10+0.080 ms cpu, 3-&gt;3-&gt;0 MB, 4 MB goal, 12 P (forced)^C\n\n可以看到结果是堆中最后存活的对象是  0M，可以发现我们申明的那个3m对象被回收，也没有触发系统mem回收！\n3、周期清理这个其实不好测试，因为那个周期值无法做配置！\npackage mainimport (\t&quot;time&quot;)// GOGC=100 GODEBUG=gctrace=1func main() &#123;\t_ = make([]byte, 0, 3&lt;&lt;20)\ttime.Sleep(time.Second * 130)&#125;\n\n等待120s的到来！……….. 结果没有\n获取Runtime信息\n​    使用prometheus 获取 proc信息，必须是linux/windows，所以mac不能使用\n\n1、mem信息package mainimport (\t&quot;fmt&quot;\t&quot;github.com/prometheus/procfs&quot;\t&quot;os&quot;\t&quot;runtime&quot;)// GOGC=100 GODEBUG=gctrace=1func main() &#123;\tmemInfo()\t_ = make([]byte, 0, 3&lt;&lt;20)\tmemInfo()\truntime.GC()\tmemInfo()&#125;func memInfo() &#123;\tstats := runtime.MemStats&#123;&#125;\truntime.ReadMemStats(&amp;stats)\tfmt.Printf(&quot;%+v\\n&quot;, stats)\tprocMem()&#125;func procMem() &#123;\tp, err := procfs.NewProc(os.Getpid())\tif err != nil &#123;\t\tpanic(err)\t&#125;\tprocStat, err := p.Stat()\tif err != nil &#123;\t\tpanic(err)\t&#125;\tprocStat.ResidentMemory() // 进程所占用的RES\tprocStat.VirtualMemory()  // 进程所占用的VIRT\tfmt.Printf(&quot;res: %dM, virt: %dM\\n&quot;, procStat.ResidentMemory()&gt;&gt;20, procStat.VirtualMemory()&gt;&gt;20)&#125;\n\n执行上面函数以下结果\n➜  gc git:(master) ✗ GOGC=100 GODEBUG=gctrace=1  bin/app&#123;Alloc:158760 TotalAlloc:158760 Sys:69928960 Lookups:0 Mallocs:173 Frees:3 HeapAlloc:158760 HeapSys:66879488 HeapIdle:66535424 HeapInuse:344064 HeapReleased:66469888 HeapObjects:170 StackInuse:229376 StackSys:229376 MSpanInuse:5168 MSpanSys:16384 MCacheInuse:20832 MCacheSys:32768 BuckHashSys:2203 GCSys:2240512 OtherSys:528229 NextGC:4473924 LastGC:0 PauseTotalNs:0 PauseNs:[0 0...] PauseEnd:[0 0 .....] NumGC:0 NumForcedGC:0 GCCPUFraction:0 EnableGC:true DebugGC:false BySize:[&#123;Size:0 Mallocs:0 Frees:0&#125; &#123;Size:8 Mallocs:5 Frees:0&#125; &#123;Size:16 Mallocs:42 Frees:0&#125; ......]&#125;res: 3M, virt: 211M&#123;Alloc:3328688 TotalAlloc:3328688 Sys:69928960 Lookups:0 Mallocs:406 Frees:111 HeapAlloc:3328688 HeapSys:66879488 HeapIdle:63250432 HeapInuse:3629056 HeapReleased:63250432 HeapObjects:295 StackInuse:229376 StackSys:229376 MSpanInuse:6528 MSpanSys:16384 MCacheInuse:20832 MCacheSys:32768 BuckHashSys:2203 GCSys:2240512 OtherSys:528229 NextGC:4473924 LastGC:0 PauseTotalNs:0 PauseNs:[0 0 ......] PauseEnd:[0 0 .......] NumGC:0 NumForcedGC:0 GCCPUFraction:0 EnableGC:true DebugGC:false BySize:[&#123;Size:0 Mallocs:0 Frees:0&#125; &#123;Size:8 Mallocs:6 Frees:0&#125; &#123;Size:16 Mallocs:151 Frees:0&#125; .....]&#125;res: 3M, virt: 211Mgc 1 @0.002s 0%: 0.006+0.17+0.004 ms clock, 0.075+0/0.098/0.20+0.052 ms cpu, 3-&gt;3-&gt;0 MB, 4 MB goal, 12 P (forced)&#123;Alloc:158248 TotalAlloc:3345520 Sys:70256640 Lookups:0 Mallocs:656 Frees:484 HeapAlloc:158248 HeapSys:66781184 HeapIdle:66,396,160 HeapInuse:385,024 HeapReleased:62,996,480 HeapObjects:172 StackInuse:327680 StackSys:327680 MSpanInuse:7072 MSpanSys:16384 MCacheInuse:20832 MCacheSys:32768 BuckHashSys:2203 GCSys:2312192 OtherSys:784229 NextGC:4194304 LastGC:1617196841921944000 PauseTotalNs:10675 PauseNs:[10675 0 0 ......] PauseEnd:[1617196841921944000 0 0 0......] NumGC:1 NumForcedGC:1 GCCPUFraction:0.007580984200182396 EnableGC:true DebugGC:false BySize:[&#123;Size:0 Mallocs:0 Frees:0&#125; &#123;Size:8 Mallocs:6 Frees:1&#125; ........]&#125;res: 3M, virt: 283M\n\n可以看到gc前内存是3m，gc后内存是0m\n\nAlloc 158,760-&gt;3,328,688-&gt;158,248 （和 HeapAlloc 一样）\nTotalAlloc  158,760-&gt; 3,328,688-&gt; 3,345,520（一共分配的内存）\nSys 69,928,960-&gt;69,928,960-&gt;70,256,640（系统分配的内存，它表示占用操作系统的全部内存！）\nHeapAlloc  158,760-&gt;3,328,688-&gt;158,248 （堆分配的内存）\nHeapSys  66,879,488-&gt;66,879,488-&gt;66,781,184\nHeapIdle  66,535,424-&gt;63,250,432-&gt;66,396,160（未被使用的span字节树，其实就是未被分配的堆内存，当内存被回收时这个数量会增加回收的内存）\nHeapInuse  344,064-&gt;3,629,056-&gt;385,024 (正在使用的字节数)\nHeapReleased  66,469,888-&gt;63,250,432-&gt;62,996,480 （返还给操作系统的内存，它统计了从idle span中返还给操作系统，没有被重新获取的内存大小.）\nPauseNs 表示GC停顿时常， PauseNs[NumGC%256] 表示第多少次GC的时长，记录最近256次的GC！\nNextGC  4,473,924-&gt; 4,473,924 -&gt; 4,194,304, 表示下次GC触发的阈值\nGCSys  229,376-&gt;2,240,512-&gt;2,312,192\n\n其他指标讲解请看 https://golang.org/src/runtime/mstats.go\n2、监控进程的指标这里需要使用 github.com/prometheus/procfs  包，很好的解决了跨平台问题！\npackage mainimport (\t&quot;github.com/prometheus/procfs&quot;\t&quot;os&quot;)func main() &#123;\tp, err := procfs.NewProc(os.Getpid())\tif err != nil &#123;\t\tpanic(err)\t&#125;\tprocStat, err := p.Stat()\tif err != nil &#123;\t\tpanic(err)\t&#125;\tprocStat.ResidentMemory() // 进程所占用的RES\tprocStat.VirtualMemory()  // 进程所占用的VIRT&#125;\n\n3、使用prometheus 监控下面是一个线上服务的metrics\n# HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.# TYPE go_gc_duration_seconds summarygo_gc_duration_seconds&#123;quantile=&quot;0&quot;&#125; 5.6827e-05go_gc_duration_seconds&#123;quantile=&quot;0.25&quot;&#125; 8.1842e-05go_gc_duration_seconds&#123;quantile=&quot;0.5&quot;&#125; 9.8818e-05go_gc_duration_seconds&#123;quantile=&quot;0.75&quot;&#125; 0.000125499go_gc_duration_seconds&#123;quantile=&quot;1&quot;&#125; 0.000555719go_gc_duration_seconds_sum 0.247680951go_gc_duration_seconds_count 2366# HELP go_goroutines Number of goroutines that currently exist.# TYPE go_goroutines gaugego_goroutines 50# HELP go_info Information about the Go environment.# TYPE go_info gaugego_info&#123;version=&quot;go1.13.5&quot;&#125; 1# HELP go_memstats_alloc_bytes Number of bytes allocated and still in use.# TYPE go_memstats_alloc_bytes gaugego_memstats_alloc_bytes 8.338104e+06# HELP go_memstats_alloc_bytes_total Total number of bytes allocated, even if freed.# TYPE go_memstats_alloc_bytes_total countergo_memstats_alloc_bytes_total 1.3874634688e+10# HELP go_memstats_buck_hash_sys_bytes Number of bytes used by the profiling bucket hash table.# TYPE go_memstats_buck_hash_sys_bytes gaugego_memstats_buck_hash_sys_bytes 1.922436e+06# HELP go_memstats_frees_total Total number of frees.# TYPE go_memstats_frees_total countergo_memstats_frees_total 8.9915565e+07# HELP go_memstats_gc_cpu_fraction The fraction of this program&#x27;s available CPU time used by the GC since the program started.# TYPE go_memstats_gc_cpu_fraction gaugego_memstats_gc_cpu_fraction 5.2633836319412915e-06# HELP go_memstats_gc_sys_bytes Number of bytes used for garbage collection system metadata.# TYPE go_memstats_gc_sys_bytes gaugego_memstats_gc_sys_bytes 2.398208e+06# HELP go_memstats_heap_alloc_bytes Number of heap bytes allocated and still in use.# TYPE go_memstats_heap_alloc_bytes gaugego_memstats_heap_alloc_bytes 8.338104e+06# HELP go_memstats_heap_idle_bytes Number of heap bytes waiting to be used.# TYPE go_memstats_heap_idle_bytes gaugego_memstats_heap_idle_bytes 5.1625984e+07# HELP go_memstats_heap_inuse_bytes Number of heap bytes that are in use.# TYPE go_memstats_heap_inuse_bytes gaugego_memstats_heap_inuse_bytes 1.0829824e+07# HELP go_memstats_heap_objects Number of allocated objects.# TYPE go_memstats_heap_objects gaugego_memstats_heap_objects 42405# HELP go_memstats_heap_released_bytes Number of heap bytes released to OS.# TYPE go_memstats_heap_released_bytes gaugego_memstats_heap_released_bytes 4.9709056e+07# HELP go_memstats_heap_sys_bytes Number of heap bytes obtained from system.# TYPE go_memstats_heap_sys_bytes gaugego_memstats_heap_sys_bytes 6.2455808e+07# HELP go_memstats_last_gc_time_seconds Number of seconds since 1970 of last garbage collection.# TYPE go_memstats_last_gc_time_seconds gaugego_memstats_last_gc_time_seconds 1.6172457774344466e+09# HELP go_memstats_lookups_total Total number of pointer lookups.# TYPE go_memstats_lookups_total countergo_memstats_lookups_total 0# HELP go_memstats_mallocs_total Total number of mallocs.# TYPE go_memstats_mallocs_total countergo_memstats_mallocs_total 8.995797e+07# HELP go_memstats_mcache_inuse_bytes Number of bytes in use by mcache structures.# TYPE go_memstats_mcache_inuse_bytes gaugego_memstats_mcache_inuse_bytes 83328# HELP go_memstats_mcache_sys_bytes Number of bytes used for mcache structures obtained from system.# TYPE go_memstats_mcache_sys_bytes gaugego_memstats_mcache_sys_bytes 98304# HELP go_memstats_mspan_inuse_bytes Number of bytes in use by mspan structures.# TYPE go_memstats_mspan_inuse_bytes gaugego_memstats_mspan_inuse_bytes 142528# HELP go_memstats_mspan_sys_bytes Number of bytes used for mspan structures obtained from system.# TYPE go_memstats_mspan_sys_bytes gaugego_memstats_mspan_sys_bytes 196608# HELP go_memstats_next_gc_bytes Number of heap bytes when next garbage collection will take place.# TYPE go_memstats_next_gc_bytes gaugego_memstats_next_gc_bytes 1.0362992e+07# HELP go_memstats_other_sys_bytes Number of bytes used for other system allocations.# TYPE go_memstats_other_sys_bytes gaugego_memstats_other_sys_bytes 5.542772e+06# HELP go_memstats_stack_inuse_bytes Number of bytes in use by the stack allocator.# TYPE go_memstats_stack_inuse_bytes gaugego_memstats_stack_inuse_bytes 4.653056e+06# HELP go_memstats_stack_sys_bytes Number of bytes obtained from system for stack allocator.# TYPE go_memstats_stack_sys_bytes gaugego_memstats_stack_sys_bytes 4.653056e+06# HELP go_memstats_sys_bytes Number of bytes obtained from system.# TYPE go_memstats_sys_bytes gaugego_memstats_sys_bytes 7.7267192e+07# HELP go_threads Number of OS threads created.# TYPE go_threads gaugego_threads 48# HELP process_cpu_seconds_total Total user and system CPU time spent in seconds.# TYPE process_cpu_seconds_total counterprocess_cpu_seconds_total 3875.24# HELP process_max_fds Maximum number of open file descriptors.# TYPE process_max_fds gaugeprocess_max_fds 1.048576e+06# HELP process_open_fds Number of open file descriptors.# TYPE process_open_fds gaugeprocess_open_fds 29# HELP process_resident_memory_bytes Resident memory size in bytes.# TYPE process_resident_memory_bytes gaugeprocess_resident_memory_bytes 7.5575296e+07# HELP process_start_time_seconds Start time of the process since unix epoch in seconds.# TYPE process_start_time_seconds gaugeprocess_start_time_seconds 1.61709350436e+09# HELP process_virtual_memory_bytes Virtual memory size in bytes.# TYPE process_virtual_memory_bytes gaugeprocess_virtual_memory_bytes 2.018103296e+09# HELP process_virtual_memory_max_bytes Maximum amount of virtual memory available in bytes.# TYPE process_virtual_memory_max_bytes gaugeprocess_virtual_memory_max_bytes -1# HELP promhttp_metric_handler_requests_in_flight Current number of scrapes being served.# TYPE promhttp_metric_handler_requests_in_flight gaugepromhttp_metric_handler_requests_in_flight 1# HELP promhttp_metric_handler_requests_total Total number of scrapes by HTTP status code.# TYPE promhttp_metric_handler_requests_total counterpromhttp_metric_handler_requests_total&#123;code=&quot;200&quot;&#125; 25373promhttp_metric_handler_requests_total&#123;code=&quot;500&quot;&#125; 0promhttp_metric_handler_requests_total&#123;code=&quot;503&quot;&#125; 0\n\n核心关注的指标： \n\n​    7.5575296e+07 含义是  7.5575296*10^7 ，所以转换为 M，快速计算只需要 / 10^6， 所以就 -6即可，也就是7.5575296e+01 所以就是 75M\n\n\nprocess_resident_memory_bytes  - RES 进程所占用的物理内存 （75M）\nprocess_virtual_memory_bytes - VIRT 进程所占用的虚拟内存 (Go的虚拟内存往往很大，2G)\ngo_memstats_heap_alloc_bytes - HeapAlloc 堆内存大小(当前堆实际使用的大小 , 8M)\ngo_memstats_next_gc_bytes - NextGC 表示下次触发GC的阈值 （10M）\ngo_memstats_heap_idle_bytes  - HeapIdle 表示堆中空闲的内存( 59M)\ngo_memstats_heap_inuse_bytes  - HeapInuse表示正在使用的堆内存 (10M，可能包含有碎片，这个就是实际占用的内存，可以参考的，因为空闲内存可能被回收/未被分配的也是可能实际没有分配)\nprocess_open_fds 打开的文件 （29）\ngo_goroutines 表示 go的goroutine 个数 (50)\ngo_memstats_buck_hash_sys_bytes 表示hash表中的数据 (8M)\n\n下面是我们公司对于Go服务的监控\n这个容器里放的是一个站内信服务，服务部署在容器中4c_4g（宿主机是128G_64C），可以看到24小时内，服务的内存还是相对来说很稳定的，堆内存基本维持在10m-15m左右，gc基本在100us内！\n\n4、使用 net/http/pprof只需要引入 _ &quot;net/http/pprof&quot; \n然后加一行\ngo func() &#123;   // 未占用的端口\thttp.ListenAndServe(&quot;:8080&quot;, nil)&#125;()\n\n1、mem最后执行一下下面的，也就是当前的 runtime.MemStats， 不用说核心关注 HeapAlloc 和 HeapInuse 以及 NextGC ,  PauseNs , NumGC\n➜  ~ curl http://localhost:8080/debug/pprof/allocs\\?debug\\=1 -v# runtime.MemStats# Alloc = 457531928# TotalAlloc = 672404416# Sys = 556939512# Lookups = 0# Mallocs = 24449# Frees = 23362# HeapAlloc = 457531928# HeapSys = 536248320# HeapIdle = 77873152# HeapInuse = 458375168# HeapReleased = 44040192# HeapObjects = 1087# Stack = 622592 / 622592# MSpan = 29512 / 32768# MCache = 20832 / 32768# BuckHashSys = 1443701# GCSys = 17530880# OtherSys = 1028483# NextGC = 915023280# LastGC = 1617268469532778000# PauseNs = [35105 36373 34839 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]# PauseEnd = [1617268337687730000 1617268338545459000 1617268469532778000 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]# NumGC = 3# NumForcedGC = 0# GCCPUFraction = 1.2248226722456959e-06# DebugGC = false* Connection #0 to host localhost left intact* Closing connection 0\n\n2、goroutine / thread➜  ~ curl http://localhost:8080/debug/pprof/goroutine\\?debug\\=1 -vgoroutine profile: total 6➜  ~ curl http://localhost:8080/debug/pprof/threadcreate\\?debug\\=1 -vthreadcreate profile: total 14\n\n3、配合go tool pprof  命令\n​    主要需要加参数 seconds，默认收集30s，下面例子是10s\n\n➜  ~ go tool  pprof -http &quot;:8888&quot;  http://localhost:62316/debug/pprof/allocs\\?seconds\\=10Fetching profile over HTTP from http://localhost:62316/debug/pprof/allocs?seconds=10Saved profile in /Users/fanhaodong/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.011.pb.gzServing web UI on http://localhost:8888\n\n可以看到采集10s最后效果\n\n1、比如查找goroutine 使用率较高！我们首先要查询 个数\n➜  ~ curl http://localhost:62316/debug/pprof/goroutine\\?debug\\=1goroutine profile: total 100\n\n为啥这么多来\n➜  ~ go tool  pprof -http &quot;:8888&quot;  http://localhost:62316/debug/pprof/goroutine\\?seconds\\=10Fetching profile over HTTP from http://localhost:62316/debug/pprof/goroutine?seconds=10Saved profile in /Users/fanhaodong/pprof/pprof.goroutine.001.pb.gzServing web UI on http://localhost:8888\n\n可以查看csv图，前提是你是在本地，首先如果在线上服务器，显然是不可能的！线上需要执行\n➜  ~ go tool pprof   http://localhost:62316/debug/pprof/goroutine\\?seconds\\=\n\n然后去查看\n\n查看trace\n➜  ~ go tool pprof   http://localhost:62316/debug/pprof/goroutine\\?seconds\\=5Fetching profile over HTTP from http://localhost:62316/debug/pprof/goroutine?seconds=5(pprof) treeShowing nodes accounting for 102, 98.08% of 104 totalShowing top 80 nodes out of 129----------------------------------------------------------+-------------      flat  flat%   sum%        cum   cum%   calls calls% + context----------------------------------------------------------+-------------                                                53 51.96% |   runtime.selectgo                                                26 25.49% |   runtime.goparkunlock                                                23 22.55% |   runtime.netpollblock       102 98.08% 98.08%        102 98.08%                | runtime.gopark----------------------------------------------------------+-------------         0     0% 98.08%         54 51.92%                | github.com/apache/rocketmq-client-go/v2/primitive.WithRecover                                                 9 16.67% |   github.com/apache/rocketmq-client-go/v2/internal/remote.(*remotingClient).connect.func1                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*pushConsumer).pullMessage.func1                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func1                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func2                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func3                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func4                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func5                                                 5  9.26% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func6                                                 2  3.70% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.2                                                 2  3.70% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.3                                                 2  3.70% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.4                                                 2  3.70% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.5                                                 2  3.70% |   github.com/apache/rocketmq-client-go/v2/internal.(*traceDispatcher).Start.func1----------------------------------------------------------+-------------                                                 5  9.43% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func1                                                 5  9.43% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func2                                                 5  9.43% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func3                                                 5  9.43% |   github.com/apache/rocketmq-client-go/v2/consumer.(*statsItemSet).init.func4                                                 5  9.43% |   github.com/apache/rocketmq-client-go/v2/internal/remote.(*ResponseFuture).waitResponse                                                 5  9.43% |   net/http.(*persistConn).writeLoop                                                 2  3.77% |   database/sql.(*DB).connectionOpener                                                 2  3.77% |   database/sql.(*DB).connectionResetter                                                 2  3.77% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.2                                                 2  3.77% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.3                                                 2  3.77% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.4                                                 2  3.77% |   github.com/apache/rocketmq-client-go/v2/internal.(*rmqClient).Start.func1.5                                                 2  3.77% |   github.com/apache/rocketmq-client-go/v2/internal.(*traceDispatcher).process                                                 2  3.77% |   github.com/go-sql-driver/mysql.(*mysqlConn).startWatcher.func1                                                 1  1.89% |   github.com/SkyAPM/go2sky/reporter/grpc/management.(*managementServiceClient).KeepAlive                                                 1  1.89% |   github.com/apache/rocketmq-client-go/v2/consumer.(*pushConsumer).Start.func1.1                                                 1  1.89% |   github.com/nacos-group/nacos-sdk-go/common/http_agent.post         0     0% 98.08%         53 50.96%                | runtime.selectgo                                                53   100% |   runtime.gopark\n\n\n\n总结Go的内存模型和GC策略总结一下，堆属于Go最大的空间，堆大小基本用不完，对于GC来说(因为分配的是虚拟内存，同时会定期释放内存)，Go采用的是能复用即复用，也就是说如果我开辟了3M然后回收了3M下次就复用这空间，其次就是Go的堆内存并不会回收，也就是说如果我某一时刻堆空间开辟了很大的空间，其实对于程序来说，内存并不会回收！\nGo的GC时间主要是根据堆的大小有关，我们线上来说，Go的堆大小基本很小，不到100M，所以GC时长也不会很大！\nGo的GC优化就是能回收的在程序/请求运行结束就立马回收，如果开辟大量内存介意用sync.Pool！\n其次减少GC频率可以在程序初始化的时候先开辟一个和程序稳定运行时大小的一个空间，那么对于Go来说，会减少GC回收的次数，但是GC回收的时间就会增加！\nGo的GC回收时间主要是受机器的CPU限制，cpu越牛逼的机器回收越快！\n备注mem 信息字段// A MemStats records statistics about the memory allocator.type MemStats struct &#123;\t// 常规统计。\t// Alloc 是已分配的堆内存对象占用的内存量（bytes）。\t//\t// 这个值和 基本和HeapAlloc 一致（看下面）。\tAlloc uint64\t// TotalAlloc 是累积的堆内存对象分配的内存量（bytes）。\t//\t// TotalAlloc 会随着堆内存对象分配慢慢增长，但不像 Alloc 和 HeapAlloc，\t// 这个值不会随着对象被释放而缩小。\tTotalAlloc uint64\t// Sys 是从 OS 获得的内存总量（bytes）。\t//\t// Sys 是下面列出的 XSys 字段的综合。Sys 维护着为 Go 运行时预留的虚拟内存空间地址，\t// 里面包含了：堆、栈，以及其他内部数据结构。\tSys uint64\t// Lookups 是 runtime 执行的指针查询的数量。\t//\t// 这主要在针对 runtime 内部进行 debugging 的时候比较有用。\tLookups uint64\t// Mallocs 是累积被分配的堆内存对象数量。\t// 存活堆内存对象数量是 Mallocs - Frees。\tMallocs uint64\t// Frees 是累积被释放掉的堆内存对象数量。\tFrees uint64\t// 堆内存统计。\t//\t// 理解堆内存统计需要一些 Go 是如何管理内存的知识。Go 将堆内存虚拟内存空间以 &quot;spans&quot; 为单位进行分割。\t// spans 是 8K（或更大）的连续内存空间。一个 span 可能会在以下三种状态之一：\t//\t// 一个 &quot;空闲 idle&quot; 的 span 内部不含任何对象或其他数据。\t// 占用物理内存空间的空闲状态 span 可以被释放回 OS（但虚拟内存空间不会），\t// 或者也可以被转化成为 &quot;使用中 in use&quot; 或 &quot;堆栈 stack&quot; 状态。\t//\t// 一个 &quot;使用中 in use&quot; span 包含了至少一个堆内存对象且可能还有富余的空间可以分配更多的堆内存对象。\t//\t// 一个 &quot;堆栈 stack&quot; span 是被用作 goroutine stack 的 内存空间。\t// 堆栈状态的 span 不被视作是堆内存的一部分。一个 span 可以在堆内存和栈内存之间切换；\t// 但不可能同时作为两者。\t// HeapAlloc 是已分配的堆内存对象占用的内存量（bytes）。\t//\t// &quot;已分配&quot;的堆内存对象包含了所有可达的对象，以及所有垃圾回收器已知但仍未回收的不可达对象。\t// 确切的说，HeapAlloc 随着堆内存对象分配而增长，并随着内存清理、不可达对象的释放而缩小。\t// 清理会随着 GC 循环渐进发生，所有增长和缩小这两个情况是同时存在的，\t// 作为结果 HeapAlloc 的变动趋势是平滑的（与传统的 stop-the-world 型垃圾回收器的锯齿状趋势成对比）。\tHeapAlloc uint64\t// HeapSys 是堆内存从 OS 获得的内存总量（bytes）。\t//\t// HeapSys 维护着为堆内存而保留的虚拟内存空间。这包括被保留但尚未使用的虚拟内存空间，\t// 这部分是不占用实际物理内存的，但趋向于缩小，\t// 和那些占用物理内存但后续因不再使用而释放回 OS 的虚拟内存空间一样。（查看 HeapReleased 作为校对）\t//\t// HeapSys 用来评估堆内存曾经到过的最大尺寸。\tHeapSys uint64\t// HeapIdle 是处于&quot;空闲状态（未使用）&quot;的 spans 占用的内存总量（bytes）。\t//\t// 空闲状态的 spans 内部不含对象。这些 spans 可以（并可能已经被）释放回 OS，\t// 或者它们可以在堆内存分配中重新被利用起来，或者也可以被重新作为栈内存利用起来。\t//\t// HeapIdle 减去 HeapReleased 用来评估可以被释放回 OS 的内存总量，\t// 但因为这些内存已经被 runtime 占用了（已经从 OS 申请下来了）所以堆内存可以重新使用这些内存，\t// 就不用再向 OS 申请更多内存了。如果这个差值显著大于堆内存尺寸，这意味着近期堆内存存活对象数量存在一个短时峰值。\tHeapIdle uint64\t// HeapInuse 是处于&quot;使用中&quot;状态的 spans 占用的内存总量（bytes）。\t//\t// 使用中的 spans 内部存在至少一个对象。这些 spans 仅可以被用来存储其他尺寸接近的对象。\t//\t// HeapInuse 减去 HeapAlloc 用来评估被用来存储特定尺寸对象的内存空间的总量，\t// 但目前并没有被使用。这是内存碎片的上界，但通常来说这些内存会被高效重用。\tHeapInuse uint64\t// HeapReleased 是被释放回 OS 的物理内存总量（bytes）。\t//\t// 这个值计算为已经被释放回 OS 的空闲状态的 spans 堆内存空间，且尚未重新被堆内存分配。\tHeapReleased uint64\t// HeapObjects 是堆内存中的对象总量。\t//\t// 和 HeapAlloc 一样，这个值随着对象分配而上涨，随着堆内存清理不可达对象而缩小。\tHeapObjects uint64\t// 栈内存统计。\t//\t// 栈内存不被认为是堆内存的一部分，但 runtime 会将一个堆内存中的 span 用作为栈内存，反之亦然。\t// StackInuse 是栈内存使用的 spans 占用的内存总量（bytes）。\t//\t// 使用中状态的栈内存 spans 其中至少有一个栈内存。这些 spans 只能被用来存储其他尺寸接近的栈内存。\t//\t// 并不存在 StackIdle，因为未使用的栈内存 spans 会被释放回堆内存（因此被计入 HeapIdle）。\tStackInuse uint64\t// StackSys 是栈内存从 OS 获得的内存总量（bytes）。\t//\t// StackSys 是 StackInuse 加上一些为了 OS 线程栈而直接从 OS 获取的内存（应该很小）。\tStackSys uint64\t// 堆外（off-heap）内存统计。\t//\t// 下列的统计信息描述了并不会从堆内存进行分配的运行时内部（runtime-internal）结构体（通常因为它们是堆内存实现的一部分）。\t// 不像堆内存或栈内存，任何这些结构体的内存分配仅只是为这些结构服务。\t//\t// 这些统计信息对 debugging runtime 内存额外开销非常有用。\t// MSpanInuse 是 mspan 结构体分配的内存量（bytes）。\tMSpanInuse uint64\t// MSpanSys 是为 mspan 结构体从 OS 申请过来的内存量（bytes）。\tMSpanSys uint64\t// MCacheInuse 是 mcache 结构体分配的内存量（bytes）。\tMCacheInuse uint64\t// MCacheSys 是为 mcache 结构体从 OS 申请过来的内存量（bytes）。\tMCacheSys uint64\t// BuckHashSys 是用来 profiling bucket hash tables 的内存量（bytes）。\tBuckHashSys uint64\t// GCSys 是在垃圾回收中使用的 metadata 的内存量（bytes）。 \tGCSys uint64\t// OtherSys 是各种各样的 runtime 分配的堆外内存量（bytes）。\tOtherSys uint64\t// 垃圾回收统计。\t// NextGC 是下一次 GC 循环的目标堆内存尺寸。\t//\t// 垃圾回收器的目标是保持 HeapAlloc ≤ NextGC。\t// 在每一轮 GC 循环末尾，下一次循环的目标值会基于当前可达对象数据量以及 GOGC 的值来进行计算。\tNextGC uint64\t// LastGC 是上一次垃圾回收完成的时间，其值为自 1970 年纸巾的 nanoseconds（UNIX epoch）。\tLastGC uint64\t// PauseTotalNs 是自程序启动开始，在 GC stop-the-world 中暂停的累积时长，以 nanoseconds 计数。\t//\t// 在一次 stop-the-world 暂停期间，所有的 goroutines 都会被暂停，仅垃圾回收器在运行。\tPauseTotalNs uint64\t// PauseNs 是最近的 GC stop-the-world 暂停耗时的环形缓冲区（以 nanoseconds 计数）。\t//\t// 最近一次的暂停耗时在 PauseNs[(NumGC+255)%256] 这个位置。\t// 通常来说，PauseNs[N%256] 记录着最近第 N%256th 次 GC 循环的暂停耗时。\t// 在每次 GC 循环中可能会有多次暂停；这是在一次循环中的所有暂停时长的总合。\tPauseNs [256]uint64\t// PauseEnd 是最近的 GC 暂停结束时间的环形缓冲区，其值为自 1970 年纸巾的 nanoseconds（UNIX epoch）。\t//\t// 这个缓冲区的填充方式和 PauseNs 是一致的。\t// 每次 GC 循环可能有多次暂停；这个缓冲区记录的是每个循环的最后一次暂停的结束时间。\tPauseEnd [256]uint64\t// NumGC 是完成过的 GC 循环的数量。\tNumGC uint32\t// NumForcedGC 是应用程序经由调用 GC 函数来强制发起的 GC 循环的数量。\tNumForcedGC uint32\t// GCCPUFraction 是自程序启动以来，应用程序的可用 CPU 时间被 GC 消耗的时长部分。\t//\t// GCCPUFraction 是一个 0 和 1 之间的数字，0 代表 GC 并没有消耗该应用程序的任何 CPU。\t// 一个应用程序的可用 CPU 时间定义为：自应用程序启动以来 GOMAXPROCS 的积分。\t// 举例来说，如果 GOMAXPROCS 是 2 且应用程序已经运行了 10 秒，那么&quot;可用 CPU 时长&quot;就是 20 秒。\t// GCCPUFraction 并未包含写屏障行为消耗的 CPU 时长。\t//\t// 该值和经由 GODEBUG=gctrace=1 报告出来的 CPU 时长是一致的。 \tGCCPUFraction float64\t// EnableGC 显示 GC 是否被启用了。该值永远为真，即便 GOGC=off 被启用。\tEnableGC bool\t// DebugGC 目前并未被使用。\tDebugGC bool\t// BySize 汇报了按大小划分的 span 级别内存分配统计信息。\t//\t// BySize[N] 给出了尺寸 S 对象的内存分配统计信息，尺寸大小是：\t// BySize[N-1].Size &lt; S ≤ BySize[N].Size。\t//\t// 这个结构里的数据并未汇报尺寸大于 BySize[60].Size 的内存分配数据。\tBySize [61]struct &#123;\t\t// Size 是当前尺寸级别可容纳的最大对象的 byte 大小。\t\tSize uint32\t\t// Mallocs 是分配到这个尺寸级别的堆内存对象的累积数量。\t\t// 累积分配的内存容量（bytes）可用：Size*Mallocs 进行计算。\t\t// 当前尺寸级别内存活的对象数量可以用 Mallocs - Frees 进行计算。\t\tMallocs uint64\t\t// Frees 是当前尺寸级别累积释放的堆内存对象的数量。\t\tFrees uint64\t&#125;&#125;\n\n使用初始化内存，减少gc周期测试代码\n​    可以看到这个代码很自由初始化240m内存的时候触发了GC，所以后续分配内存没有发生一次GC\n\nvar (\tbuffer = makeArr(240 &lt;&lt; 20) // 240m ,意思就是堆2*240M是不会触发gc的)var (\tappender = make([][]byte, 0, 100))// GODEBUG=gctrace=1func main() &#123;\tcount := 0\talloc := 4 &lt;&lt; 20\tfor x := 0; x &lt; 100; x++ &#123;\t\tappender = append(appender, makeArr(alloc))\t\tcount++\t\ttime.Sleep(time.Millisecond * 10)\t\t// 到50就回收历史的数据，那么内存达到 480m的时候就会触发gc，所以这个程序结束后内存使用一般是在480m左右\t\tif x == 50 &#123;\t\t\tfor index := range appender &#123;\t\t\t\tappender[index] = nil\t\t\t&#125;\t\t\tprintln(len(appender))\t\t&#125;\t&#125;&#125;func makeArr(len int) []byte &#123;\tfmt.Printf(&quot;分配堆内存: %dM\\n&quot;, len&gt;&gt;20)\tbytes := make([]byte, len)\tfor index, _ := range bytes &#123;\t\tbytes[index] = &#x27;x&#x27;\t&#125;\treturn bytes&#125;\n\n对比一下使用buffer和不使用buffer的gc总时间\n分配buffer的gc次数两次\ngc 1 @0.009s 0%: 0.016+191+0.034 ms clock, 0.064+0.007/0.13/191+0.13 ms cpu, 240-&gt;240-&gt;240 MB, 241 MB goal, 4 Pgc 2 @1.251s 0%: 0.030+8.8+0.025 ms clock, 0.12+0/0.13/8.6+0.10 ms cpu, 468-&gt;468-&gt;264 MB, 480 MB goal, 4 P# gc时间283700 302700 =586400 ns\n\n未分配buffer的gc\n# 工9次gc122800 81400 55000 78900 103200 39400 88400 66800 33900  = 669800 ns# 最后一次gcgc 9 @1.830s 0%: 0.016+2.2+0.017 ms clock, 0.066+0/0/2.2+0.069 ms cpu, 188-&gt;188-&gt;188 MB, 192 MB goal, 4 Pres: 263M, virt: 355M\n\n所以整体来说，gc时间基本一致，但是降低gc次数也是一个不错的选择\n参考https://xenojoshua.com/2019/03/golang-memory/\n","categories":["Golang"],"tags":["Golang","GC"]},{"title":"python学习笔记(基本语法+脚本)","url":"/2021/11/21/3f563fcaf31a49a8ecd1b956a4aa695a/","content":"​    个人学习python的笔记！基于 python3 ! 相关文档可以参考: https://docs.python.org/zh-cn/3/library/index.html , 本地可以执行python3 -m pydoc -p 1234 打开文档\n\n\n基本语法1. 简单控制语句\n字符串推荐用 &#39;&#39; 单引号引用\n\nlist: List[int] = [1, 2, 3]for elem in list:    if elem &gt; 1:        print(f&#x27;data &#123;elem&#125; &gt; 1&#x27;)  # 这里是format语句，属于语法糖    else:        print(f&#x27;data &#123;elem&#125; &lt; 1&#x27;)&#x27;&#x27;&#x27;data 1 &lt; 1data 2 &gt; 1data 3 &gt; 1&#x27;&#x27;&#x27;\n\n2. 异常x = -1try:    if x &lt; 0:        raise Exception(&quot;Sorry, no numbers below zero&quot;)except Exception as err:    print(&quot;find err: %s&quot; % err)&#x27;&#x27;&#x27;find err: Sorry, no numbers below zero&#x27;&#x27;&#x27; \n\n3. 推导式(比较晦涩难懂)\n参考： https://www.cnblogs.com/desireyang/p/12160332.html\n\n\n推导式好处: 效率更高，底层是c执行\n\n1. 列表推导式一共两种形式：(参考:  https://zhuanlan.zhihu.com/p/139621170) ， 它主要是输出是列表(list)\n\n[x for x in data if condition]  这里的含义是data只有满足if条件中的情况才保留 (if)\n\n[exp1 if condition else exp2 for x in data] ， 这里的含义是data满足if条件时执行exp1 否则 exp2 （if - else）\n\n\nimport re&quot;&quot;&quot;获取所有的数字&quot;&quot;&quot;list = [&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;]print([elem for elem in list if re.match(&quot;\\\\d&quot;, elem)])&#x27;&#x27;&#x27;[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;]&#x27;&#x27;&#x27;&quot;&quot;&quot;获取所有的字母&quot;&quot;&quot;print([elem for elem in list if re.match(&quot;[a-z]&quot;, elem)])&#x27;&#x27;&#x27;[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]&#x27;&#x27;&#x27;&quot;&quot;&quot;如果元素是数字则存储，否则则upper&quot;&quot;&quot;print([elem if re.match(&quot;\\\\d&quot;, elem) else elem.upper() for elem in list])&#x27;&#x27;&#x27;[&#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;]&#x27;&#x27;&#x27;\n\n最佳实践： 参考(https://github.com/httpie/httpie/blob/master/httpie/core.py#L235)\ndef decode_raw_args(        args: List[Union[str, bytes]],        stdin_encoding: str) -&gt; List[str]:    &quot;&quot;&quot;    Convert all bytes args to str    by decoding them using stdin encoding.    &quot;&quot;&quot;    return [        arg.decode(stdin_encoding)        if type(arg) is bytes else arg        for arg in args    ]def decode_raw_args_parse(        args: List[Union[str, bytes]],        stdin_encoding: str) -&gt; List[str]:    &quot;&quot;&quot;    Convert all bytes args to str    by decoding them using stdin encoding.    不使用推导式    &quot;&quot;&quot;    result: List[str] = []    for arg in args:        if type(arg) is bytes:            result.append(arg.decode(stdin_encoding))        else:            result.append(arg)    return result# arg.decode(stdin_encoding) if type(arg) is bytes else arg for arg in argsprint(decode_raw_args(args=[b&#x27;111&#x27;, b&#x27;222&#x27;], stdin_encoding=&quot;utf-8&quot;))print(decode_raw_args(args=[&quot;111&quot;, &quot;222&quot;], stdin_encoding=&quot;&quot;))&#x27;&#x27;&#x27;[&#x27;111&#x27;, &#x27;222&#x27;][&#x27;111&#x27;, &#x27;222&#x27;]&#x27;&#x27;&#x27;print(decode_raw_args_parse(args=[b&#x27;111&#x27;, b&#x27;222&#x27;], stdin_encoding=&quot;utf-8&quot;))print(decode_raw_args_parse(args=[&quot;111&quot;, &quot;222&quot;], stdin_encoding=&quot;&quot;))&#x27;&#x27;&#x27;[&#x27;111&#x27;, &#x27;222&#x27;][&#x27;111&#x27;, &#x27;222&#x27;]&#x27;&#x27;&#x27;\n\n2. 字典推导式&#123; key_expr: value_expr for value in collection if condition &#125;  ，输出是 dict\n&quot;&quot;&quot;&#123; key_expr: value_expr for value in collection if condition &#125;反转key value，且获取 value 为在set &#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125;中的元素&quot;&quot;&quot;dict_old = &#123;&#x27;a&#x27;: &#x27;A&#x27;, &#x27;b&#x27;: &#x27;B&#x27;, &#x27;c&#x27;: &#x27;C&#x27;, &#x27;d&#x27;: &#x27;D&#x27;&#125;print(&#123;dict_old[value]: value for value in dict_old if value in &#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125;&#125;)&#x27;&#x27;&#x27;&#123;&#x27;A&#x27;: &#x27;a&#x27;, &#x27;B&#x27;: &#x27;b&#x27;, &#x27;C&#x27;: &#x27;c&#x27;&#125;&#x27;&#x27;&#x27;print(&#123;key: value for value, key in dict_old.items() if value in &#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125;&#125;)&#x27;&#x27;&#x27;&#123;&#x27;A&#x27;: &#x27;a&#x27;, &#x27;B&#x27;: &#x27;b&#x27;, &#x27;C&#x27;: &#x27;c&#x27;&#125;&#x27;&#x27;&#x27;\n\n3. 集合推导式表达式:\n\n&#123; expr for value in collection if condition &#125; \n&#123;exp1 if condition else exp2 for x in data&#125;\n\n 输出是 set\n其实就是上面列表推导式 [] 换成 &#123;&#125; ，输出由 list 变成了 set\n4. for 循环 迭代器import osfrom collections.abc import Iterablewith open(&quot;text.log&quot;, &quot;wt&quot;) as file:    file.truncate()    file.writelines(&quot;line 1&quot; + os.linesep)    file.writelines(&quot;line 2&quot; + os.linesep)    file.writelines(&quot;line 3&quot; + os.linesep)    passwith open(&quot;text.log&quot;, &quot;rt&quot;) as file:    for line in file:        print(&quot;type: &#123;type&#125;, isinstance: &#123;isinstance&#125;, line: &#123;line&#125;&quot;.format(type=type(file),                                                                            isinstance=isinstance(file, Iterable),                                                                            line=line))    pass&#x27;&#x27;&#x27;type: &lt;class &#x27;_io.TextIOWrapper&#x27;&gt;, isinstance: True, line: line 1type: &lt;class &#x27;_io.TextIOWrapper&#x27;&gt;, isinstance: True, line: line 2type: &lt;class &#x27;_io.TextIOWrapper&#x27;&gt;, isinstance: True, line: line 3&#x27;&#x27;&#x27;\n\n这里面 _io.TextIOWrapper 实现了  __next__() 方法\n比如我们自己实现一个可迭代的对象\n\n下面可以看到我使用了类型申明 List[str] 其实这个python运行时并不会检测，需要工具进行检测！\n变量默认都是 Any 类型 ，具体可以看 https://docs.python.org/zh-cn/3/library/typing.html\n\nfrom typing import Listclass Items(object):    def __init__(self, list: List[str]):        self.list = list        self.index = 0    def __next__(self, *args, **kwargs):        &quot;&quot;&quot;        next，没有抛出StopIteration        &quot;&quot;&quot;        if self.index &gt;= len(self.list):            raise StopIteration        result = self.list[self.index]        self.index = self.index + 1        return result    def __iter__(self, *args, **kwargs):        &quot;&quot;&quot;        返回一个迭代器        &quot;&quot;&quot;        return selfdata = Items([&quot;1&quot;, &quot;2&quot;, &quot;3&quot;])for x in data:    print(x)&#x27;&#x27;&#x27;123&#x27;&#x27;&#x27;\n\n5. 包管理from ..a import foo  # 上级目录from .a import foo_a  # 当前目录import sys  # 引用源码或者libfrom copy import deepcopy  # 引用源码或者libfrom pygments.formatters.terminal import TerminalFormatter  # 引用 lib.lib.fileimport demo.utils.adef c_foo():    demo.utils.a.foo_a()    TerminalFormatter()    deepcopy()    print(sys.api_version)def b_foo():    foo()\n\n基本数据类型1. 定义方式\nmylist: list[str] = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]\nmylist=[&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]\n\n\n\n\nText Type:\nstr\n\n\n\nNumeric Types:\nint, float, complex\n\n\nSequence Types:\nlist, tuple, range\n\n\nMapping Type:\ndict\n\n\nSet Types:\nset, frozenset\n\n\nBoolean Type:\nbool\n\n\nBinary Types:\nbytes, bytearray, memoryview\n\n\n2. 数字基本类型x = 1  # inty = 1.1  # floatz = 1j  # 复数(complex)a = complex(1, 2)  # 复数(complex)print(type(x))print(type(y))print(type(z))print(z.imag, z.real)print(type(a))print(a.imag, a.real)&#x27;&#x27;&#x27;&lt;class &#x27;int&#x27;&gt;&lt;class &#x27;float&#x27;&gt;&lt;class &#x27;complex&#x27;&gt;1.0 0.0&lt;class &#x27;complex&#x27;&gt;2.0 1.0&#x27;&#x27;&#x27;\n\n3. 字符串str = &quot;hello&quot;print(str)print(str[0:])print(str[:5])print(str[:-1])print(str[0:5])print(str[0:5:1])print(str[0:5:2])&#x27;&#x27;&#x27;hellohellohellohellhellohellohlo&#x27;&#x27;&#x27;# formatprint(&quot;My name is &#123;&#125; and age is &#123;&#125;&quot;.format(&quot;tom&quot;, 18))&#x27;&#x27;&#x27;My name is tom and age is 18&#x27;&#x27;&#x27;quantity = 3itemno = 567price = 49.95myorder = &quot;I want to pay &#123;2&#125; dollars for &#123;0&#125; pieces of item &#123;1&#125;.&quot;print(myorder.format(quantity, itemno, price))&#x27;&#x27;&#x27;I want to pay 49.95 dollars for 3 pieces of item 567.&#x27;&#x27;&#x27;# funcstr = &quot;hello world! &quot;print(str.upper())print(str.lower())print(str.strip())print(str + &quot; ...&quot;)&#x27;&#x27;&#x27;HELLO WORLD! hello world! hello world!hello world!  ...&#x27;&#x27;&#x27;# formatmyorder = &quot;I have a &#123;carname&#125;, it is a &#123;model&#125;.&quot;print(myorder.format(carname=&quot;Ford&quot;, model=&quot;Mustang&quot;))&#x27;&#x27;&#x27;I have a Ford, it is a Mustang.&#x27;&#x27;&#x27;\n\n4. lambda其实就是一个func\ndef add(num):    return lambda x: x + numprint(add(10)(10))&#x27;&#x27;&#x27;20&#x27;&#x27;&#x27;\n\nlanbda 例子2\nimport jsonclass Obj:    def __init__(self):        self.name = &quot;tom&quot;        self.age = 1print(json.dumps(Obj(), default=lambda obj: obj.__dict__))&#x27;&#x27;&#x27;&#123;&quot;name&quot;: &quot;tom&quot;, &quot;age&quot;: 1&#125;&#x27;&#x27;&#x27;\n\n集合list, tuple, range, dict, set, frozenset\n\nlist , 例如: mylist = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]\ntuple 是特殊的数组，就是不能改变， 例如 mytuple = (&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;)\nrange 可以理解是个迭代器, 例如： \ndict 就是个map， 例如： thisdict = &#123;&quot;brand&quot;: &quot;Ford&quot;, &quot;model&quot;: &quot;Mustang&quot;, &quot;year&quot;: 1964&#125;\nset 就是个去重复的list , 例如： myset = &#123;&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;&#125;\n\n1. listmylist = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]# 切片print(mylist[0])print(mylist[2])print(mylist[-1])print(mylist[0:3:2])&#x27;&#x27;&#x27;applecherrycherry[&#x27;apple&#x27;, &#x27;cherry&#x27;]&#x27;&#x27;&#x27;# 基本操作mylist.append(&quot;orange&quot;)print(mylist)&#x27;&#x27;&#x27;[&#x27;apple&#x27;, &#x27;banana&#x27;, &#x27;cherry&#x27;, &#x27;orange&#x27;]&#x27;&#x27;&#x27;mylist.insert(0, &quot;mango&quot;)print(mylist)&#x27;&#x27;&#x27;[&#x27;mango&#x27;, &#x27;apple&#x27;, &#x27;banana&#x27;, &#x27;cherry&#x27;, &#x27;orange&#x27;]&#x27;&#x27;&#x27;# 循环for x in mylist:    print(x)&#x27;&#x27;&#x27;applebananacherryorange&#x27;&#x27;&#x27;for index in range(len(mylist)):    print(&quot;index: %d&quot; % index)&#x27;&#x27;&#x27;index: 0index: 1index: 2index: 3index: 4&#x27;&#x27;&#x27;if &quot;apple&quot; in mylist:    print(&quot;success!&quot;)&#x27;&#x27;&#x27;success!&#x27;&#x27;&#x27;# [执行表达式(也就是for循环中的，如果有if则是if中执行的), for item in list 条件表达式]new_list = [elem.upper() for elem in mylist if &quot;a&quot; in elem]  # contains &#x27;a&#x27; char elem strprint(new_list)&#x27;&#x27;&#x27;[&#x27;MANGO&#x27;, &#x27;APPLE&#x27;, &#x27;BANANA&#x27;, &#x27;ORANGE&#x27;]&#x27;&#x27;&#x27;newList = []for elem in mylist:    if &#x27;a&#x27; in elem:        newList.append(elem.upper())print(newList)&#x27;&#x27;&#x27;[&#x27;MANGO&#x27;, &#x27;APPLE&#x27;, &#x27;BANANA&#x27;, &#x27;ORANGE&#x27;]&#x27;&#x27;&#x27;\n\n2. mapthisdict = &#123;&quot;brand&quot;: &quot;Ford&quot;, &quot;model&quot;: &quot;Mustang&quot;, &quot;year&quot;: 1964&#125;for key, value in thisdict.items():    print(&quot;key: &#123;&#125;, value: &#123;&#125;&quot;.format(key, value))&#x27;&#x27;&#x27;key: brand, value: Fordkey: model, value: Mustangkey: year, value: 1964&#x27;&#x27;&#x27;for key in thisdict:    print(&quot;key: &#123;&#125;, value: &#123;&#125;&quot;.format(key, thisdict[key]))&#x27;&#x27;&#x27;key: brand, value: Fordkey: model, value: Mustangkey: year, value: 1964&#x27;&#x27;&#x27;\n\n3. range# range 会生成一个迭代器，(start,end,sep) ， 左闭右开for x in range(6):  # [0,1,2,3,4,5]    print(&quot;x is %d&quot; % x)&#x27;&#x27;&#x27;x is 0x is 1x is 2x is 3x is 4x is 5&#x27;&#x27;&#x27;for x in range(2, 6):    print(&quot;x is %d&quot; % x)&#x27;&#x27;&#x27;x is 2x is 3x is 4x is 5&#x27;&#x27;&#x27;for x in range(1, 6, 2):    print(&quot;x is %d&quot; % x)&#x27;&#x27;&#x27;x is 1x is 3x is 5&#x27;&#x27;&#x27;\n\n方法1. 定义一个空方法def func_1():    pass  # 空方法必须申明passfunc_1()\n\n2. 参数# name 为必须添的参数，不然为空会报错# age 为默认参数# agrs 为可变参数# kwargs 为 k v 参数def func_1(name, age=1, *args, **kwargs):    print(&quot;name: %s&quot; % name)    print(&quot;age: %d&quot; % age)    print(&quot;len(args): &#123;&#125;, type: &#123;&#125;&quot;.format(len(args), type(args)))    for value in args:        print(&quot;args value: &#123;&#125;&quot;.format(value))    print(&quot;len(kwargs): &#123;&#125;, type: &#123;&#125;&quot;.format(len(kwargs), type(kwargs)))    for key, value in kwargs.items():        print(&quot;kwargs key: &#123;&#125;, value: &#123;&#125;&quot;.format(key, value))func_1(name=&quot;tom&quot;, age=10, args=&quot;1&quot;, kwargs=&quot;2&quot;)&#x27;&#x27;&#x27;name: tomage: 10len(args): 0len(kwargs): 0, type: &lt;class &#x27;tuple&#x27;&gt;len(kwargs): 2, type: &lt;class &#x27;dict&#x27;&gt;kwargs key: args, value: 1kwargs key: kwargs, value: 2&#x27;&#x27;&#x27;# 这里注意由于dict所以不能申明kvfunc_1(&quot;tom&quot;, 10, &quot;1&quot;, &quot;2&quot;, args=&quot;1&quot;, kwargs=&quot;2&quot;)&#x27;&#x27;&#x27;name: tomage: 10len(args): 2, type: &lt;class &#x27;tuple&#x27;&gt;args value: 1args value: 2len(kwargs): 2, type: &lt;class &#x27;dict&#x27;&gt;kwargs key: args, value: 1kwargs key: kwargs, value: 2&#x27;&#x27;&#x27;\n\n3. 类型\n申明输入输出类型\n\nfrom typing import List, Uniondef decode_raw_args(    args: List[Union[str, bytes]],    stdin_encoding: str) -&gt; List[str]:    &quot;&quot;&quot;    Convert all bytes args to str    by decoding them using stdin encoding.    &quot;&quot;&quot;    return [        arg.decode(stdin_encoding)        if type(arg) is bytes else arg        for arg in args    ]\n\n类1. 定义类和方法# 如果没有父类继承，这里选择 object，比较规范class Person(object):    # gender none, male or female    gender = &quot;none&quot;    # 构造器    def __init__(self, name, age):        self.name = name        self.age = age    def my_name(self):        return self.namep = Person(name=&quot;tome&quot;, age=1)print(p.my_name())\n\n2. 类型的继承import jsonclass Person(object):    # gender none, male or female    gender = &quot;none&quot;    # 构造器    def __init__(self, name, age):        self.name = name        self.age = age    def my_name(self):        return self.namep = Person(name=&quot;tome&quot;, age=1)print(p.my_name())class Mail(Person):    def __init__(self, name, age):        super(Mail, self).__init__(name, age)        self.gender = &quot;mail&quot;    def my_name(self):        return self.name + &quot;_mail&quot;p = Mail(name=&quot;tome&quot;, age=1)print(json.dumps(p, default=lambda obj: obj.__dict__))print(p.my_name())\n\n3. 类 __new__ 函数\n主要是__init__ 执行前会调用\n\n#!/usr/bin/pythonimport jsonclass Person(object):    def __new__(cls, *args, **kwargs):        instance = object.__new__(cls)        instance.job = &quot;it&quot;        return instance    # construct    def __init__(self, name, age):        self.name = name        self.age = age    def to_json(self):        return json.dumps(self, default=lambda obj: obj.__dict__)p = Person(name=&quot;tome&quot;, age=1)print(p.to_json()) # &#123;&quot;age&quot;: 1, &quot;job&quot;: &quot;it&quot;, &quot;name&quot;: &quot;tome&quot;&#125;\n\n\n\n其他用法技巧1. 断言if type(1) is int:    print(&quot;args is int&quot;)    ...  # 等效 pass&#x27;&#x27;&#x27;args is int&#x27;&#x27;&#x27;\n\n2.  测试 &lt;&lt;&lt;可以参考文件: https://segmentfault.com/q/1010000010389542 , 属于doctest\ndef humanize_bytes(n, precision=2):    # Author: Doug Latornell    # Licence: MIT    # URL: https://code.activestate.com/recipes/577081/    &quot;&quot;&quot;Return a humanized string representation of a number of bytes.    &gt;&gt;&gt; humanize_bytes(1)    &#x27;1 B&#x27;    &gt;&gt;&gt; humanize_bytes(1024, precision=1)    &#x27;1.0 kB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 123, precision=1)    &#x27;123.0 kB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 12342, precision=1)    &#x27;12.1 MB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 12342, precision=2)    &#x27;12.05 MB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 1234, precision=2)    &#x27;1.21 MB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 1234 * 1111, precision=2)    &#x27;1.31 GB&#x27;    &gt;&gt;&gt; humanize_bytes(1024 * 1234 * 1111, precision=1)    &#x27;1.3 GB&#x27;    &quot;&quot;&quot;    abbrevs = [        (1 &lt;&lt; 50, &#x27;PB&#x27;),        (1 &lt;&lt; 40, &#x27;TB&#x27;),        (1 &lt;&lt; 30, &#x27;GB&#x27;),        (1 &lt;&lt; 20, &#x27;MB&#x27;),        (1 &lt;&lt; 10, &#x27;kB&#x27;),        (1, &#x27;B&#x27;)    ]    if n == 1:        return &#x27;1 B&#x27;    for factor, suffix in abbrevs:        if n &gt;= factor:            break    # noinspection PyUnboundLocalVariable    return f&#x27;&#123;n / factor:.&#123;precision&#125;f&#125; &#123;suffix&#125;&#x27;\n\n3. yield\n参考: https://zhuanlan.zhihu.com/p/268605982\n\n其实类似于程序的断电，比如程序运行到那里其实是返回一个生成器，然后当你下一步是才会执行，比较节省内存\nfrom typing import Listdef new(size: int = 1024 * 1024):    yield new_data(size)def new_data(size: int) -&gt; List[int]:    return [0] * sizedata = new()print(type(data))print(len(next(data)))  # 只能执行一次 next不然报错&#x27;&#x27;&#x27;&lt;class &#x27;generator&#x27;&gt;1048576&#x27;&#x27;&#x27;\n\n\n\n脚本base64输出echo &quot;aGVsbG8gcHl0aG9uCg==&quot; | python -c &quot;import sys,base64; print(sys.stdin.read())&quot;-&gt;echo &quot;aGVsbG8gcHl0aG9uCg==&quot; | python -c &quot;import sys,base64; print(base64.b64decode(sys.stdin.read()))&quot;-&gt; stdout:b&#x27;hello python\\n&#x27;\n\n文件操作\nr , w, x ,a四种类型(a: append, w=truncate+create, x=truncate+create if not exit)\nb,t 文件类型\n\n第一列可以和第二列文件类型组合，第一列不允许并存\nimport oswith open(&quot;file.log&quot;, &quot;w&quot;) as file:    for x in range(0, 100):        file.write(&quot;hello world&quot;+os.linesep)with open(&quot;file.log&quot;,&quot;r&quot;) as file:    for line in file.readlines():        print(line)\n\njsonimport jsonprint(json.dumps(&#123;&quot;k1&quot;: &quot;v1&quot;, &quot;k2&quot;: [1, 2, 3]&#125;))print(json.loads(&#x27;&#123;&quot;k1&quot;: &quot;v1&quot;, &quot;k2&quot;: [1, 2, 3]&#125;&#x27;))\n\n如果是class，需要继承 JSONEncoder和JSONDecoder实现子类 ，或者\nimport json, datetimeclass Demo(object):    def __init__(self, name: str, age: int, birthday: datetime.date):        self.name = name        self.agw = age        self.birthday = birthday    def to_json(self, _):        return &#123;&quot;name&quot;: self.name, &quot;age&quot;: self.agw, &quot;birthday&quot;: self.birthday.strftime(&quot;%Y-%m-%d&quot;)&#125;data = Demo(&quot;tom&quot;, 18, datetime.date(2001, 1, 1))print(json.dumps(data, default=data.to_json))\n\ntyping (申明类型)官方文档： https://docs.python.org/zh-cn/3/library/typing.html\n可以参考这篇文章： https://sikasjc.github.io/2018/07/14/type-hint-in-python/\n对于喜欢静态类型的语言，我觉得是非常nice的\nfrom typing import Dict, Listdef test(data: Dict[str, str]) -&gt; List[str]:    return [x for x in data]print(test(&#123;&quot;k1&quot;: &quot;v1&quot;, &quot;k2&quot;: &quot;v2&quot;&#125;))\n\n","categories":["Python"],"tags":["Python"]},{"title":"Java-ThreadLocal和InheritableThreadLocal的局限性以及如何在线程池模型中传递上下文","url":"/2021/03/10/4d9d26e79dde722bc37676b188b2f254/","content":"跨线程使用ThreadLocal 如何做？？？\n\n\nThreadLocal1、使用@Testpublic void testThreadLocal() &#123;    final ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();    new Thread(            () -&gt; &#123;                threadLocal.set(Thread.currentThread().getName());                System.out.println(&quot;current thread: &quot; + threadLocal.get()); // current thread: thread-1                threadLocal.remove();            &#125;            , &quot;thread-1&quot;)            .start();    new Thread(            () -&gt; &#123;                threadLocal.set(Thread.currentThread().getName());                System.out.println(&quot;current thread: &quot; + threadLocal.get()); // current thread: thread-2                threadLocal.remove();            &#125;            , &quot;thread-2&quot;)            .start();&#125;\n\n执行\ncurrent thread: thread-1current thread: thread-2\n\n可以看到线程是可以拿到 threadlocal中的变量\n2、threadlocal是否跨线程？@Testpublic void testThreadLocalWithChild() &#123;    final ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();    new Thread(            () -&gt; &#123;                threadLocal.set(Thread.currentThread().getName());                System.out.println(&quot;current thread: &quot; + threadLocal.get()); // current thread: thread-1                new Thread(() -&gt; &#123;                    System.out.println(&quot;child thread current thread: &quot; + threadLocal.get()); // child thread current thread: null                &#125;, &quot;thread-child-1&quot;).start();                threadLocal.remove();            &#125;            , &quot;thread-1&quot;)            .start();&#125;\n\n输出\ncurrent thread: thread-1current thread: thread-2\n\n可以看到跨线程后，我们无法拿到父亲线程的变量，所以thread无法解决跨线程\n3、问题\n使用简单，模型简单，如果普通业务完全满足，对于没有异步操作的业务都满足\n局限性就是多线程异步操作！\n\nInheritableThreadLocal1、简单实用\n​    它可以传递父线程的变量\n\n@Testpublic void testInheritableThreadLocal() &#123;    final InheritableThreadLocal&lt;Object&gt; threadLocal = new InheritableThreadLocal&lt;&gt;();    threadLocal.set(Thread.currentThread().getName());    Thread thread = new Thread(() -&gt; &#123;        System.out.println(&quot;current thread: &quot; + threadLocal.get());//current thread: main    &#125;);    thread.start();&#125;\n\n输出\ncurrent thread: main\n\n可以看到是可以拿到结果的，是如何实现的呢？\n2、InheritableThreadLocal 原理1、OBJECT_INHERITABLE_THREAD_LOCAL.set(Thread.currentThread().getName()); 到底执行了什么\njava.lang.ThreadLocal#set 方法：\npublic void set(T value) &#123;// 获取当前线程为main    Thread t = Thread.currentThread();// 去获取当前线程的map -&gt; t.threadLocals  显然是没有，因为没有threadlocal去绑定到main线程里    ThreadLocalMap map = getMap(t);    if (map != null)      // 有的话，就设置 thradlocal=&gt;value        map.set(this, value);    else    // 去创建一个map        createMap(t, value);&#125;\n\njava.lang.InheritableThreadLocal#createMap 重写了 java.lang.ThreadLocal#createMap \n# java.lang.ThreadLocal#createMapvoid createMap(Thread t, T firstValue) &#123;  // t.threadLocals  进行赋值，显然是线程捆绑对象罢了    t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;void createMap(Thread t, T firstValue) &#123;    t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);&#125;\n\n结论就是，inheritableThreadLocal进行set的时候会像thread线程绑定一个 k-v 对象，k就是 inheritableThreadLocal , v就是我们要的对象，然后如果线程的 inheritableThreadLocals 为空就初始化一下。注意ThreadLocalMap里有趣的WeakReference，值得测试一哈，如果真的内存满了，会回收线程的变量么？\n2、new Thread()\npublic Thread(Runnable target) &#123;        init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;\n\n继续\nprivate void init(ThreadGroup g, Runnable target, String name,                  long stackSize) &#123;    init(g, target, name, stackSize, null, true);&#125;\n\n继续\nprivate void init(ThreadGroup g, Runnable target, String name,                  long stackSize, AccessControlContext acc,                  boolean inheritThreadLocals) &#123;    if (name == null) &#123;        throw new NullPointerException(&quot;name cannot be null&quot;);    &#125;    this.name = name;    Thread parent = currentThread(); \t\t/// ................省略  \t  // 如果支持inheritThreadLocals &amp;&amp; 父线程的inheritableThreadLocals不为空，显然调用过java.lang.InheritableThreadLocal#set是会进行初始化的    if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null)      // 设置当前线程的inheritableThreadLocals为父类的，下面其实就是一个map拷贝        this.inheritableThreadLocals =            ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);    /* Stash the specified stack size in case the VM cares */    this.stackSize = stackSize;    /* Set thread ID */    tid = nextThreadID();&#125;\n\n3、局限性测试1、测试是否支持线程传递\n@Testpublic void testInheritableThreadLocalQuestion() throws InterruptedException &#123;    final InheritableThreadLocal&lt;Object&gt; threadLocal = new InheritableThreadLocal&lt;&gt;();    ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 10, 1000000, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;());    threadPoolExecutor.execute(() -&gt; &#123;        // 父线程set一个变量        threadLocal.set(&quot;parent&quot;);        threadPoolExecutor.execute(() -&gt; &#123;            // 子线程去拿，最后移除            System.out.println(&quot;child get thread name: &quot; + threadLocal.get());            threadLocal.remove();        &#125;);        // 最后父线程执行完毕去删除当前线程变量        threadLocal.remove();    &#125;);    if (!threadPoolExecutor.awaitTermination(5, TimeUnit.SECONDS)) &#123;        threadPoolExecutor.shutdown();    &#125;&#125;\n\n输出： child get thread name: parent\n这个现象显然是支持线程传递的，因为在传递过程中出现了创建线程，执行第二个execute时出现了线程池没有线程，然后去创建一个，就可以传递了，真实中线程池是基本保活的\n2、再次模拟\n@Testpublic void testInheritableThreadLocalQuestion2() throws InterruptedException &#123;    final InheritableThreadLocal&lt;Object&gt; threadLocal = new InheritableThreadLocal&lt;&gt;();    ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 2, 1000000, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;());    // 初始化线程池中的线程    threadPoolExecutor.execute(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    threadPoolExecutor.execute(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    TimeUnit.SECONDS.sleep(2);    // 测试    threadPoolExecutor.execute(() -&gt; &#123;        threadLocal.set(&quot;parent&quot;);        threadPoolExecutor.execute(() -&gt; &#123;            System.out.println(&quot;child get thread name: &quot; + threadLocal.get());            threadLocal.remove();        &#125;);        threadLocal.remove();    &#125;);    if (!threadPoolExecutor.awaitTermination(5, TimeUnit.SECONDS)) &#123;        threadPoolExecutor.shutdown();    &#125;&#125;\n\n输出：\nchild get thread name: null\n\n可以看到输出结果为null，是因为在执行测试任务的第二个execute的时候没有创建线程，也就是没有发生传递\n4、问题\n虽然InheritableThreadLocal可以解决跨线程传递的问题，但是它的局限性就是在于跨线程是必须创建新的线程\n业务中通常使用线程池模型(这里就不做解释了)，大多数实现的线程池无法满足调用时线程重复创建，所以无法\n\n线程池如何跨线程传递？参考Golang中的context.Context的实现，我们可以想到如果依赖ThreadLocal 和  InheritableThreadLocal 是不解决问题的，除非我们修改了 ThreadPoolExecutor 的源码，在每次调用的时候，将线程变量传递进去，其实也只能通过 Runnable函数进行传递了，因为对于线程池还是线程来说他们都需要传递 Runnable函数，所以考虑这个通用性最好！\n1、代码实现\n​    局限性就是依赖参数传递ThreadLocal，所以后期可以考虑加入多个ThreadLocal 或者 业务中通常依赖于Spring进行管理，所以可以对ThreadLocal进行bean的注入，全局使用spring的bean进行初始化ThreadLocalRunnable，那么参数传递其实只需要一个ApplicationContext\n\nprivate static class ThreadLocalRunnable&lt;T&gt; implements Runnable &#123;    private ThreadLocal&lt;T&gt; local;    private T args;    private Runnable runnable;    public ThreadLocalRunnable(ThreadLocal&lt;T&gt; local, Runnable runnable) &#123;        if (local == null || runnable == null) &#123;            throw new RuntimeException(&quot;new ThreadLocalRunnable find args has null arg&quot;);        &#125;        this.local = local;        // 初始化的时候获取绑定的线程变量        this.args = local.get();        this.runnable = runnable;    &#125;    /**     * 被new的线程/线程池中调度的线程调用     */    @Override    public void run() &#123;        try &#123;            // 设置绑定的线程变量            local.set(args);            runnable.run();        &#125; finally &#123;            // 移除绑定的线程变量            local.remove();        &#125;    &#125;&#125;\n\n2、测试代码@Testpublic void testThreadLocalRunnable() throws InterruptedException &#123;    final ThreadLocal&lt;Object&gt; threadLocal = new ThreadLocal&lt;&gt;();    ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 2, 1000000, TimeUnit.SECONDS, new SynchronousQueue&lt;&gt;());    // 初始化线程池中的线程    threadPoolExecutor.execute(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    threadPoolExecutor.execute(() -&gt; &#123;        try &#123;            TimeUnit.SECONDS.sleep(1);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;);    TimeUnit.SECONDS.sleep(2);    threadLocal.set(&quot;my name is main&quot;);    // 测试    threadPoolExecutor.execute(new ThreadLocalRunnable&lt;&gt;(threadLocal, () -&gt; &#123;        System.out.println(&quot;parent get thread name: &quot; + threadLocal.get());        threadLocal.set(&quot;my name is parent&quot;);        threadPoolExecutor.execute(new ThreadLocalRunnable&lt;&gt;(threadLocal, () -&gt; &#123;            System.out.println(&quot;child get thread name: &quot; + threadLocal.get());            threadLocal.remove();        &#125;));        threadLocal.remove();    &#125;));    if (!threadPoolExecutor.awaitTermination(5, TimeUnit.SECONDS)) &#123;        threadPoolExecutor.shutdown();    &#125;&#125;\n\n输出\nparent get thread name: my name is mainchild get thread name: my name is parent\n\n3、参考 spring的 ThreadPoolTaskExecutor其实就是一个包装模式的使用，给你一个Runnable，然后你去包装一个Runnable，依靠闭包去实现！\n@Configurationpublic class Config &#123;    @Bean    public Executor executor() &#123;        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();        executor.setThreadNamePrefix(ASYNC_EXECUTOR_NAME);        executor.setCorePoolSize(5);        executor.setMaxPoolSize(5);        executor.setQueueCapacity(-1);        // 这里在每次异步调用的时候, 会包装一下.        executor.setTaskDecorator(runnable -&gt; &#123;            // 这个时候还是同步状态            RequestAttributes requestAttributes = RequestContextHolder.currentRequestAttributes();            // 返回的这个 runnable对象 才是去调用线程池.            return () -&gt; &#123;                try &#123;                    // 我们set 进去 ,其实是一个ThreadLocal维护的.                    RequestContextHolder.setRequestAttributes(requestAttributes);                    runnable.run();                &#125; finally &#123;                    // 最后记得释放内存                    RequestContextHolder.resetRequestAttributes();                &#125;            &#125;;        &#125;);        return executor;    &#125;&#125;\n\n","categories":["Java"],"tags":["ThreadLocal","InheritableThreadLocal","线程池"]},{"title":"Docker学习","url":"/2020/09/26/58eb7a52b940359a191f97578179026e/","content":"​        学习docker的基本组件、dockerfile、docker命令等！\n\n\n官方文章：https://docs.docker.com/\ndocker 官方镜像地址： https://hub.docker.com/\n推荐阅读丛书 ： Docker实战(博文视点出品) ， 第一本Docker书 修订版\ndocker 快速安装： curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun , 记得用户设置在docker用户组！，推荐在非mac os/windows上玩。\n1、docker 的组成\n1、runcrunc实质上是一个轻量级的、针对Libcontainer进行了包装的命令行交互工具( Libcontainer取代了早期Docker架构中的LXC )。\n使用很简单，它是运行一个容器最基本的工具，所以我们需要创建容器。\ndocker中创建容器是，docker create docker-image-name ，但是需要导出到文件系统中\n# create the top most bundle directorymkdir /mycontainercd /mycontainer# create the rootfs directorymkdir rootfs# export busybox via Docker into the rootfs directorydocker export $(docker create busybox) | tar -C rootfs -xvf -runc spec# run as rootcd /mycontainerrunc run mycontainerid\n\n2、containerd对于docker进行拆分后，容器执行逻辑被重构到一个新的名为containerd (发音为container-dee) 的工具中。它的主要任务是容器的生命周期管理———— start | stop | pause | rm….\nDocker引擎技术栈中，containerd位于daemon和runc所在的OCI层之间。随着时间的推移，它被赋予了更多的功能，如镜像管理。虽然名叫containerd, 但是它并不负责创建容器，而是指挥runc去做。containerd将Docker镜像转换为OCI bundle,并让runc基于此创建一个新的容器。然后，runc与操作系统内核接口进行通信，基于所有必要的工具( Namespace、CGroup 等)来创建容器。容器进程作为runc的子进程启动，启动完毕后，runc 将会退出。\n\n​      将所有的用于启动、管理容器的逻辑和代码从daemon中移除，意味着容器运行时与Docker daemon是解耦的，有时称之为“无守护进程的容器(daemonless container)”,如此，对Docker daemon的维护和升级工作不会影响到运行中的容器。\n3、shimshim是实现无daemon的容器(用于将运行中的容器与daemon解耦，以便进行daemon升级等操作)不可或缺的工具。containerd 指挥runc来创建新容器。事实上,每次创建容器时它都会fork一个新的runc实例。不过，一旦容器创建完毕，对应的runc进程就会退出。因此，即使运行上百个容器，也无须保持上百个运行中的runc实例。一旦容器进程的父进程runc退出，相关联的containerd-shim 进程就会成为容器的父进程。\n作为容器的父进程，shim 的部分职责如下。\n\n保持所有STDIN和STDOUT流是开启状态，从而当daemon重启的时候,容器不会因为管道( pipe)的关闭而终止。\n将容器的退出状态反馈给daemon。\n\n4、daemondaemon的主要功能包括镜像管理、镜像构建、REST API、身份验证、安全、核心网络以及编排。\n2、Dockerfile 学习\n​    官方文档： https://docs.docker.com/engine/reference/builder/\n\n1、dockerfile 文件，基本玩法FROM alpine:latestMAINTAINER anthony-dong &quot;fanhaodong516@gamil.com&quot;RUN mkdir -p /opt/projectWORKDIR /opt/projectADD project.tar.gz .COPY run.sh .EXPOSE 8080VOLUME [ &quot;/opt/project&quot; ]ENV PROJECT_HOME /opt/projectENV PATH $PATH:$PROJECT_HOMECMD [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;run.sh&quot;]\n\n执行：\ndocker build -t test .docker run --rm -it test\n\n2、CMD 和 ENTRYPOINT 的区别\nCMD 和 ENTRYPOINT 的区别，这里其实区别很简单， 可以理解为 在没有启动命令是 ENTRYPOINT+ CMD （启动docker run时运行的默认命令）\n当我们 docker run image_name [cmd1] [cmd2] 时，其实已经把 Dokerfile中配置的CMD命令替换掉了，其实真正执行的是  ENTRYPOINT+ [cmd1]+ [cmd2]  ， 但是这俩CMD 和 ENTRYPOINT  都可以为空\n根据上面可以发现 CMD可以通过 docker run可以替换，那么 ENTRYPOINT 也是可以替换的，可以通过 -entrypoint 指定\n\nFROM alpine:latestENTRYPOINT [ &quot;ls&quot;]CMD [&quot;-al&quot;]\n\n比如上面找个，我们如果默认执行的话，会是：\n➜  kubernetes docker run --rm demo                 total 64drwxr-xr-x    1 root     root          4096 Jan 26 12:50 .// ...drwxr-xr-x    2 root     root          4096 Jan 14 11:49 optdr-xr-xr-x  226 root     root             0 Jan 26 12:50 proc\n\n但是如果我们添加了参数：\n➜  kubernetes docker run --rm demo -a...dockerenvbin//.... home\n\n修改 ENTRYPOINT\n➜  kubernetes docker run --rm --entrypoint env demoPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=4791b485ab53HOME=/root\n\n3、AND 和 COPY的区别AND 可以是多种source源，支持url/tar/unzip/文件包，所以看需求选择，比如使用tar包会自动解压\nCOPY 只能copy文件，所以一般推荐copy\n4、build 失败如何继续，如何调试！！FROM centos:centos7USER admin:adminCMD [ &quot;/bin/bash&quot; ]\n\n这个build是可以通过的！！！\n➜  docker-file-test docker build -t test-1 .Sending build context to Docker daemon  25.09kBStep 1/3 : FROM centos:centos7 ---&gt; 7e6257c9f8d8Step 2/3 : USER admin:admin ---&gt; Running in f8ed46bdda32Removing intermediate container f8ed46bdda32 ---&gt; 9611a153742eStep 3/3 : CMD [ &quot;/bin/bash&quot; ] ---&gt; Running in abc32bd8e245Removing intermediate container abc32bd8e245 ---&gt; 0f0f0aeeec29Successfully built 0f0f0aeeec29Successfully tagged test-1:latest\n\n然后运行\n➜  docker-file-test docker run --rm -it test-1docker: Error response from daemon: linux spec user: unable to find user admin: no matching entries in passwd file.\n\n发现这个，我们需要从Step 1/3开始！！！\n➜  docker-file-test docker run --rm -it  7e6257c9f8d8[root@532c8a693273 /]# useradd admin -p admin -d /home/admin --create-home -s /bin/bash[root@532c8a693273 /]# su admin[admin@532c8a693273 /]$ exitexit\n\n然后我们需要继续改dockerfile\nFROM centos:centos7RUN useradd admin -p admin -d /home/admin --create-home -s /bin/bashUSER admin:adminCMD [ &quot;/bin/bash&quot; ]\n\n继续运行\n➜  docker-file-test docker build -t test-1 .Sending build context to Docker daemon  25.09kBStep 1/4 : FROM centos:centos7 ---&gt; 7e6257c9f8d8Step 2/4 : RUN useradd admin -p admin -d /home/admin --create-home -s /bin/bash ---&gt; Running in f36f10b603bdRemoving intermediate container f36f10b603bd ---&gt; 843554e160f7Step 3/4 : USER admin:admin ---&gt; Running in 796341a1be27Removing intermediate container 796341a1be27 ---&gt; ab964ed78d8fStep 4/4 : CMD [ &quot;/bin/bash&quot; ] ---&gt; Running in 2c67de0242eaRemoving intermediate container 2c67de0242ea ---&gt; 17a4bc8d7206Successfully built 17a4bc8d7206Successfully tagged test-1:latest➜  docker-file-test docker run --rm -it 17a4bc8d7206[admin@55f84f22acf6 /]$\n\n这个就是一个简单的过程！！！！！！，这个好处是类似于调试的过程\n其实还可以通过 docker run -u 来制定用户，切记一点，别记忆命令！！，要记忆如何学习！！\n➜  docker-file-test docker run -it --rm --user root test-1[root@6dbeb01f5329 /]#\n\n5、安装一个Go的环境FROM centos:centos7MAINTAINER anthony-dong &quot;fanhaodong516@gamil.com&quot;# 添加文件地址ADD go1.13.15.linux-amd64.tar.gz /opt# 项目地址文件,安装工具RUN mkdir /opt/project \\    &amp;&amp; yum install -y vim \\    &amp;&amp; yum install  -y curl \\    &amp;&amp; yum install  -y git \\    &amp;&amp; yum install  -y wget# 环境变量    ENV GO_HOME &quot;/opt/go&quot;ENV PATH $PATH:$GO_HOME/bin# export端口EXPOSE 8080 EXPOSE 10010 # 直接启动bashCMD [ &quot;/bin/bash&quot;]\n\n然后执行， --tag 可以写成-t ，比如--tag go:1.13 意思就是镜像名称是go，版本是1.13，大致就是这个样子！ \ndocker build --file ./Dockerfile -p  --tag goenv1.13 .\n\n最后启动需要指定-t ，意思就是 --rm是容器被停止则被删除，-d是deamon启动， -it就是hold住类似于开启一个终端（i是输出，t是终端，然后程序就被hold住了）， -P暴漏端口随机到宿主机上， 最后指定使用的镜像\ndocker run --rm -d -it -P goenv1.13\n\n然后查看一下\n➜  test docker psCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                                               NAMESf67a0f2bcb0e        goenv1.13           &quot;/bin/bash&quot;         21 seconds ago      Up 19 seconds       0.0.0.0:32769-&gt;8080/tcp, 0.0.0.0:32768-&gt;10010/tcp   heuristic_lumiere\n\n6、多阶段构建\n​    Docker v17.05 开始支持多阶段构建 (multistage builds)， 参考：https://yeasy.gitbook.io/docker_practice/image/multistage-builds  , 主要命令就是 COPY --from=builder /data/apps/project/bin/app bin/\n但是业务中不推荐，很多时候要去容器里操作！\n\n还是一个Go项目，假如以一个Http-Server 为例子\n➜  pck tree -L 2.├── Dockerfile├── cmd│   └── main.go├── go.mod└── go.sum\n\n项目文件：\npackage mainimport (\t&quot;github.com/gin-gonic/gin&quot;\t&quot;log&quot;\t&quot;net/http&quot;)func main() &#123;\trouter := gin.Default()\trouter.GET(&quot;/echo&quot;, func(context *gin.Context) &#123;\t\tcontext.JSON(http.StatusOK, gin.H&#123;\t\t\t&quot;code&quot;:    0,\t\t\t&quot;data&quot;:    &quot;hello world&quot;,\t\t\t&quot;message&quot;: &quot;success&quot;,\t\t&#125;)\t&#125;)\tlog.Fatal(router.Run(&quot;:8080&quot;))&#125;\n\nDockerfile\n# 1.11+ 默认自动支持Go mod,切记builder的编译和运行的编译内核一致FROM  golang:1.13.15-alpine3.12 as builder# 全局变量，项目名称ARG GOPROXY=https://goproxy.cn,directENV GOPROXY=$&#123;GOPROXY&#125;WORKDIR /dataCOPY . .RUN go build -v -ldflags &quot;-s -w&quot; -o bin/app cmd/main.goFROM alpine:3.12 as runing# 切记环境变量不能共享ARG PROJECT_NAME=projectARG PROJECT_PORT=8080WORKDIR /data/$&#123;PROJECT_NAME&#125;COPY . .# 含义是 copy上一个镜像的 /data/$&#123;PROJECT_NAME&#125;/bin/app 文件到当前目录的binCOPY --from=builder /data/bin/app bin/# COPY --from=0 /opt/bin/app .EXPOSE $&#123;PROJECT_PORT&#125;CMD [ &quot;bin/app&quot; ]\n\n编译 ：(注意 alpine是不支持 race 的，会编译报错）\ndocker build -t test .\n\n启动:\n➜  my-docker docker run --rm -p 8080:8080 test  [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.[GIN-debug] [WARNING] Running in &quot;debug&quot; mode. Switch to &quot;release&quot; mode in production. - using env:   export GIN_MODE=release - using code:  gin.SetMode(gin.ReleaseMode)[GIN-debug] GET    /echo                     --&gt; main.main.func1 (3 handlers)[GIN-debug] Listening and serving HTTP on :8080\n\n查看大小：\n➜  my-docker docker imagesREPOSITORY              TAG                  IMAGE ID            CREATED             SIZEtest                    latest               fdbca700806f        8 minutes ago       17.8MBalpine                  latest               7731472c3f2a        6 days ago          5.61MB\n\n其实真实的Go的构建不是这种，一般都有打包机器，无须我们去找机器编译和运行\n7、构建多种系统架构支持的 Docker 镜像https://yeasy.gitbook.io/docker_practice/image/manifest\n3、Docker 限制资源压测程序,不准确，因为数组扩容，是十分消耗内存的，如果内存满了，无法申请内存，那么就不会打印消息！可以使用stress工具来测试CPU和内存。这里我也懒得下载！！\npackage mainimport (\t&quot;fmt&quot;\t&quot;os&quot;\t&quot;strconv&quot;\t&quot;time&quot;)var (\tref []byte)func main() &#123;\tfmt.Println(os.Getpid())\tmem, _ := strconv.ParseInt(os.Args[1], 10, 64)\tfor &#123;\t\tif mem == 0 &#123;\t\t\tmem = 1\t\t&#125;\t\tsize := 1024 * 1024 * mem\t\tnewSlice(size)\t\ttime.Sleep(time.Second)\t&#125;&#125;func newSlice(size int64) &#123;\tadd := make([]byte, size)\tref = append(ref, add...)                                                        // 分配size\tfmt.Println(fmt.Sprintf(&quot;%s  %v\\n&quot;, time.Now().Format(&quot;15:04:05&quot;), os.Getpid())) // 打印消息&#125;\n\n下面表示：表示在现在的内存是200M，cpu限制是1\n➜  go-demo docker run -it --rm --memory  200M  --cpuset-cpus=&quot;1&quot;  --oom-kill-disable -v /Users/dong/go/version/go-1.13.5:/opt/project ce2534430fc2 /bin/bash\n\n[root@17d356297d5f project]# go build -o bin/main study/slice/main2.go // .. 可以发现在45s的卡壳了，也就是内存被限制了08:52:44  10308:52:45  103top - 08:52:45 up  5:24,  0 users,  load average: 0.96, 1.45, 1.12Tasks:   4 total,   1 running,   3 sleeping,   0 stopped,   0 zombie%Cpu(s):  0.3 us,  3.0 sy,  0.0 ni, 93.3 id,  1.0 wa,  0.0 hi,  2.4 si,  0.0 stKiB Mem :  2046748 total,  1592784 free,   324656 used,   129308 buff/cache// 这些信息是假的，不能看KiB Swap:  1048572 total,   703508 free,   345064 used.  1582140 avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND  103 root      20   0  645568 200120     68 S  18.9  9.8   0:01.31 main // 200 m    1 root      20   0   11836   2400   2400 S   0.0  0.1   0:00.15 bash   51 root      20   0   11836   2332   2332 S   0.0  0.1   0:00.05 bash   71 root      20   0   56188   2016   1924 R   0.0  0.1   0:00.03 top\n\n查看docker容器真实的内存，可以\n➜  ~ docker stats 17d356297d5fCONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS17d356297d5f        cocky_shaw          0.00%               199.4MiB / 200MiB   99.69%              1.18kB / 0B         357MB / 927MB       7\n\n1、关于内存设置这几个参数的关系\n\n\n选项\n描述\n\n\n\n-m,--memory\n内存限制，格式是数字加单位，单位可以为 b,k,m,g。最小为 4M\n\n\n--memory-swap\n内存+交换分区大小总限制。格式同上。必须必-m设置的大\n\n\n--memory-reservation\n内存的软性限制。格式同上\n\n\n--oom-kill-disable\n是否阻止 OOM killer 杀死容器，默认没设置\n\n\n--oom-score-adj\n容器被 OOM killer 杀死的优先级，范围是[-1000, 1000]，默认为 0\n\n\n--memory-swappiness\n用于设置容器的虚拟内存控制行为。值为 0~100 之间的整数\n\n\n--kernel-memory\n核心内存限制。格式同上，最小为 4M\n\n\n –memory-swap 值必须比**–memory** 值大，因为：–memory-swap不是交换分区，而是内存加交换分区的总大小\n1. 不设置如果不设置-m,–memory和–memory-swap，容器默认可以用完宿舍机的所有内存和 swap 分区。不过注意，如果容器占用宿主机的所有内存和 swap 分区超过一段时间后，会被宿主机系统杀死（如果没有设置–00m-kill-disable=true的话）。\n2. 设置-m,–memory，不设置–memory-swap给-m或–memory设置一个不小于 4M 的值，假设为 a，不设置–memory-swap，或将–memory-swap设置为 0。这种情况下，容器能使用的内存大小为 a，能使用的交换分区大小也为 a。因为 Docker 默认容器交换分区的大小和内存相同。\n如果在容器中运行一个一直不停申请内存的程序，你会观察到该程序最终能占用的内存大小为 2a。\n比如$ docker run -m 1G ubuntu:16.04，该容器能使用的内存大小为 1G，能使用的 swap 分区大小也为 1G。容器内的进程能申请到的总内存大小为 2G。\n3. 设置-m,–memory=a，–memory-swap=b，且b &gt; a给-m设置一个参数 a，给–memory-swap设置一个参数 b。a 时容器能使用的内存大小，b是容器能使用的 内存大小 + swap 分区大小。所以 b 必须大于 a。b -a 即为容器能使用的 swap 分区大小。\n比如$ docker run -m 1G –memory-swap 3G ubuntu:16.04，该容器能使用的内存大小为 1G，能使用的 swap 分区大小为 2G。容器内的进程能申请到的总内存大小为 3G。\n4. 设置-m,–memory=a，–memory-swap=-1给-m参数设置一个正常值，而给–memory-swap设置成 -1。这种情况表示限制容器能使用的内存大小为 a，而不限制容器能使用的 swap 分区大小。\n这时候，容器内进程能申请到的内存大小为 a + 宿主机的 swap 大小。\n2、cpu限制➜  ~ docker run --helpUsage:\tdocker run [OPTIONS] IMAGE [COMMAND] [ARG...]Run a command in a new containerOptions:      --add-host list                  Add a custom host-to-IP mapping (host:ip)  -c, --cpu-shares int                 CPU shares (relative weight)      --cpus decimal                   Number of CPUs      --cpuset-cpus string             CPUs in which to allow execution (0-3, 0,1)      --cpuset-mems string             MEMs in which to allow execution (0-3, 0,1)\n\n\n\n\n选项\n描述\n\n\n\n--cpuset-cpus=&quot;&quot;\n允许使用的 CPU 集，值可以为 0-3,0,1\n\n\n-c,--cpu-shares=0\nCPU 共享权值（相对权重）\n\n\ncpu-period=0\n限制 CPU CFS 的周期，范围从 100ms~1s，即[1000, 1000000]\n\n\n--cpu-quota=0\n限制 CPU CFS 配额，必须不小于1ms，即 &gt;= 1000\n\n\n--cpuset-mems=&quot;&quot;\n允许在上执行的内存节点（MEMs），只对 NUMA 系统有效\n\n\n关于CFS的概念： https://www.jianshu.com/p/1da5cfd5cee4 \n后端基本不需要关注cpu，因为本身不是cpu密集型业务，基本都是io密集型/内存密集型。\n4、docker push 命令\n1、docker hub，类似于git一样，比如很多私人仓库，默认是 hub.docker.com， 比如覆盖则 docker login aliyun.docker.com 等等\n\ndocker login\n\n输入姓名，输入密码\n\n2、 查看推送的镜像\n\ndocker images go1.13.15        latest       ce2534430fc2    26 minutes ago   769MB\n\n\n3、第一步需要打tag\n\n一般是 : docker tag &lt;镜像名称&gt; &lt;用户名&gt;/&lt;镜像名称&gt;:&lt;镜像版本号&gt;\ndocker tag go1.13.15 fanhaodong/go1.13.15:v1.0\n\n\n4、push\n\n命令： docker push &lt;用户名&gt;/&lt;镜像名称&gt;:&lt;镜像版本号&gt;\ndocker push fanhaodong/go1.13.15:v1.0\n\n5、docker 其他命令1、docker builddocker build  --build-arg arg=value --file Dockerfile_path --tag name:version  build_path\nFROM alpine:latest# 变量 = 默认值ARG IMG_V=1.0 ENV IMG_V=$&#123;IMG_V&#125;CMD [ &quot;sh&quot;,&quot;-c&quot;,&quot;env&quot; ]\n\n执行：\n➜  docker-file-test docker build --tag test:v1 --file ./Dockerfile --build-arg IMG_V=2.0 .Sending build context to Docker daemon  20.99kBStep 1/4 : FROM alpine:latest ---&gt; a24bb4013296Step 2/4 : ARG IMG_V=1.0 ---&gt; Running in bd247961f4c5Removing intermediate container bd247961f4c5 ---&gt; 48608560ae13Step 3/4 : ENV IMG_V=$&#123;IMG_V&#125; ---&gt; Running in 0ccb1c5aef84Removing intermediate container 0ccb1c5aef84 ---&gt; 45d309fc4a52Step 4/4 : CMD [ &quot;sh&quot;,&quot;-c&quot;,&quot;env&quot; ] ---&gt; Running in 6d266d8d8301Removing intermediate container 6d266d8d8301 ---&gt; d4ccf528c0edSuccessfully built d4ccf528c0edSuccessfully tagged test:v1➜  docker-file-test docker run --rm test:v1HOSTNAME=59991997b9beSHLVL=1HOME=/rootIMG_V=2.0PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binPWD=/\n\n可以看到成功 执行了环境变量！\n2、docker run传递envFROM alpine:latestaCMD [ &quot;sh&quot;,&quot;-c&quot;,&quot;env&quot; ]\n\n[admin@centos-linux docker-file-test]$ docker build -t test-1 .Sending build context to Docker daemon  23.04kBStep 1/2 : FROM alpine:latest ---&gt; a24bb4013296Step 2/2 : CMD [ &quot;sh&quot;,&quot;-c&quot;,&quot;env&quot; ] ---&gt; Running in 65c81ab9dc1fRemoving intermediate container 65c81ab9dc1f ---&gt; 027268ad86eeSuccessfully built 027268ad86eeSuccessfully tagged test-1:latest[admin@centos-linux docker-file-test]$ docker run --env demo=1 test-1HOSTNAME=d4504e8ef3beSHLVL=1HOME=/rootPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bindemo=1PWD=/\n\n传递环境变量，是可以到运行时！\n3、docker  start\n\nshell脚本启动#!/bin/bash# 获取cidCID=$(docker create --rm test-1)# 根据cid启动docker start $CID# flagecho &quot;start success!!!!&quot;\n\n运行\n[admin@centos-linux docker-file-test]$ bash new.shdd9159e2d3da614f6dc7f816300d75ad58c6acf673eb9bea1e8a3f3af60a4137start success!!!!\n\ngood 启动了 ！！！\n5、挂载docker run --rm -v /opt test-3\n如果容器销毁，宿主机文件也会被销毁！！！！\n&quot;Mounts&quot;: [  &#123;      &quot;Type&quot;: &quot;volume&quot;,      &quot;Name&quot;: &quot;79c49a14a84ce8f6ba852e11d91a109ac1c02a6649e83f68b316990404035148&quot;,      &quot;Source&quot;: &quot;/var/lib/docker/volumes/79c49a14a84ce8f6ba852e11d91a109ac1c02a6649e83f68b316990404035148/_data&quot;,// 宿主机目录      &quot;Destination&quot;: &quot;/opt&quot;, // 容器目录      &quot;Driver&quot;: &quot;local&quot;,      &quot;Mode&quot;: &quot;&quot;,      &quot;RW&quot;: true,      &quot;Propagation&quot;: &quot;&quot;  &#125;],&quot;Volumes&quot;: &#123;      &quot;/home/admin/dong/docker/docker-file-test&quot;: &#123;&#125;  &#125;,\n\ndocker run --rm -v /home/admin/dong/docker/docker-file-te/:/opt test-3\n&quot;Mounts&quot;: [    &#123;        &quot;Type&quot;: &quot;bind&quot;,        &quot;Source&quot;: &quot;/home/admin/dong/docker/docker-file-test&quot;,        &quot;Destination&quot;: &quot;/opt&quot;,        &quot;Mode&quot;: &quot;&quot;,        &quot;RW&quot;: true,        &quot;Propagation&quot;: &quot;rprivate&quot;    &#125;],\n\n6、docker commit\n​    这个比较适合不会写docker file的人，这里我举个例子，假如现在我们有一个centos:7\n\ndocker pull centos:7\n\n其次，我们要安装一个curl命令\n➜  /data docker run --rm -it 7e6257c9f8d8  /bin/bash[root@bcdaea8354a6 /]# yum install -y curl[root@bcdaea8354a6 /]# curl www.baidu.com&lt;!DOCTYPE html&gt; // good\n\n此时我们只需要进行\n➜  ~ docker ps -a -lCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMESbcdaea8354a6        7e6257c9f8d8        &quot;/bin/bash&quot;         2 minutes ago       Up 2 minutes                            happy_liskov➜  ~ docker commit bcdaea8354a6  demo-2sha256:350fbf288cb1a47a29e3d8e441e2814726de6faf54d044a585fb80b7a1f38f83\n\n这个镜像就OK了，就可以使用 demo-2的镜像了\n","categories":["云原生"],"tags":["Docker"]},{"title":"用markdown画流程图和时序图","url":"/2022/03/27/583186f06a088dc9967a483e3876b2a2/","content":"​    markdown 目前已经成为轻量级编辑器的代表，依靠markdown可以解决日常生活中写文档的基本需求，并且对于一些日常使用的流程图和序列图也有一定的支持！目前本人使用的是 Typora 写个人文章，在公司内用的是飞书文档，基本都是markdown语法！而使用目前比较好用的ProcessOn（网页版）、Visio/PowerPoint(microsoft) 、Draw.io(开源)使用下来的体验就是文章和流程图分离！也就是导致使用体验大打折扣，目前飞书文档支持的PlantUML很不错！我个人一般是PlantUML和Mermaid！\n\n\n1. UML1. 基本介绍​    UML 是统一建模语言的简称，它是一种由一整套图表组成的标准化建模语言。UML用于帮助系统开发人员阐明，展示，构建和记录软件系统的产出。UML代表了一系列在大型而复杂系统建模中被证明是成功的做法，是开发面向对象软件和软件开发过程中非常重要的一部分。UML主要使用图形符号来表示软件项目的设计，使用UML可以帮助项目团队沟通、探索潜在的设计和验证软件的架构设计。以下我们将向您详细介绍什么是UML、UML的历史以及每个UML图类型的描述，辅之以UML示例。\n2. 作用\n为用户提供现成的、有表现力的可视化建模语言，主要就是可视化，直观！！\n逻辑思维的整理吧，如果你可以画图清晰的表述出逻辑，那么一定方案可执行会很好！\n画图也是一门学问和技巧！\n\n3. 分类大概上有13种，下面我列出我们常用的！\n\n1. 结构图1. 类图 (Class Diagram)\n\n\n2. 行为性图1. 活动图 (Activity Diagram)\n 这里主要多了一个概念叫做泳道，泳道可以很好的隔离开流程！\n\n\n\n2. 状态机图 (State Machine Diagram)\n其实这个就和流程图！\n\n\n\n\n3. 序列图 (Sequence Diagram)\n\n2. 流程图 (Flow Chart)markdown 支持流程图(Flow Chart) 是用的开源的 flowchart 语法进行的支持!  流程图一般是用来清晰的表达出流程逻辑的一个可视化工具，比如你要跟同事沟通一个技术方案，你文档文字写的满满的，但是导致有些专业性的隔阂或者你表述不清晰，导致同事很难理解你在说什么，这时候可能就需要流程图进行弥补下！\n1. 简单语法介绍流程图一般有几个关键的节点，也一般是开始和结束两个节点！其次是有多个不同类型的节点组成！具体可以看官方文档: flowchart\n节点定义语法如 : 节点名称=&gt;节点类型: 节点显示的内容[:&gt; 超链接URL]  是空格敏感的！\n1. 节点类型节点类型主要有:  常用的其实就前5个\n\nstart (开始)\n\nend （结束）\n\noperation （操作节点，表示你要执行的步骤，比如平时顺序结构 步骤A-&gt;步骤B-&gt;步骤C）\n\ncondition （条件节点，表示判断条件）\n\ninputoutput （输入输出节点，类似于前端的input框，输入个账户名称和密码之类的！）\n\nsubroutine（子流程，即表示一个流程，但是流程比较复杂，直接通过自流程代替，表示这块逻辑只是没有展开而已，其实很复杂！）\n\nparallel （并行流，允许多个流程同时发生）\n\n\n2. 流程控制类型说明符:\n\n基本操作流: startVar(&lt;direction&gt;)-&gt;nextNode\n\ndirection 表示方位，有left、right、top、bottom \n\npreviousNode-&gt;endVar\n\noperationVar(&lt;direction&gt;)-&gt;nextNode\n\ninputoutputVar(&lt;direction&gt;)-&gt;nextNode\n\nsubroutineVar(&lt;direction&gt;)-&gt;nextNode\n\nconditionalVar(yes, &lt;direction&gt;)-&gt;nextNode1\n\nconditionalVar(no,  &lt;direction&gt;)-&gt;nextNode2\n\nparallel 控制流介绍\n\n\nparallelVar(path1, &lt;direction&gt;)-&gt;nextNode1parallelVar(path2, &lt;direction&gt;)-&gt;nextNode2parallelVar(path3, &lt;direction&gt;)-&gt;nextNode3\n\n\ncondition 控制流介绍\n\n# @ 表示覆写描述，比如正在这个line上描述的是true，@可以覆写描述为 正确cond(true@正确)-&gt;io-&gt;e\n\n3. 官方例子介绍下图为官方介绍的流程图：\nst=&gt;start: Start:&gt;http://www.google.com[blank]e=&gt;end:&gt;http://www.google.comop1=&gt;operation: My Operationsub1=&gt;subroutine: My Subroutinecond=&gt;condition: Yesor No?:&gt;http://www.google.comio=&gt;inputoutput: catch something...para=&gt;parallel: parallel tasksst-&gt;op1-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;parapara(path1, bottom)-&gt;sub1(right)-&gt;op1para(path2, top)-&gt;op1\n\n展示效果如下: \n\n\n2. 简单例子介绍例如一个网关发布(分级发布)的前置流程，主要就是用户选择发布版本，然后进行判断，提交发布信息的流程，流程图如下:\n我觉得flowchart好处就是可以像写代码一样，清晰的描述流程图，要比 mermaid实用的多！\nstart=&gt;start: 开始流程end=&gt;end: 结束select_publish_version=&gt;inputoutput: 输入/选择发布版本op_start_publish=&gt;operation: 点击开始发布cond_publish_version=&gt;condition: 判断版本是否已经发布测试环境op_throw_error=&gt;operation: 抛出异常(当前版本x.x.x未经过测试环境验证，不允许发布)op_load_publish_list=&gt;operation: 加载测试环境发布成功的工单select_tlb_path=&gt;inputoutput: 选择TLB发布集群以及分流策略select_agw_env=&gt;inputoutput: 选择AGW发布环境op_submit=&gt;operation: 提交发布信息start-&gt;select_publish_version-&gt;op_start_publish-&gt;cond_publish_versioncond_publish_version(no@否)-&gt;op_throw_error-&gt;endcond_publish_version(yes@是)-&gt;op_load_publish_list-&gt;select_tlb_path-&gt;select_agw_env-&gt;op_submit-&gt;end\n\n\n\n\n\n\n\n3. PlantUML（UML）markdown 支持时序图基本上用的都是 PlantUML ！ 目前飞书文档支持使用 PlantUML ，但是我个人使用的typora不支持，而且我的博客也不支持，所以目前主流的解决方案就是通过网站:https://g.gravizo.com/  画 svg 实现！\n不过可以配合 vscode进行使用！不过我觉得PlantUML渲染比较棒！\n@startuml;actor User;participant &quot;First Class&quot; as A;participant &quot;Second Class&quot; as B;participant &quot;Last Class&quot; as C;User -&gt; A: DoWork;activate A;A -&gt; B: Create Request;activate B;B -&gt; C: DoWork;activate C;C --&gt; B: WorkDone;destroy C;B --&gt; A: Request Created;deactivate B;A --&gt; User: Done;deactivate A;@enduml\n\n\n\n4. Mermaid （UML）1. 流程图(flowchart)\n头部需要定义 graph|flowchart  [direction] ， 其中direction 主要由 LR 和 TB 组合上下左右！\n内容部分只需要定义流程即可\na --&gt; b --&gt; c 表示 顺序引用\na --&gt; |注释|b 表示 a -&gt; b 中间需要加注释\na(show_name) 表示 a需要通过 show_name 进行展示，也就是节点内容\n\n\n单向箭头主要有 --&gt;实线， -.-&gt; 虚线，==&gt; 加粗线； 双向箭头就是 &lt;==&gt;和…， 无箭头是 == ，很形象！\n节点可以通过 &#123;condition name&#125; 和 [operation name] 和 (start|end name) 和 ((multi condition name)) 进行渲染形状！\n和上面我们讲的 flowchart区别就是他不需要再去定义节点了！但是这个流程图定义的并不严格！\n\n1. 普通流程图例子1:\ngraph LR\ta--&gt;|注释|b(开始结束类型)--&gt;c[operation类型] --&gt;d&#123;condition类型&#125; -.-&gt;|虚线|e((圆型节点))==&gt;|加粗线|f &lt;--&gt; |双向箭头|g(end)\n\ngraph LR\n    a-->|注释|b(开始结束类型)-->c[operation类型] -->d{condition类型} -.->|虚线|e((圆型节点))==>|加粗线|f  |双向箭头|g(end)\n\n例子2:\ngraph LR  A&#123;A&#125; --&gt; |a-&gt;b普通线|B(B)  B --&gt; C --&gt; F((F)) --&gt; |输入|G&gt;G] --&gt; D   C --&gt; D  A ==&gt; |a-&gt;d block|D(D)  A --&gt; |a-&gt;e 注释|E[e注释]  E -.-&gt; |e-d 虚线|D\n\ngraph LR\n  A{A} --> |a->b普通线|B(B)\n  B --> C --> F((F)) --> |输入|G>G] --> D \n  C --> D\n  A ==> |a->d block|D(D)\n  A --> |a->e 注释|E[e注释]\n  E -.-> |e-d 虚线|D\n\n例子3:\nflowchart LRA[Hard] &lt;--&gt;|Text| B(Round)B --&gt; C&#123;Decision&#125;C --&gt;|One| D[Result 1]C --&gt;|Two| E[Result 2]\n\nflowchart LR\nA[Hard] |Text| B(Round)\nB --> C{Decision}\nC -->|One| D[Result 1]\nC -->|Two| E[Result 2]\n\n例子4: 可以通过关键字 &amp; 来表示 a-&gt;c , b-&gt;d, c-&gt;d\nflowchart LR   a --&gt; b &amp; c--&gt; d\n\nflowchart LR\n   a --> b & c--> d\n\n2. 子图表可以通过 subgraph 名称+end关键字来构建子图标，你可以理解为就是加了个框框！可以区分流程图\ngraph LR\t\ta(a) --&gt; b\t\tsubgraph one模块\t\tb --&gt; c\t\tend\t\tc --&gt; d\t\tsubgraph two模块\t\td --&gt; e\t\tend\t\te --&gt; f(f)\n\ngraph LR\n        a(a) --> b\n        subgraph one模块\n        b --> c\n        end\n        c --> d\n        subgraph two模块\n        d --> e\n        end\n        e --> f(f)\n\n\n\n\n\n2. 序列图 （Sequence Diagram）时序图由简称UML图，\n\n首先需要定义参与者： participant [name] as [show_name]  或者直接 participant name , 或者可以直接不定义participant\n连接线: -&gt;&gt; 实线，--&gt;&gt; 虚线，一般请求用实线，return 用虚线，\n + 和 -表示加入会话[activate]和结束会话[deactivate]，例如 a -&gt; + b 表示b开启会话（会话是俩人都可以开启的，这个a-&gt;&gt;+b只是表示b开启，如果a也要开启，需要 activate a），例如 activate a表示a开启会话!\n添加node: Note 位置描述 参与者: 标注文字 \n\n# over a,b,c 多个人# left of a  单个人# right of a 单个人Note over John,Alice: note: 嘻嘻嘻 😊！Note left of John: Text in noteNote right of John: Text in note\n\n1. 普通序列图例子一：\nsequenceDiagram\tparticipant Alice as Alice # 定义参与者： participant [name] as [show_name]\tparticipant John # 定义参与者: participant [name]\tAlice-&gt;&gt; + John: Hello John, how are you? # 表示和john进行会话，同时a和j开始会话\tJohn--&gt;&gt; Alice: Great! \tNote over John,Alice: note: 嘻嘻嘻，over 😊！ # 表示添加注释\tNote left of John: note: 嘻嘻嘻, left 😊!\tNote right of John: note: 嘻嘻嘻, wright 😊!\t\tAlice-&gt;&gt; John: Hi John, I can hear you!\tJohn--&gt;&gt; - Alice: I feel great! # 表示john断开了会话\n\n\n\nsequenceDiagram\n    participant Alice as Alice # 定义参与者： participant [name] as [show_name]\n    participant John # 定义参与者: participant [name]\n    Alice->> + John: Hello John, how are you? # 表示和john进行会话，同时a和j开始会话\n    John-->> Alice: Great! \n    Note over John,Alice: note: 嘻嘻嘻，over 😊！ # 表示添加注释\n    Note left of John: note: 嘻嘻嘻, left 😊!\n    Note right of John: note: 嘻嘻嘻, wright 😊!    \n    Alice->> John: Hi John, I can hear you!\n    John-->> - Alice: I feel great! # 表示john断开了会话\n\n\n\n2. 序列图例子例子2： \nsequenceDiagram\tparticipant fe as 小程序\tparticipant service as 服务器\tparticipant wx_service as 微信服务器\tloop 失败重试\t\tfe -&gt;&gt; fe: wx.login()获取code\tend\tfe -&gt;&gt; service: wx.request() 发送code\tactivate service\tservice -&gt;&gt; wx_service: 发送code+appid+签名\tactivate wx_service\twx_service --&gt;&gt; service: 返回code id\tdeactivate wx_service\tservice -&gt;&gt; service: 生成token\tservice --&gt;&gt; fe: 返回token\tdeactivate service\n\nsequenceDiagram\n    participant fe as 小程序\n    participant service as 服务器\n    participant wx_service as 微信服务器\n    loop 失败重试\n        fe ->> fe: wx.login()获取code\n    end\n    fe ->> service: wx.request() 发送code\n    activate service\n    service ->> wx_service: 发送code+appid+签名\n    activate wx_service\n    wx_service -->> service: 返回code id\n    deactivate wx_service\n    service ->> service: 生成token\n    service -->> fe: 返回token\n    deactivate service\n\n5. 参考\nUML整体概述\nUML时序图(Sequence Diagram)学习笔记st=>start: Start:> http://www.google.com[blank]\ne=>end: End :>http://www.google.com\nop1=>operation: My Operation\nsub1=>subroutine: My Subroutine\ncond=>condition: Yes\nor No?:>http://www.google.com\nio=>inputoutput: catch something...\npara=>parallel: parallel tasks\n\nst->op1->cond\ncond(yes)->io->e\ncond(no)->para\npara(path1, bottom)->sub1(right)->op1\npara(path2, top)->op1{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12}  var code = document.getElementById(\"flowchart-0-code\").value;  var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-0-options\").value));  var diagram = flowchart.parse(code);  diagram.drawSVG(\"flowchart-0\", options);start=>start: 开始流程\nend=>end: 结束\nselect_publish_version=>inputoutput: 输入/选择发布版本\nop_start_publish=>operation: 点击开始发布\ncond_publish_version=>condition: 判断版本是否\n已经发布测试环境\nop_throw_error=>operation: 抛出异常\n(当前版本x.x.x未经过测试环境验证，不允许发布)\nop_load_publish_list=>operation: 加载测试环境发布成功的工单\nselect_tlb_path=>inputoutput: 选择TLB发布集群以及分流策略\nselect_agw_env=>inputoutput: 选择AGW发布环境\nop_submit=>operation: 提交发布信息\n\nstart->select_publish_version->op_start_publish->cond_publish_version\ncond_publish_version(no@否)->op_throw_error->end\ncond_publish_version(yes@是)->op_load_publish_list->select_tlb_path->select_agw_env->op_submit->end{\"scale\":1,\"line-width\":2,\"line-length\":50,\"text-margin\":10,\"font-size\":12}  var code = document.getElementById(\"flowchart-1-code\").value;  var options = JSON.parse(decodeURIComponent(document.getElementById(\"flowchart-1-options\").value));  var diagram = flowchart.parse(code);  diagram.drawSVG(\"flowchart-1\", options);\n\n","categories":["工具"],"tags":["工具","Mermaid","UML","流程图"]},{"title":"grpc","url":"/2021/11/29/5d738324e2189d8e9a1c3974d34f5a95/","content":"​    学习grpc文件\n\n\n1、rpc1、wikipedia概念在分布式计算，远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一个地址空间（通常为一个开放网络的一台计算机）的子程序，而程序员就像调用本地程序一样，无需额外地为这个交互作用编程（无需关注细节）。RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。\n如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用，例：Java RMI。\nRPC是一种进程间通信的模式，程序分布在不同的地址空间里。如果在同一主机里，RPC可以通过不同的虚拟地址空间（即便使用相同的物理地址）进行通讯，而在不同的主机间，则通过不同的物理地址进行交互。许多技术（常常是不兼容）都是基于这种概念而实现的。\n\n2、http和rpc的区别1、http指的是一个应用层协议，它提供的只是一个传输协议\n2、rpc讲的是一个远程过程调用，它是一个过程，一个rpc架构包含了多个层级，以dubbo的架构来\nrpc其实架构很简单，就是下面一图，但是具体实现上差异还是有点，比如我们所了解的 http + json 只能说是dubbo 只能说是dubbo的最下层实现，所以 rpc相对来说偏向于服务治理这一块\n\n\n3、为什么我们需要rpc框架，http1.1 提供的rest api不行吗1、不支持长连接，keepalive \n2、http1.1 ping-pang  client - server http , 建立很多个连接 (http tcp 连接慢，传输/窗口) \n3、rpc 多路复用能力 (http2/3) client - server (io) ，server 包 (二进制) -&gt; go  顺序 http2 奇偶 \n4、并发性\n5、rpc tcp 传输 -&gt; http1.1 纯文本  头部， rcp  hello  行头体 \n5、 json rpc \n4、比较出名的rpc框架\nJava: JNI ， WebService ， Dubbo ，HSF ，spring的Feign那一套，grpc\nGolang: gorpc ，grpc 等\nC++：Svrkit ，grpc 等\n\n大厂用的吧，各大厂都有自己的轮子，比如 thrift，gprc，Tars，brpc ，motan， dubbo    还有很多吧\n其实轮生态的话，绝对是开源项目的生态比较好，所以开源项目中生态比较好的就是  grpc,thrift,dubbo ，使用难度上来看 dubbo是最简单的，如果你们全Java的话它是个不错的选择！\n2、grpc介绍\n​    gRPC 是一个现代的开源高性能远程过程调用(Remote Procedure Call，RPC)框架，可以在任何环境中运行。它可以高效地连接数据中心内部和跨数据中心的服务，并为负载平衡、跟踪、健康检查和身份验证提供可插拔的支持。它也适用于最后一英里的分布式计算连接设备，移动应用程序和浏览器的后端服务。\n\n1、开源的grpc官方，主要提供的能力\n\n服务调用（提供有stream流，请求响应类型的）\n负载均衡 (提供xsd协议)\n权限(安全方面)\n\n2、grpc主要采用的技术\n\n传输层：http2协议\n序列化层：protobuf \n负载均衡：xsd\n\n3、推荐学习文章，其实grpc是奔着一个规范去走了，所以在开源项目中所使用grpc的项目有很多，云原生中大量的项目使用grpc\n关于序列化和反序列化的思考\n关于HTTP2相关知识\nXDS标准引入GRPC\n关于xsd的学习\n➜  grpc-go git:(master) ✗ tree -L 2.├── api ## pb 项目(不同业务组名称是不一样的，像我们组直接叫项目名字直接叫api)│   ├── Makefile ## 脚本│   ├── bin ## protoc / protoc-gen-go/ protoc-gen-gofast 脚本用来生成pb文件│   ├── dto ## 传输层数据│   ├── go.mod│   ├── go.sum│   └── third ## rpc接口，我们这里叫做third└── service ## 业务项目    ├── client.go    ├── common ##common    ├── go.mods    ├── go.sum    ├── lbs-service.go    ├── service ## 具体业务层    └── user-service.go\n\n3、protobuf 介绍1、介绍和文档\n​    Protocol Buffers 是一种语言无关、平台无关、可扩展的序列化结构数据的方法，它可用于（数据）通信协议、数据存储等。Protocol Buffers 是一种灵活，高效，自动化机制的结构数据序列化方法－可类比 XML，但是比 XML 更小（3 ~ 10倍）、更快（20 ~ 100倍）、更为简单。你可以定义数据的结构，然后使用特殊生成的源代码轻松的在各种数据流中使用各种语言进行编写和读取结构数据。你甚至可以更新数据结构，而不破坏由旧数据结构编译的已部署程序。\n\n\nwiki: https://en.wikipedia.org/wiki/Protocol_Buffers\nprotobuf是 Google 的语言中立、平台中立、可扩展的结构化数据序列化机制\n编译器是用 c + + 编写，高性能！\n支持各种开发语言，有效解决了跨平台问题，跨平台开发\n其实就是 pb 核心的一点：高性能、高压缩率、兼容性比较高\n语法简单，学习难度较低\ngithub官方地址：https://github.com/protocolbuffers/protobuf \nprotobuf go support （golang）：https://github.com/golang/protobuf\nprotobuf go support （gogo）：https://github.com/gogo/protobuf\n官方文档：https://developers.google.com/protocol-buffers/\n相当的火热，在c/cpp/java/go/云原生/Native App 中火热程度很高，使用范围也很广, 学习只有好处没有坏处\n\n2、基础学习1、基本格式syntax = &quot;proto3&quot;; // 默认走的是 proto2,所以需要强制指定，pb3比pb2语法上简单package dto; //当前文件的package，我们项目不喜欢使用前缀类似于 project-name.dto，因为根本不会存在多个项目互相引用！根据你们需求去决定import &quot;dto/demo.proto&quot;; // import 其他文件，相对于--proto_path 路径的相对路径option java_multiple_files = true;option java_package = &quot;com.grpc.api.third&quot;; //java包的路径option go_package=&quot;api/dto&quot;;// go的包路径(切记一定要写全，和go的import有关系，如果写 dto，那么别人引入你就是 dto了，显然是引入不到的，一定要写全)message SearchRequest &#123;// 每个字段都有四块组成: 字段规则，类型，名称，编号  string query = 1;  int32 page_number = 2;  int32 result_per_page = 3;  repeated string hobby = 4;&#125;\n\n2、类型\n字符串：string ，（默认为””）\n整型：int32, int64, uint32, uint64  （默认为0）\n浮点： double, float （默认为0）\n字节流： bytes （默认为nil）\n布尔类型：bool ，（默认false）\n枚举：enum （默认为0，枚举的第一个值必须是0）\nmap类型: 比如 map&lt;string,string&gt; （默认为nil）\noneof 类型，它是一个结构体，但是它定义你结构体中只能赋值一个字段，就算你有多个字段！(默认为nil)\n\n3、编号​    消息定义中的每个字段都有一个唯一的编号。这些字段编号用于以消息二进制格式标识字段，在使用消息类型后不应更改。注意，范围1到15中的字段编号需要一个字节进行编码，包括字段编号和字段类型。范围16到2047的字段编号采用两个字节。因此，应该为经常出现的消息元素保留数字1到15。记住为将来可能添加的频繁出现的元素留出一些空间。\n\n大小限制：1-2^29-1 ,  19000 through 19999 不能使用\n\n4、字段规则\nsingular，默认类型就是这个，不需要申明\nrepeated， 类似于数组，go里面默认就转换成了数组，是个list所以不会自动去重\n\n5、注释两种格式，和java/c++/go保持一致\n/** 注释*/// 注释\n\n6、删除/保留字段message SearchRequest &#123;  string query = 1;  int32 page_number = 2;  int32 result_per_page = 3;  repeated string hobby = 4;  reserved  15, 9 to 11;  reserved &quot;foo&quot;, &quot;bar&quot;;&#125;\t\n\n7、其他1、支持任意的结构体嵌套message Outer &#123;                  // Level 0  message MiddleAA &#123;  // Level 1    message Inner &#123;   // Level 2      int64 ival = 1;      bool  booly = 2;    &#125;  &#125;  message MiddleBB &#123;  // Level 1    message Inner &#123;   // Level 2      int32 ival = 1;      bool  booly = 2;    &#125;  &#125;&#125;\n\n2、任意类型\n​    这里代表的不是任意的数据类型，指的是 Message 类型！\n\nsyntax=&quot;proto3&quot;;package dto;option java_multiple_files = true;option java_package = &quot;com.grpc.api.third&quot;;option go_package=&quot;dto&quot;;import &quot;google/protobuf/any.proto&quot;;message City &#123;    uint64 id=1;    string name=2;    // 引用包名称.类型名称    google.protobuf.Any any = 9;&#125;\n\n3、map类型message City &#123;    uint64 id=1;    string name=2;    // 引用包名称.类型名称    google.protobuf.Any any = 9;    map&lt;string,uint64&gt; demo=10;&#125;\n\n4、oneof 类型下面为例子，就是你只能选择 v3 或者 v4    ！\nmessage BenchMarkModel &#123;    string v1=1;    uint64 v2=2;    oneof test_oneof &#123;        string v3 = 3;        uint32 v4 = 4;    &#125;&#125;\n\n8、import 作用首先 import 是引用 路径的，那个路径是相对于你的 --proto_path 路径的路径\n比如我的项目中，引用就是，项目路径是 /Users/fanhaodong/project/programing/grpc-go/api\nbin/protoc \\        --proto_path /Users/fanhaodong/project/programing/grpc-go/api \\        --proto_path /Users/fanhaodong/go/src/github.com/gogo/protobuf/protobuf \\        --plugin=protoc-gen-go=bin/protoc-gen-go \\        --go_out=. \\        ./dto/*.proto\n\n那么我的import 可以来自于两个路径\nimport &quot;dto/city.proto&quot;;import &quot;google/protobuf/any.proto&quot;;\n\n首先 dto/city.proto  ，绝对路径是 /Users/fanhaodong/project/programing/grpc-go/api/dto/city.proto 我们的编译目录是 /Users/fanhaodong/project/programing/grpc-go/api ，所以去除前缀就是 dto/city.proto\n然后看google/protobuf/any.proto 也是同理\n9、package 作用主要是区分 package 区分 import 可能引用了相同的 message ，所以就需要 package指定，一般package命令为比如我的目录是 api/dto，所以一般命名为 api.dto ，一般来说跨业务组是不允许相互引用，只能引用一些common的结构\n比如下面这种情况，我引用了两个 文件 dto/demo.proto， google/protobuf/any.proto\ndemo.proto 定义了 Any 类型\nmessage Any &#123;  string name=1;&#125;\n\n但是我这时候没有告诉我到底用的哪个 Any，此时编译期无法解决\nsyntax=&quot;proto3&quot;;package dto;option java_multiple_files = true;option java_package = &quot;com.grpc.api.dto&quot;;option go_package=&quot;dto&quot;;import &quot;google/protobuf/any.proto&quot;;import &quot;dto/demo.proto&quot;;message City &#123;    uint64 id=1;    string name=2;    // 引用包名称.类型名称    Any any = 9;    map&lt;string,uint64&gt; demo=10;&#125;\n\n可以看到\ntype City struct &#123;\tstate         protoimpl.MessageState\tsizeCache     protoimpl.SizeCache\tunknownFields protoimpl.UnknownFields\tId   uint64 `protobuf:&quot;varint,1,opt,name=id,proto3&quot; json:&quot;id,omitempty&quot;`\tName string `protobuf:&quot;bytes,2,opt,name=name,proto3&quot; json:&quot;name,omitempty&quot;`\t// 引用包名称.类型名称\tAny  *Any              `protobuf:&quot;bytes,9,opt,name=any,proto3&quot; json:&quot;any,omitempty&quot;`\tDemo map[string]uint64 `protobuf:&quot;bytes,10,rep,name=demo,proto3&quot; json:&quot;demo,omitempty&quot; protobuf_key:&quot;bytes,1,opt,name=key,proto3&quot; protobuf_val:&quot;varint,2,opt,name=value,proto3&quot;`&#125;\n\n所以存在这种问题，此时就需要 package解决引用的问题\nmessage City &#123;    uint64 id=1;    string name=2;    // 引用包名称.类型名称    google.protobuf.Any any = 9;    map&lt;string,uint64&gt; demo=10;&#125;\n\n3、Protobuf的编码算法原理Encoding\n4、编译工具\n官方编译工具，比如我是mac os ，可以直接下载 wget https://github.com/protocolbuffers/protobuf/releases/download/v3.9.0/protoc-3.9.0-osx-x86_64.zip\ngogoprotobuf ，对于需要编码为Golang时，其编码效率贼高而且还省内存， 对立项目是 https://github.com/golang/protobuf\n如何编译了 ？  --proto_path指定include 目录， --plugin 指定需要用的plugin， 最后一个参数指的是引用的pb文件\n\n使用测试的pb 文件\nsyntax=&quot;proto3&quot;;package dto;option java_multiple_files = true;option java_package = &quot;com.grpc.api.dto&quot;;option go_package=&quot;api/dto&quot;;import &quot;google/protobuf/any.proto&quot;;import &quot;google/protobuf/duration.proto&quot;;import &quot;google/protobuf/timestamp.proto&quot;;import &quot;google/protobuf/empty.proto&quot;;import &quot;google/protobuf/wrappers.proto&quot;;message BenchMarkModel &#123;    string v1=1;    uint64 v2=2;    int64 v3=3;    double v4=4;    float v5=5;    bool v6=6;    enum Corpus &#123;        UNIVERSAL = 0;        WEB = 1;        IMAGES = 2;        LOCAL = 3;        NEWS = 4;        PRODUCTS = 5;        VIDEO = 6;    &#125;    Corpus v7=7;    map&lt;string,uint32&gt; v8=8;    oneof test_oneof &#123;        string v9 = 9;        uint32 v10 = 10;    &#125;    bytes v11=11;    message Msg &#123;        string content=1;    &#125;    repeated Msg v12=12;    google.protobuf.Any v13 = 13;    google.protobuf.Duration v14=14;    google.protobuf.Empty v15=15;    google.protobuf.UInt64Value v16=16;    google.protobuf.Timestamp v17=17;&#125;\n\n\n\n2、测试代码\npackage dtoimport (\t&quot;github.com/golang/protobuf/proto&quot;\t&quot;github.com/stretchr/testify/assert&quot;\t&quot;google.golang.org/protobuf/types/known/anypb&quot;\t&quot;google.golang.org/protobuf/types/known/durationpb&quot;\t&quot;google.golang.org/protobuf/types/known/emptypb&quot;\t&quot;google.golang.org/protobuf/types/known/timestamppb&quot;\t&quot;google.golang.org/protobuf/types/known/wrapperspb&quot;\t&quot;math&quot;\t&quot;testing&quot;\t&quot;time&quot;)func newModel(b testing.TB) *BenchMarkModel &#123;\tany := &amp;anypb.Any&#123;&#125;\tif err := any.MarshalFrom(wrapperspb.UInt64(math.MaxUint64)); err != nil &#123;\t\tb.Fatal(err)\t&#125;\treturn &amp;BenchMarkModel&#123;\t\tV1: &quot;hello 12345424234234&quot;,\t\tV2: math.MaxUint64,\t\tV3: math.MaxInt64,\t\tV4: math.MaxFloat64,\t\tV5: math.MaxFloat32,\t\tV6: true,\t\tV7: BenchMarkModel_PRODUCTS,\t\tV8: map[string]uint32&#123;&quot;1&quot;: 1, &quot;2&quot;: 2, &quot;3&quot;: 3&#125;,\t\tTestOneof: &amp;BenchMarkModel_V10&#123;\t\t\tV10: math.MaxUint32,\t\t&#125;,\t\tV11: []byte(&quot;hello 1234567890&quot;),\t\tV12: []*BenchMarkModel_Msg&#123;\t\t\t&#123;Content: &quot;1&quot;&#125;, &#123;Content: &quot;2&quot;&#125;, &#123;Content: &quot;3&quot;&#125;,\t\t&#125;,\t\tV13: any,\t\tV14: durationpb.New(time.Hour * 24),\t\tV15: &amp;emptypb.Empty&#123;&#125;,\t\tV16: wrapperspb.UInt64(math.MaxUint64),\t\tV17: timestamppb.Now(),\t&#125;&#125;func TestGo_Marshal(t *testing.T) &#123;\tmodel := newModel(t)\tprotoBufBody, err := proto.Marshal(model)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\tnewModel := &amp;BenchMarkModel&#123;&#125;\tif err := proto.UnmarshalMerge(protoBufBody, newModel); err != nil &#123;\t\tt.Fatal(err)\t&#125;\tassertModel(t, model, newModel)&#125;func assertModel(t testing.TB, model *BenchMarkModel, newModel *BenchMarkModel) &#123;\tassert.Equal(t, model.V1, newModel.V1)\tassert.Equal(t, model.V2, newModel.V2)\tassert.Equal(t, model.V3, newModel.V3)\tassert.Equal(t, model.V4, newModel.V4)\tassert.Equal(t, model.V5, newModel.V5)\tassert.Equal(t, model.V6, newModel.V6)\tassert.Equal(t, model.V7, newModel.V7)\tassert.Equal(t, model.V8, newModel.V8)\tassert.Equal(t, model.TestOneof, newModel.TestOneof)\tassert.Equal(t, model.V11, newModel.V11)\tfor index, _ := range model.V12 &#123;\t\tassert.Equal(t, model.V12[index].Content, newModel.V12[index].Content)\t&#125;  \tassert.Equal(t, model.V13.Value, newModel.V13.Value)\tassert.Equal(t, model.V13.TypeUrl, newModel.V13.TypeUrl)\tassert.Equal(t, model.V14.Nanos, newModel.V14.Nanos)\tassert.Equal(t, model.V14.Seconds, newModel.V14.Seconds)\tassert.Equal(t, model.V15, newModel.V15)\tassert.Equal(t, model.V16.Value, newModel.V16.Value)\tassert.Equal(t, model.V17.Seconds, newModel.V17.Seconds)\tassert.Equal(t, model.V17.Nanos, newModel.V17.Nanos)&#125;\n\n1、使用protoc-gen-go这里需要知道的是 --go_out 需要找到 protoc-gen-go 的位置，如果你的protoc-gen-go放在 PATH目录下就可以直接使用，但是我们一般不会放在PATH目录下，所以需要指定 --plugin=protoc-gen-go=bin/protoc-gen-go，意思就是告诉位置所在\nbin/protoc \\        --proto_path . \\        --proto_path /Users/fanhaodong/go/grpc/include \\        --plugin=protoc-gen-go=bin/protoc-gen-go \\        --go_out=../ \\        ./dto/*.proto\n\n帮助\n--plugin=EXECUTABLE         Specifies a plugin executable to use.                            Normally, protoc searches the PATH for                            plugins, but you may specify additional                            executables not in the path using this flag.                            Additionally, EXECUTABLE may be of the form                            NAME=PATH, in which case the given plugin name                            is mapped to the given executable even if                            the executable&#x27;s own name differs.\n\n其实规则就是\n--plugin=protoc-gen-go=bin/protoc-gen-go  对应的必须是 --go_out，它走的是拼前缀，比如你执行这个也OK，因为是看前缀说话\nbin/protoc \\        --proto_path . \\        --proto_path /Users/fanhaodong/go/grpc/include \\        --plugin=protoc-gen-go1=bin/protoc-gen-go \\        --go1_out=../ \\        ./dto/*.proto\n\n开始进入话题进行benchmark\nfunc BenchmarkGo_Marshal(b *testing.B) &#123;\tmodel := newModel(b)\tfor i := 0; i &lt; b.N; i++ &#123;\t\tif _, err := proto.Marshal(model); err != nil &#123;\t\t\tb.Fatal(err)\t\t&#125;\t&#125;&#125;func BenchmarkGo_UnMarshal(b *testing.B) &#123;\tmodel := newModel(b)\tresult, err := proto.Marshal(model)\tif err != nil &#123;\t\tb.Fatal(err)\t&#125;\tnewModel := &amp;BenchMarkModel&#123;&#125;\tfor i := 0; i &lt; b.N; i++ &#123;\t\tif err := proto.UnmarshalMerge(result, newModel); err != nil &#123;\t\t\tb.Fatal(err)\t\t&#125;\t&#125;&#125;\n\n测试结果\n➜  dto git:(master) ✗ go test -run=none -bench=BenchmarkGo_ -benchmem -count=4 . goos: darwingoarch: amd64pkg: api/dtoBenchmarkGo_Marshal-12            428138              2624 ns/op             600 B/op         17 allocs/opBenchmarkGo_Marshal-12            431756              2552 ns/op             600 B/op         17 allocs/opBenchmarkGo_Marshal-12            418332              2595 ns/op             600 B/op         17 allocs/opBenchmarkGo_Marshal-12            503637              2520 ns/op             600 B/op         17 allocs/opBenchmarkGo_UnMarshal-12          537661              2824 ns/op             555 B/op         19 allocs/opBenchmarkGo_UnMarshal-12          542142              2398 ns/op             554 B/op         19 allocs/opBenchmarkGo_UnMarshal-12          509076              2420 ns/op             563 B/op         19 allocs/opBenchmarkGo_UnMarshal-12          544599              2063 ns/op             553 B/op         19 allocs/opPASSok      api/dto 11.746s\n\n2、使用 protoc-gen-gofast1、首先需要安装\ngo install github.com/gogo/protobuf/protoc-gen-gofast ## protoc-gen-gofast 工具go get github.com/gogo/protobuf ## 代码依赖\n\n2、这里使用了Any类型，所以需要我们做gofast的兼容，这点比较坑，官网也写了如何解决：https://github.com/gogo/protobuf ， 因此编译命令需要添加一些参数！\nbin/protoc \\        --proto_path . \\        --proto_path /Users/fanhaodong/go/src/github.com/gogo/protobuf/protobuf \\        --plugin=protoc-gen-gofast=bin/protoc-gen-gofast \\        --gofast_out=\\        Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/duration.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/field_mask.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/struct.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/type.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/api.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/descriptor.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/empty.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/source_context.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/timestamp.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/wrappers.proto=github.com/gogo/protobuf/types:../ \\        ./dto/*.proto\n\n3、最坑的来了，也就是它为啥不兼容的问题！\n1）原来定义的any现在不能使用了，也就是说api的使用方式上变了!\nimport (\t&quot;encoding/json&quot;\t&quot;github.com/gogo/protobuf/types&quot;\t&quot;github.com/golang/protobuf/proto&quot;\t&quot;github.com/stretchr/testify/assert&quot;\t&quot;math&quot;\t&quot;testing&quot;\t&quot;time&quot;)func newModel(b testing.TB) *BenchMarkModel &#123;\tany, err := types.MarshalAny(&amp;types.UInt64Value&#123;\t\tValue: math.MaxUint64,\t&#125;)\tif err != nil &#123;\t\tb.Fatal(err)\t&#125;\treturn &amp;BenchMarkModel&#123;\t\tV1: &quot;hello 12345424234234&quot;,\t\tV2: math.MaxUint64,\t\tV3: math.MaxInt64,\t\tV4: math.MaxFloat64,\t\tV5: math.MaxFloat32,\t\tV6: true,\t\tV7: BenchMarkModel_PRODUCTS,\t\tV8: map[string]uint32&#123;&quot;1&quot;: 1, &quot;2&quot;: 2, &quot;3&quot;: 3&#125;,\t\tTestOneof: &amp;BenchMarkModel_V10&#123;\t\t\tV10: math.MaxUint32,\t\t&#125;,\t\tV11: []byte(&quot;hello 1234567890&quot;),\t\tV12: []*BenchMarkModel_Msg&#123;&#123;Content: &quot;1&quot;&#125;, &#123;Content: &quot;2&quot;&#125;, &#123;Content: &quot;3&quot;&#125;,&#125;,\t\tV13: any,\t\tV14: types.DurationProto(time.Hour * 24),\t\tV15: &amp;types.Empty&#123;&#125;,\t\tV16: &amp;types.UInt64Value&#123;\t\t\tValue: math.MaxUint64,\t\t&#125;,\t\tV17: types.TimestampNow(),\t&#125;&#125;\n\n3、benchmark \n➜  dto git:(master) ✗ go test -run=none -bench=BenchmarkGoFast_ -benchmem -count=4 .goos: darwingoarch: amd64pkg: api/dtoBenchmarkGoFast_Marshal-12               1579309               748 ns/op             240 B/op          2 allocs/opBenchmarkGoFast_Marshal-12               1487350               840 ns/op             240 B/op          2 allocs/opBenchmarkGoFast_Marshal-12               1389932               765 ns/op             240 B/op          2 allocs/opBenchmarkGoFast_Marshal-12               1532866               784 ns/op             240 B/op          2 allocs/opBenchmarkGoFast_UnMarshal-12             1000000              1173 ns/op             382 B/op          7 allocs/opBenchmarkGoFast_UnMarshal-12             1235286              1001 ns/op             384 B/op          7 allocs/opBenchmarkGoFast_UnMarshal-12             1083085              1191 ns/op             371 B/op          7 allocs/opBenchmarkGoFast_UnMarshal-12             1000000              1144 ns/op             382 B/op          7 allocs/opPASSok      api/dto 14.907s\n\n3、总结1、从性能上来看确实提升至少是一倍起步，基本带来了翻倍的收益(官方给的数据是5-10倍的性能提升，它还提供了更快的！1），然后主要是内存分配上可以看到内存优势很大！\n2、但从效率上来说其实对于业务开发其实是不关注太多这些的，开发效率和质量决定一切！\n3、关于选择protoc-gen-gofast 还是选择 protoc-gen-go ，看你们业务已开始用的什么，如果开始就选择 protoc-gen-gofast 那么可以一直用，但是一开始就选择 protoc-gen-go 那就恶心了，基本上无法切换到 protoc-gen-gofast，可以选择使用 protoc-gen-gogo\n4、gRPC1、介绍和文档\n​        gRPC 是一个现代的开源高性能远程过程调用(Remote Procedure Call，RPC)框架，可以在任何环境中运行。它可以高效地连接数据中心内部和跨数据中心的服务，并为负载平衡、跟踪、健康检查和身份验证提供可插拔的支持。它也适用于最后一英里的分布式计算连接设备，移动应用程序和浏览器的后端服务。\n\n\nc系列(官方系): https://github.com/grpc/grpc\njava 系：https://github.com/grpc/grpc-java\ngo 系：https://github.com/grpc/grpc-go\n官方文档：https://grpc.io/\n如何使用 wireshark 抓取 grpc &amp;&amp; http2 包：https://grpc.io/blog/wireshark/\ngrcp 和 http2的关系: https://grpc.io/blog/grpc-on-http2/\n\n2、写rpc接口 (IDL)第一个lbs接口是：\nsyntax=&quot;proto3&quot;;package third;option java_multiple_files = true;option java_package = &quot;com.grpc.api.third&quot;;option go_package=&quot;api/third&quot;;import &quot;google/protobuf/wrappers.proto&quot;;import &quot;dto/city.proto&quot;;service LbsService &#123;    rpc getCityInfo (google.protobuf.UInt64Value) returns (dto.City);&#125;\n\n第二个是user服务接口：\nsyntax=&quot;proto3&quot;;package third;option java_multiple_files = true;option java_package = &quot;com.grpc.api.third&quot;;option go_package=&quot;api/third&quot;;import &quot;dto/user.proto&quot;;import &quot;google/protobuf/wrappers.proto&quot;;service UserService &#123;    rpc GetUserInfo (google.protobuf.UInt64Value) returns (dto.User);&#125;\n\n3、gofast编译rcp接口如何编译，我们使用的是 gofast进行编译，所以需要修改一些参数，关于参数如何使用的，这些绝对百度不来，主要是看人家这个gofast项目的文档和example\n这里就是需要告诉一下编译的时候使用 plugin=grpc, 然后还需要改变一下引用，最后就是指定一下输出目录\n格式就是 --&#123;pugin&#125;_out=k1=v1,k2=v2,k3=v3....,kn=vn:&#123;输出目录&#125;\nbin/protoc \\        --proto_path . \\        --proto_path /Users/fanhaodong/go/src/github.com/gogo/protobuf/protobuf \\        --plugin=protoc-gen-gofast=bin/protoc-gen-gofast \\        --gofast_out=plugins=grpc,\\        Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/duration.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/field_mask.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/struct.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/type.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/api.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/descriptor.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/empty.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/source_context.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/timestamp.proto=github.com/gogo/protobuf/types,\\        Mgoogle/protobuf/wrappers.proto=github.com/gogo/protobuf/types:../ \\        ./third/*.proto\n\n4、go写接口服务调用1、服务端代码\npackage mainimport (\t&quot;api/dto&quot;\t&quot;api/third&quot;\t&quot;context&quot;\t&quot;fmt&quot;\t&quot;github.com/gogo/protobuf/types&quot;\t&quot;google.golang.org/grpc&quot;\t&quot;log&quot;\t&quot;net&quot;\t&quot;service/common&quot;\t&quot;time&quot;)type lbsServiceServer struct&#123;&#125;func (lbsServiceServer) GetCityInfo(ctx context.Context, cityId *types.UInt64Value) (*dto.City, error) &#123;\tif cityId.Value == 0 &#123;\t\treturn nil, fmt.Errorf(&quot;not found city: %d&quot;, cityId.Value)\t&#125;\treturn &amp;dto.City&#123;\t\tId:         cityId.Value,\t\tName:       fmt.Sprintf(&quot;beijing-%d&quot;, cityId.Value),\t\tProperties: map[string]string&#123;&quot;time&quot;: time.Now().Format(time.RFC3339)&#125;,\t\tMsg: &amp;dto.OneofMessage&#123;\t\t\tTestOneof: &amp;dto.OneofMessage_Name&#123;\t\t\t\tName: &quot;demo&quot;,\t\t\t&#125;,\t\t&#125;,\t&#125;, nil&#125;func main() &#123;\t// 创建一个tcp listener\tlis, err := net.Listen(&quot;tcp&quot;, common.LbsService)\tif err != nil &#123;\t\tlog.Fatalf(&quot;failed to listen: %v&quot;, err)\t&#125;\t// 创建一个 grpc server\tser := grpc.NewServer()\t// 注册信息\tthird.RegisterLbsServiceServer(ser, lbsServiceServer&#123;&#125;)\t// 启动服务\tif err := ser.Serve(lis); err != nil &#123;\t\tlog.Fatalf(&quot;failed to serve: %v&quot;, err)\t&#125;&#125;\n\n2、客户端代码\npackage mainimport (\t&quot;api/third&quot;\t&quot;context&quot;\t&quot;github.com/gogo/protobuf/types&quot;\t&quot;google.golang.org/grpc&quot;\t&quot;log&quot;\t&quot;service/common&quot;)func main() &#123;\tconn, err := grpc.Dial(common.LbsService, grpc.WithInsecure(), grpc.WithBlock())\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\tclient := third.NewLbsServiceClient(conn)\tcityInfo, err := client.GetCityInfo(context.Background(), &amp;types.UInt64Value&#123;Value: 1&#125;)\tif err != nil &#123;\t\tlog.Fatal(err)\t&#125;\tlog.Printf(&quot;%s&quot;, cityInfo)&#125;\n\n请求一下可以看到完全可以调通\n2021/04/16 20:10:48 id:1 name:&quot;beijing-1&quot; properties:&lt;key:&quot;time&quot; value:&quot;2021-04-16T20:10:48+08:00&quot; &gt; msg:&lt;name:&quot;demo&quot; &gt; \n\n5、如何抓包1、配置pb位置，比如我的就是在 /Users/fanhaodong/project/programing/grpc-go/api目录下\n\n2、选择抓取网卡\n本地的话一般是就是本地回环网络，我的本地网卡就是 lo0\n\n然后选择过滤的端口，比如我刚刚启动的服务端口是 8001， 然后记得客户端调用一次服务端,就可以看到以下的流量包了\n\n此时可以监控到流量，但是是tcp，所以我们很难看懂，需要需要分析一下，因此需要decode一下包\n\n所以大概你就可以看到所有包的情况了！\n6、http27、grpc conn pool1、如果发现 []  conn\n2、如果发现 conn (http2  http3 ) \n3、\n5、使用go-micro 搭建grpc服务1、官方文档https://github.com/Anthony-Dong/go-micro\n\n微解决了在云中构建服务的关键需求。它利用微服务体系结构模式，并提供一组作为平台构建块的服务。微处理分布式系统的复杂性，并提供更简单的可编程抽象。\n\n其实看起来和那个现在比较火的 dapr 很像，抽象的级别很高，更加傻瓜式，但是你要是研究的话往往会增大学习成本\n2、快速开始的话，你就根据官方提供的就行了\n2、提供的能力1、基本上人家帮代码给你封装好了，直接用\n2、提供api-gateway 方便使用\n3、提供有 一些内部提供的服务治理能力，需要细细学习\n4、有兴趣可以学习一下\n","categories":["RPC"],"tags":["GRPC","Protobuf"]},{"title":"tcpdump","url":"/2021/03/29/a22db6b9984d48fcdf4adcc9ff16c659/","content":"​        使用tcpdump + wireshark 可以很好的帮助我们解决线上抓包问题！\n\n\n测试http的流量，指定端口的1、测试指定tcp的流量\npackage mainimport (\t&quot;github.com/gin-gonic/gin&quot;\t&quot;log&quot;)func main() &#123;\tr := gin.Default()\tr.GET(&quot;/&quot;, func(c *gin.Context) &#123;\t\tc.JSON(200, gin.H&#123;\t\t\t&quot;code&quot;: 0,\t\t\t&quot;data&quot;: &quot;hello world&quot;,\t\t\t&quot;msg&quot;:  &quot;success&quot;,\t\t&#125;)\t&#125;)\tlog.Fatal(r.Run(&quot;:80&quot;))&#125;\n\n2、编译运行\ngo build -v -o bin/app main.gobin/app\n\n3、使用tcpdump测试\n查看 man tcpdump\n\ntcp 表示监听tcp端口\nport 表示监听80端口\n-i 表示本地网卡接口，默认是 eth0\n-X 是打印文本为ASCII.格式\n\n[root@2979ef744f9c go]# tcpdump tcp port 80 -i lo -Xtcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes11:47:04.830856 IP localhost.54072 &gt; localhost.http: Flags [S], seq 3285825130, win 43690, options [mss 65495,sackOK,TS val 2334119 ecr 0,nop,wscale 7], length 0\t0x0000:  4500 003c 2bcd 4000 4006 10ed 7f00 0001  E..&lt;+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b66a 0000 0000  .....8.P...j....\t0x0020:  a002 aaaa fe30 0000 0204 ffd7 0402 080a  .....0..........\t0x0030:  0023 9da7 0000 0000 0103 0307            .#..........11:47:04.830994 IP localhost.http &gt; localhost.54072: Flags [S.], seq 1580062543, ack 3285825131, win 43690, options [mss 65495,sackOK,TS val 2334119 ecr 2334119,nop,wscale 7], length 0\t0x0000:  4500 003c 0000 4000 4006 3cba 7f00 0001  E..&lt;..@.@.&lt;.....\t0x0010:  7f00 0001 0050 d338 5e2d d74f c3d9 b66b  .....P.8^-.O...k\t0x0020:  a012 aaaa fe30 0000 0204 ffd7 0402 080a  .....0..........\t0x0030:  0023 9da7 0023 9da7 0103 0307            .#...#......11:47:04.831042 IP localhost.54072 &gt; localhost.http: Flags [.], ack 1, win 342, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 2bce 4000 4006 10f4 7f00 0001  E..4+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b66b 5e2d d750  .....8.P...k^-.P\t0x0020:  8010 0156 fe28 0000 0101 080a 0023 9da7  ...V.(.......#..\t0x0030:  0023 9da7                                .#..11:47:04.831223 IP localhost.54072 &gt; localhost.http: Flags [P.], seq 1:74, ack 1, win 342, options [nop,nop,TS val 2334119 ecr 2334119], length 73: HTTP: GET / HTTP/1.1\t0x0000:  4500 007d 2bcf 4000 4006 10aa 7f00 0001  E..&#125;+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b66b 5e2d d750  .....8.P...k^-.P\t0x0020:  8018 0156 fe71 0000 0101 080a 0023 9da7  ...V.q.......#..\t0x0030:  0023 9da7 4745 5420 2f20 4854 5450 2f31  .#..GET./.HTTP/1\t0x0040:  2e31 0d0a 5573 6572 2d41 6765 6e74 3a20  .1..User-Agent:.\t0x0050:  6375 726c 2f37 2e32 392e 300d 0a48 6f73  curl/7.29.0..Hos\t0x0060:  743a 206c 6f63 616c 686f 7374 0d0a 4163  t:.localhost..Ac\t0x0070:  6365 7074 3a20 2a2f 2a0d 0a0d 0a         cept:.*/*....11:47:04.831257 IP localhost.http &gt; localhost.54072: Flags [.], ack 74, win 342, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 4af7 4000 4006 f1ca 7f00 0001  E..4J.@.@.......\t0x0010:  7f00 0001 0050 d338 5e2d d750 c3d9 b6b4  .....P.8^-.P....\t0x0020:  8010 0156 fe28 0000 0101 080a 0023 9da7  ...V.(.......#..\t0x0030:  0023 9da7                                .#..11:47:04.831750 IP localhost.http &gt; localhost.54072: Flags [P.], seq 1:171, ack 74, win 342, options [nop,nop,TS val 2334119 ecr 2334119], length 170: HTTP: HTTP/1.1 200 OK\t0x0000:  4500 00de 4af8 4000 4006 f11f 7f00 0001  E...J.@.@.......\t0x0010:  7f00 0001 0050 d338 5e2d d750 c3d9 b6b4  .....P.8^-.P....\t0x0020:  8018 0156 fed2 0000 0101 080a 0023 9da7  ...V.........#..\t0x0030:  0023 9da7 4854 5450 2f31 2e31 2032 3030  .#..HTTP/1.1.200\t0x0040:  204f 4b0d 0a43 6f6e 7465 6e74 2d54 7970  .OK..Content-Typ\t0x0050:  653a 2061 7070 6c69 6361 7469 6f6e 2f6a  e:.application/j\t0x0060:  736f 6e3b 2063 6861 7273 6574 3d75 7466  son;.charset=utf\t0x0070:  2d38 0d0a 4461 7465 3a20 4d6f 6e2c 2032  -8..Date:.Mon,.2\t0x0080:  3920 4d61 7220 3230 3231 2031 313a 3437  9.Mar.2021.11:47\t0x0090:  3a30 3420 474d 540d 0a43 6f6e 7465 6e74  :04.GMT..Content\t0x00a0:  2d4c 656e 6774 683a 2034 370d 0a0d 0a7b  -Length:.47....&#123;\t0x00b0:  2263 6f64 6522 3a30 2c22 6461 7461 223a  &quot;code&quot;:0,&quot;data&quot;:\t0x00c0:  2268 656c 6c6f 2077 6f72 6c64 222c 226d  &quot;hello.world&quot;,&quot;m\t0x00d0:  7367 223a 2273 7563 6365 7373 227d       sg&quot;:&quot;success&quot;&#125;11:47:04.831838 IP localhost.54072 &gt; localhost.http: Flags [.], ack 171, win 350, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 2bd0 4000 4006 10f2 7f00 0001  E..4+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b6b4 5e2d d7fa  .....8.P....^-..\t0x0020:  8010 015e fe28 0000 0101 080a 0023 9da7  ...^.(.......#..\t0x0030:  0023 9da7                                .#..11:47:04.832207 IP localhost.54072 &gt; localhost.http: Flags [F.], seq 74, ack 171, win 350, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 2bd1 4000 4006 10f1 7f00 0001  E..4+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b6b4 5e2d d7fa  .....8.P....^-..\t0x0020:  8011 015e fe28 0000 0101 080a 0023 9da7  ...^.(.......#..\t0x0030:  0023 9da7                                .#..11:47:04.832424 IP localhost.http &gt; localhost.54072: Flags [F.], seq 171, ack 75, win 342, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 4af9 4000 4006 f1c8 7f00 0001  E..4J.@.@.......\t0x0010:  7f00 0001 0050 d338 5e2d d7fa c3d9 b6b5  .....P.8^-......\t0x0020:  8011 0156 fe28 0000 0101 080a 0023 9da7  ...V.(.......#..\t0x0030:  0023 9da7                                .#..11:47:04.832484 IP localhost.54072 &gt; localhost.http: Flags [.], ack 172, win 350, options [nop,nop,TS val 2334119 ecr 2334119], length 0\t0x0000:  4500 0034 2bd2 4000 4006 10f0 7f00 0001  E..4+.@.@.......\t0x0010:  7f00 0001 d338 0050 c3d9 b6b5 5e2d d7fb  .....8.P....^-..\t0x0020:  8010 015e fe28 0000 0101 080a 0023 9da7  ...^.(.......#..\t0x0030:  0023 9da7                                .#..\n\n\n\n\n\n监听特定条件可以通过 host 指定，以下是发送了个 Ping 包进行执行的！\n下面统一执行了 ping 172.15.64.10 -c 1\n\nsrc host 源\ndst host 目的\nhost 一起\nhost ip1 and ip2 监听 ip1 和 ip2 之间的包\n\n[root@2979ef744f9c /]# tcpdump host 172.15.64.10tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes11:55:25.595460 IP 2979ef744f9c &gt; 172-15-64-10.lightspeed.miamfl.sbcglobal.net: ICMP echo request, id 1311, seq 1, length 6411:55:25.596104 IP 172-15-64-10.lightspeed.miamfl.sbcglobal.net &gt; 2979ef744f9c: ICMP echo reply, id 1311, seq 1, length 64\n\n比如\n[root@2979ef744f9c /]# tcpdump dst host 172.15.64.10 -ntcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes11:58:22.417951 IP 172.17.0.3 &gt; 172.15.64.10: ICMP echo request, id 1319, seq 1, length 64\n\n\n\n其他参数\n-s 0 默认抓包只抓取 68个字节，指定0抓全部\n-c 100 抓取100次\ndst port ! 22  目标端口不是 22的包\n-w dm.cap : 保存成cap文件，方便用ethereal(即wireshark)分析\n\n配合wireshark使用[root@2979ef744f9c bin]# tcpdump -c 80 -n -i eth0 tcp port 80 and host 172.15.64.10 -w /opt/project/dm.captcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes80 packets captured110 packets received by filter0 packets dropped by kernel\n\n执行：\n[root@2979ef744f9c bin]# for x in &#123;1..10&#125;; do curl http://172.15.64.10; echo &quot;&quot; ; done&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;&#123;&quot;code&quot;:0,&quot;data&quot;:&quot;hello world&quot;,&quot;msg&quot;:&quot;success&quot;&#125;\n\n然后使用wireshark 打开包！\n\n三次握手，四次挥手这个是一次http请求所发送的包！\n\n1、三次握手172.17.0.3 是客户端\n172.15.64.10是服务端\n可以看到客户端发送一个 syn 同步，需要等待服务端响应一个 syn同步+ack响应，然后客户端再发送一个ack=1 ，整个握手长度大约是 74+62+54 个字节\n\n三次握手的必要性在于：防止已失效的请求报文段突然又传送到了服务端而造成连接的误判 ， 假如我们与 172.15.64.10 服务连接，此时我们发送了一个包(B)但是由于网络阻塞的问题，我们继续重试发包(B)，服务端收到包(B)，然后响应给客户端此时建立连接，然后突然收到包(A)，又建立了个连接，响应给客户端，但是客户端确认为这个事无效的，此时服务端就尴尬了，这个连接活活浪费了！\n如何解决了，其实就是第三次握手解决，客户端必须向服务端确认哪个包是建立连接的，按上面的情况，B建立连接，此时A包继续响应，但是由于没有收到客户端三次响应，所以就认为这个连接是无效的！\n这里有个问题就是那个客户端发送大量的sync包，对于服务端是否有影响，首先影响是有的！\n首先客户端每次与服务端建立连接，都需要一个socket，然后socket都需要做bind函数来告诉socket的地址，因为tcp是面向连接的协议，bind其实就是为socket绑定端口和ip，int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\nstruct sockaddr_in addr;addr.sin_family = AF_INET; //设置tcp协议族addr.sin_port = htons(6789); //设置端口号addr.sin_addr.s_addr = inet_addr(&quot;192.168.102.169&quot;); //设置ip地址int ret = bind(skfd, (struct sockaddr*)&amp;addr, sizeof(addr));\n\n\n2、四次挥手(双方都可以执行)\n可以看到这个是客户端主动发起的！\n服务端关闭主要是需要通知程序关闭连接，所以有个Fin 操作\n最终需要客户端响应关闭连接，如果没有的话，客户端会进入time-wait\nhttps://zhuanlan.zhihu.com/p/53374516\n3、2MSL (Maximum segment lifetime)\n客户端关闭连接需要进行最后的 time_wait 到 closed 的状态，这个时间需要等待 2msl，主要是为了解决tcp错乱的问题，防止端口被重复占用的问题\nProto Recv-Q Send-Q Local Address           Foreign Address         Statetcp        0      0 172.17.0.3:38890        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38894        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38900        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38888        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38904        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38898        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38902        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38892        172.15.64.10:36832      TIME_WAITtcp        0      0 127.0.0.1:44606         127.0.0.1:8001          ESTABLISHEDtcp        0      0 172.17.0.3:38896        172.15.64.10:36832      TIME_WAITtcp        0      0 172.17.0.3:38906        172.15.64.10:36832      TIME_WAITtcp6       0      0 127.0.0.1:8001          127.0.0.1:44606         ESTABLISHED\n\n具体配置在\n[root@2979ef744f9c bin]# cat /proc/sys/net/ipv4/tcp_fin_timeout60[root@2979ef744f9c bin]#  sysctl net.ipv4.tcp_fin_timeoutnet.ipv4.tcp_fin_timeout = 60\n\n\n\nActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address           Foreign Address         Statetcp        0      0 127.0.0.1:59690         127.0.0.1:36832         TIME_WAITtcp        0      0 127.0.0.1:44606         127.0.0.1:8001          ESTABLISHEDtcp        0      0 127.0.0.1:59698         127.0.0.1:36832         ESTABLISHEDtcp        0      0 127.0.0.1:59696         127.0.0.1:36832         TIME_WAITtcp        0      0 127.0.0.1:59692         127.0.0.1:36832         TIME_WAITtcp        0      0 127.0.0.1:59694         127.0.0.1:36832         TIME_WAITtcp6       0      0 127.0.0.1:36832         127.0.0.1:59698         ESTABLISHEDtcp6       0      0 127.0.0.1:8001          127.0.0.1:44606         ESTABLISHED\n\n","categories":["Linux"],"tags":["Linux命令"]},{"title":"docker网络","url":"/2021/01/26/62dbd7c2e00a1add795e54f9c9d4ee75/","content":"​        容器网络通信是一块很大的内容，docker原生的网络模式其实已经很强大了，可以看一下官方文档！本文只是阐述业务中常用的几种模式！\n\n\n\n\n1、bridge模式\n　在该模式中，Docker 守护进程创建了一个虚拟以太网桥 docker0，新建的容器会自动桥接到这个接口，附加在其上的任何网卡之间都能自动转发数据包。\n[root@centos-linux ~]# ip addr show docker03: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default    link/ether 02:42:dd:54:2a:d4 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:ddff:fe54:2ad4/64 scope link       valid_lft forever preferred_lft forever\n\n默认情况下，守护进程会创建一一对等虚拟设备接口 veth pair，将其中一个接口设置为容器的 eth0 接口（容器的网卡），另一个接口放置在宿主机的命名空间中，以类似 vethxxx 这样的名字命名，从而将宿主机上的所有容器都连接到这个内部网络上。\n首先启动一个容器，可以看到它的网卡，eth0\n[fanhaodong@centos-linux ~]$ docker run --rm -it busybox /bin/sh/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever6: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever       \n\n然后再看宿主机，由于mac的网络模型和linux发行版有区别，所以使用的centos7的CentOS Linux release 7.9.2009\n[root@centos-linux ~]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 00:1c:42:b8:a6:b2 brd ff:ff:ff:ff:ff:ff    inet 192.168.56.3/24 brd 192.168.56.255 scope global noprefixroute dynamic eth0       valid_lft 1769sec preferred_lft 1769sec    inet6 fdb2:2c26:f4e4:0:21c:42ff:feb8:a6b2/64 scope global noprefixroute dynamic       valid_lft 2591754sec preferred_lft 604554sec    inet6 fe80::21c:42ff:feb8:a6b2/64 scope link noprefixroute       valid_lft forever preferred_lft forever3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default    link/ether 02:42:dd:54:2a:d4 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:ddff:fe54:2ad4/64 scope link       valid_lft forever preferred_lft forever7: veth132f35c@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP group default    link/ether 0e:5e:61:09:28:7c brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::c5e:61ff:fe09:287c/64 scope link       valid_lft forever preferred_lft forever\n\n\n可以看到本地网络多了一个网卡7: veth132f35c@if6，\n通过以上的比较可以发现，证实了之前所说的：守护进程会创建一对对等虚拟设备接口 veth pair，将其中一个接口设置为容器的 eth0 接口（容器的网卡），另一个接口放置在宿主机的命名空间中，以类似 vethxxx 这样的名字命名。\n同时，守护进程还会从网桥 docker0 的私有地址空间中分配一个 IP 地址和子网给该容器，并设置 docker0 的 IP 地址为容器的默认网关。也可以安装 yum install -y bridge-utils 以后，通过 brctl show 命令查看网桥信息。\n\n[fanhaodong@centos-linux ~]$ brctl showbridge name\tbridge id\t\tSTP enabled\tinterfacesdocker0\t\t8000.0242dd542ad4\tno\t\tveth132f35c\n\n可以看到 interfaces有一个叫做 veth132f35c\n可以通过  docker network inspect bridge 查看模式\n[root@centos-linux ~]# docker network inspect bridge[    &#123;        &quot;Name&quot;: &quot;bridge&quot;,        &quot;Id&quot;: &quot;50e703932ca8d619016f1e08df21269ee09b3f9799c81f47e5df6e477ee3c341&quot;,        &quot;Created&quot;: &quot;2021-02-03T11:22:58.527865244+08:00&quot;,        &quot;Scope&quot;: &quot;local&quot;,        &quot;Driver&quot;: &quot;bridge&quot;,        &quot;EnableIPv6&quot;: false,        &quot;IPAM&quot;: &#123;            &quot;Driver&quot;: &quot;default&quot;,            &quot;Options&quot;: null,            &quot;Config&quot;: [                &#123;                    &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;                &#125;            ]        &#125;,        &quot;Internal&quot;: false,        &quot;Attachable&quot;: false,        &quot;Ingress&quot;: false,        &quot;ConfigFrom&quot;: &#123;            &quot;Network&quot;: &quot;&quot;        &#125;,        &quot;ConfigOnly&quot;: false,        &quot;Containers&quot;: &#123;            &quot;66949d48a6c0d1629240ab01c2601fd1c885e66b8e75b254b2e5537e7414914e&quot;: &#123;                &quot;Name&quot;: &quot;modest_tesla&quot;,                &quot;EndpointID&quot;: &quot;1012aaac090fa8dac5fababa3467338a255f867b581a97539abb67477da3036a&quot;,                &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,                &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,                &quot;IPv6Address&quot;: &quot;&quot;            &#125;        &#125;,        &quot;Options&quot;: &#123;            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;        &#125;,        &quot;Labels&quot;: &#123;&#125;    &#125;]\n\n可以看到 容器名称一样,\n[root@centos-linux ~]# docker psCONTAINER ID   IMAGE     COMMAND     CREATED         STATUS         PORTS     NAMES66949d48a6c0   busybox   &quot;/bin/sh&quot;   2 minutes ago   Up 2 minutes             modest_tesla\n\n查看 network, docker inspect 66949d48a6c0  -f &#39;&#123;&#123;json .NetworkSettings.Networks.bridge&#125;&#125;&#39;\n[root@centos-linux ~]# docker inspect 66949d48a6c0  -f &#x27;&#123;&#123;json .NetworkSettings.Networks.bridge&#125;&#125;&#x27;&#123;    &quot;IPAMConfig&quot;: null,    &quot;Links&quot;: null,    &quot;Aliases&quot;: null,    &quot;NetworkID&quot;: &quot;50e703932ca8d619016f1e08df21269ee09b3f9799c81f47e5df6e477ee3c341&quot;,    &quot;EndpointID&quot;: &quot;1012aaac090fa8dac5fababa3467338a255f867b581a97539abb67477da3036a&quot;,    &quot;Gateway&quot;: &quot;172.17.0.1&quot;,    &quot;IPAddress&quot;: &quot;172.17.0.2&quot;,    &quot;IPPrefixLen&quot;: 16,    &quot;IPv6Gateway&quot;: &quot;&quot;,    &quot;GlobalIPv6Address&quot;: &quot;&quot;,    &quot;GlobalIPv6PrefixLen&quot;: 0,    &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,    &quot;DriverOpts&quot;: null&#125;\n\n注意：\n网桥模式下，各个容器是可以互相ping通的，可以通过主机IP相互PING通（默认的不支持主机名相互ping通）\n2、host 网络模式\n​    这个比较适合用于本地软件安装，单软件，类似于启动一个程序，但是需要环境依赖，可以使用这个\n\n\nhost 网络模式需要在创建容器时通过参数 --net host 或者 --network host 指定；\n采用 host 网络模式的 Docker Container，可以直接使用宿主机的 IP 地址与外界进行通信，若宿主机的 eth0 是一个公有 IP，那么容器也拥有这个公有 IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行 NAT 转换；\nhost 网络模式可以让容器共享宿主机网络栈，这样的好处是外部主机与容器直接通信，但是容器的网络缺少隔离性。\nhost 模式不能访问外部网络，比如ping www.baidu.com是行不通的\n\n[root@centos-linux .ssh]#  docker run --rm -it --network host  busybox ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host       valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000    link/ether 00:1c:42:b8:a6:b2 brd ff:ff:ff:ff:ff:ff    inet 192.168.56.3/24 brd 192.168.56.255 scope global dynamic eth0       valid_lft 1128sec preferred_lft 1128sec    inet6 fdb2:2c26:f4e4:0:21c:42ff:feb8:a6b2/64 scope global dynamic       valid_lft 2591996sec preferred_lft 604796sec    inet6 fe80::21c:42ff:feb8:a6b2/64 scope link       valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue    link/ether 02:42:dd:54:2a:d4 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:ddff:fe54:2ad4/64 scope link       valid_lft forever preferred_lft forever\n\n3、none 网络模式\nnone 网络模式是指禁用网络功能，只有 lo 接口 local 的简写，代表 127.0.0.1，即 localhost 本地环回接口。在创建容器时通过参数 --net none 或者 --network none 指定；\nnone 网络模式即不为 Docker Container 创建任何的网络环境，容器内部就只能使用 loopback 网络设备，不会再有其他的网络资源。可以说 none 模式为 Docke Container 做了极少的网络设定，但是俗话说得好“少即是多”，在没有网络配置的情况下，作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发。这也恰巧体现了 Docker 设计理念的开放。\n\n[root@centos-linux .ssh]#  docker run --rm -it --network none  busybox ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever\n\n4、container 网络模式\nContainer 网络模式是 Docker 中一种较为特别的网络的模式。在创建容器时通过参数 --net container:已运行的容器名称/ID 或者 --network container:已运行的容器名称/ID 指定；\n处于这个模式下的 Docker 容器会共享一个网络栈，这样两个容器之间可以使用 localhost 高效快速通信。\n\n[root@centos-linux .ssh]#  docker run --rm -it --name b1  busybox /bin/sh/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever28: eth0@if29: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever\n\n主机2\n[root@centos-linux ~]#  docker run --rm -it --name b2 --network container:b1  busybox ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever28: eth0@if29: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0       valid_lft forever preferred_lft forever\n\n假如此时 主机b1死机了，其实它的网卡也只剩下lo网卡\nb2 主机当 b1 挂掉后会如图所示，当 b1重启，b2也需要重启才能看到网卡信息\n/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever/ #\n\n5、自定义网络1、自定义创建一个网络，默认是bridge模式！\n[root@centos-linux /]# docker network create custom_network94a35aa31bdee048a0e5d8b178e4246b429d4525a4036d3d9287650933357c6e\n\n2、查看网络\n[root@centos-linux /]# docker network inspect custom_network[    &#123;        &quot;Name&quot;: &quot;custom_network&quot;,        &quot;Id&quot;: &quot;94a35aa31bdee048a0e5d8b178e4246b429d4525a4036d3d9287650933357c6e&quot;,        &quot;Created&quot;: &quot;2021-03-26T14:35:27.907496817+08:00&quot;,        &quot;Scope&quot;: &quot;local&quot;,        &quot;Driver&quot;: &quot;bridge&quot;,        &quot;EnableIPv6&quot;: false,        &quot;IPAM&quot;: &#123;            &quot;Driver&quot;: &quot;default&quot;,            &quot;Options&quot;: &#123;&#125;,            &quot;Config&quot;: [                &#123;                    &quot;Subnet&quot;: &quot;172.18.0.0/16&quot;,                    &quot;Gateway&quot;: &quot;172.18.0.1&quot;                &#125;            ]        &#125;,        &quot;Internal&quot;: false,        &quot;Attachable&quot;: false,        &quot;Ingress&quot;: false,        &quot;ConfigFrom&quot;: &#123;            &quot;Network&quot;: &quot;&quot;        &#125;,        &quot;ConfigOnly&quot;: false,        &quot;Containers&quot;: &#123;&#125;,        &quot;Options&quot;: &#123;&#125;,        &quot;Labels&quot;: &#123;&#125;    &#125;]\n\n3、使用 custom网络\n[root@centos-linux /]# docker run --rm -d --name demo-1 --network custom_network alpine top93e04b37b6a7418131a1ff2ef21d45c807757746841a601a1438ffa5c6fa1061[root@centos-linux /]# docker run --rm -d --name demo-2 --network custom_network alpine topbe07cf3872c42a46dc564fa8f20dee696301e8cc24dc653ffa71cb52bd4c0de3\n\n4、是否可以相互ping通\n\n容器间可以相互Ping通\n\n[root@centos-linux /]# docker exec -it demo-1 ping  -c 2 demo-2PING demo-2 (172.18.0.3): 56 data bytes64 bytes from 172.18.0.3: seq=0 ttl=64 time=0.034 ms64 bytes from 172.18.0.3: seq=1 ttl=64 time=0.143 ms--- demo-2 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.034/0.088/0.143 ms[root@centos-linux /]# docker exec -it demo-2 ping -c 2 demo-1PING demo-1 (172.18.0.2): 56 data bytes64 bytes from 172.18.0.2: seq=0 ttl=64 time=0.041 ms64 bytes from 172.18.0.2: seq=1 ttl=64 time=0.091 ms--- demo-1 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.041/0.066/0.091 ms\n\n\nping 宿主机 pass\n\n[root@centos-linux /]# docker exec -it demo-2 ping -c 2 192.168.56.3PING 192.168.56.3 (192.168.56.3): 56 data bytes64 bytes from 192.168.56.3: seq=0 ttl=64 time=0.082 ms64 bytes from 192.168.56.3: seq=1 ttl=64 time=0.121 ms--- 192.168.56.3 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.082/0.101/0.121 ms\n\n6、跨宿主机访问​    官方文档: 某些应用程序，尤其是旧版应用程序或监视网络流量的应用程序，期望直接连接到物理网络。在这种情况下，可以使用macvlan网络驱动程序为每个容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。\n​    对于SDN来说，一般都是基于overlay模式，尤其是在使用docker中会出现跨主机容器无法通信的问题，docker提供ipvlan技术完全可以解决，但是需要linux内核版本&gt; 4.2，唯一的局限性就是需要自己实现宿主机与容器间通信的问题！\n​    像我们公司就是基于ipvlan实现的跨宿主机通信的问题\n1、macvlan 模式介绍​        macvlan 是在docker1.2版本之后推出的，主要是解决：是旧版应用程序或监视网络流量的应用程序，期望直接连接到物理网络(意思就是直接连接到物理网络，可以相互ping通)\n​        在这种情况下，可以使用macvlan网络驱动程序为每个容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，您需要在Docker主机上指定用于的物理接口macvlan，以及的子网和网关macvlan。您甚至可以macvlan使用不同的物理网络接口隔离网络。请记住以下几点：\n\n由于IP地址耗尽或“ VLAN传播”，很容易无意间损坏您的网络，在这种情况下，您的网络中有大量不正确的唯一MAC地址。\n您的网络设备需要能够处理“混杂模式”，在该模式下，可以为一个物理接口分配多个MAC地址。\n如果您的应用程序可以使用网桥（在单个Docker主机上）或覆盖（跨多个Docker主机进行通信）工作，那么从长远来看，这些解决方案可能会更好。\n\n使用1、我的主机ip\n[root@centos-linux ~]# ip addr show eth02: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 00:1c:42:b8:a6:b2 brd ff:ff:ff:ff:ff:ff    inet 192.168.56.3/24 brd 192.168.56.255 scope global noprefixroute dynamic eth0       valid_lft 1098sec preferred_lft 1098sec    inet6 fdb2:2c26:f4e4:0:21c:42ff:feb8:a6b2/64 scope global noprefixroute dynamic       valid_lft 2591546sec preferred_lft 604346sec    inet6 fe80::21c:42ff:feb8:a6b2/64 scope link noprefixroute       valid_lft forever preferred_lft forever\n\n2、根据主机ip去创建 macvlan\n[root@centos-linux ~]# docker network create -d macvlan \\--subnet=192.168.56.0/24 \\--gateway=192.168.56.1 \\-o parent=eth0 macvlan_net3adcc89a20a0a40b55b026ffcb9164990ca8c347d23445f367ed1a88f83ddd57\n\n3、查看docker网络信息\n所有网络\n[root@centos-linux ~]# docker network listNETWORK ID     NAME          DRIVER    SCOPE3505ceea1e1b   bridge        bridge    local892b017dd40d   host          host      local3adcc89a20a0   macvlan_net   macvlan   local69e3ce2179b5   none          null      local\n\n信息\n[root@centos-linux ~]# docker network inspect macvlan_net[    &#123;        &quot;Name&quot;: &quot;macvlan_net&quot;,        &quot;Id&quot;: &quot;71e776d96002b0d6977a65b6e370b3d8b71283304239e16144cdf1298f7500cc&quot;,        &quot;Created&quot;: &quot;2021-03-05T19:59:54.375164139+08:00&quot;,        &quot;Scope&quot;: &quot;local&quot;,        &quot;Driver&quot;: &quot;macvlan&quot;,        &quot;EnableIPv6&quot;: false,        &quot;IPAM&quot;: &#123;            &quot;Driver&quot;: &quot;default&quot;,            &quot;Options&quot;: &#123;&#125;,            &quot;Config&quot;: [                &#123;                    &quot;Subnet&quot;: &quot;192.168.56.0/24&quot;,                    &quot;Gateway&quot;: &quot;192.168.56.1&quot;                &#125;            ]        &#125;,        &quot;Internal&quot;: false,        &quot;Attachable&quot;: false,        &quot;Ingress&quot;: false,        &quot;ConfigFrom&quot;: &#123;            &quot;Network&quot;: &quot;&quot;        &#125;,        &quot;ConfigOnly&quot;: false,        &quot;Containers&quot;: &#123;            &quot;2a2285139cd7fb92a93b437ad6bd00b9b2d80f1918b448f22cadc03a32cc5d12&quot;: &#123;                &quot;Name&quot;: &quot;gallant_nightingale&quot;,                &quot;EndpointID&quot;: &quot;7399fc4d01163d87b0ef078772c0abd3e1dd857eb6bcc692eb06d5cc9767008b&quot;,                &quot;MacAddress&quot;: &quot;02:42:c0:a8:38:20&quot;,                &quot;IPv4Address&quot;: &quot;192.168.56.32/24&quot;,                &quot;IPv6Address&quot;: &quot;&quot;            &#125;,            &quot;61e4e496c22ab5ca0f4bd7a44fd3c9b996f6ff81a33c6853ac94270608696974&quot;: &#123;                &quot;Name&quot;: &quot;nervous_mendeleev&quot;,                &quot;EndpointID&quot;: &quot;e238ca83dc06eff26cc6f862d431ffac8750815870bfb2eb7fc5a498c9a81cec&quot;,                &quot;MacAddress&quot;: &quot;02:42:c0:a8:38:1f&quot;,                &quot;IPv4Address&quot;: &quot;192.168.56.31/24&quot;,                &quot;IPv6Address&quot;: &quot;&quot;            &#125;        &#125;,        &quot;Options&quot;: &#123;            &quot;parent&quot;: &quot;eth0&quot;        &#125;,        &quot;Labels&quot;: &#123;&#125;    &#125;]\n\n4、创建容器\n1)直接启动\n可以看到IP是 192.168.56.2 ，属于 192.168.56.3/24 子网下面，由于是第一个，所以第一个容器是顺序创建的，ip就是2 (存在的问题就是可能和宿主机ip相同，这就尴尬了)\n容器1\n[root@centos-linux ~]# docker run --rm -it --net=macvlan_net --ip 192.168.56.31 alpine /bin/sh/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever8: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP    link/ether 02:42:c0:a8:38:1f brd ff:ff:ff:ff:ff:ff    inet 192.168.56.31/24 brd 192.168.56.255 scope global eth0       valid_lft forever preferred_lft forever\n\n容器2\n[root@centos-linux ~]# docker run --rm -it --net=macvlan_net --ip 192.168.56.32 alpine /bin/sh/ # ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever9: eth0@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue state UP    link/ether 02:42:c0:a8:38:20 brd ff:ff:ff:ff:ff:ff    inet 192.168.56.32/24 brd 192.168.56.255 scope global eth0       valid_lft forever preferred_lft forever\n\n2）ping实验\n1、同一宿主机无法PING通容器：\n[root@centos-linux ~]# ping 192.168.56.31 -c 2PING 192.168.56.31 (192.168.56.31) 56(84) bytes of data.From 192.168.56.3 icmp_seq=1 Destination Host UnreachableFrom 192.168.56.3 icmp_seq=2 Destination Host Unreachable--- 192.168.56.31 ping statistics ---2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 1002mspipe 2[root@centos-linux ~]# ping 192.168.56.32 -c 2PING 192.168.56.32 (192.168.56.32) 56(84) bytes of data.^[From 192.168.56.3 icmp_seq=1 Destination Host UnreachableFrom 192.168.56.3 icmp_seq=2 Destination Host Unreachable--- 192.168.56.32 ping statistics ---2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 1007mspipe 2\n\n关于： Destination Host Unreachable ,可以看一下这篇文章：https://www.eefocus.com/communication/426853 ,问题就是  局域网中无法找到对应 IP 的 MAC 地址，无法完成封装，所以可以看到docker的实现其实就是做了一层mac地址的转换\n[root@centos-linux ~]# ip route get 192.168.56.32192.168.56.32 dev eth0 src 192.168.56.3 uid 0    cache# 主要走的是通过 eth0     \n\n2、同一个宿主机那容器无法ping通宿主机：\n/ # ping -c 2  192.168.56.3PING 192.168.56.3 (192.168.56.3): 56 data bytes^C--- 192.168.56.3 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss/ # ping -c 2  192.168.56.3PING 192.168.56.3 (192.168.56.3): 56 data bytes--- 192.168.56.3 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss\n\n原因是什么：\n3、同一个宿主机那容器间通信\n可以看到同一个宿主机内的容器可以相互通信\n/ #  ping 192.168.56.32 -c 2PING 192.168.56.32 (192.168.56.32): 56 data bytes64 bytes from 192.168.56.32: seq=0 ttl=64 time=0.054 ms64 bytes from 192.168.56.32: seq=1 ttl=64 time=0.116 ms--- 192.168.56.32 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.054/0.085/0.116 ms/ # ping 192.168.56.31 -c 2PING 192.168.56.31 (192.168.56.31): 56 data bytes64 bytes from 192.168.56.31: seq=0 ttl=64 time=0.055 ms64 bytes from 192.168.56.31: seq=1 ttl=64 time=0.114 ms--- 192.168.56.31 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.055/0.084/0.114 ms\n\n4、创建宿主机2\n[root@centos-4-5 ~]# ip addr show eth02: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 00:1c:42:79:65:9d brd ff:ff:ff:ff:ff:ff    inet 192.168.56.7/24 brd 192.168.56.255 scope global noprefixroute dynamic eth0       valid_lft 1475sec preferred_lft 1475sec    inet6 fdb2:2c26:f4e4:0:21c:42ff:fe79:659d/64 scope global noprefixroute dynamic       valid_lft 2591565sec preferred_lft 604365sec    inet6 fe80::21c:42ff:fe79:659d/64 scope link noprefixroute       valid_lft forever preferred_lft forever\n\n5、测试主机1与主机2通信 ,完全OK\n[root@centos-4-5 ~]# ping 192.168.56.3 -c 2PING 192.168.56.3 (192.168.56.3) 56(84) bytes of data.64 bytes from 192.168.56.3: icmp_seq=1 ttl=64 time=0.585 ms64 bytes from 192.168.56.3: icmp_seq=2 ttl=64 time=0.521 ms--- 192.168.56.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1043msrtt min/avg/max/mdev = 0.521/0.553/0.585/0.032 ms\n\n6、测试主机2与主机1的容器通信，不可用\n[root@centos-4-5 ~]# ping 192.168.56.31 -c 2PING 192.168.56.31 (192.168.56.31) 56(84) bytes of data.--- 192.168.56.31 ping statistics ---2 packets transmitted, 0 received, 100% packet loss, time 1051ms\n\n总结macvlan 模式的局限性较大，只能宿主机内容器之间相互可以访问，但是不能实现跨主机容器的通信\n2、IpVlan 模式ipvlan就比较强大了，可以支持跨宿主机通信，不需要任何额外的配置！\n使用[root@centos-linux ~]# docker network create -d ipvlan \\--subnet=192.168.56.0/24 \\--gateway=192.168.56.1 \\-o parent=eth0 ipvlan_net\n\n详情\n[root@centos-linux ~]# docker network inspect ipvlan_net[    &#123;        &quot;Name&quot;: &quot;ipvlan_net&quot;,        &quot;Id&quot;: &quot;22a8b5faf9ddc2b8a7a81d67467649b331c8ccaf2a7bc7aaf25dd7344d1fed26&quot;,        &quot;Created&quot;: &quot;2021-03-06T16:03:26.113213178+08:00&quot;,        &quot;Scope&quot;: &quot;local&quot;,        &quot;Driver&quot;: &quot;ipvlan&quot;,        &quot;EnableIPv6&quot;: false,        &quot;IPAM&quot;: &#123;            &quot;Driver&quot;: &quot;default&quot;,            &quot;Options&quot;: &#123;&#125;,            &quot;Config&quot;: [                &#123;                    &quot;Subnet&quot;: &quot;192.168.56.0/24&quot;,                    &quot;Gateway&quot;: &quot;192.168.56.1&quot;                &#125;            ]        &#125;,        &quot;Internal&quot;: false,        &quot;Attachable&quot;: false,        &quot;Ingress&quot;: false,        &quot;ConfigFrom&quot;: &#123;            &quot;Network&quot;: &quot;&quot;        &#125;,        &quot;ConfigOnly&quot;: false,        &quot;Containers&quot;: &#123;            &quot;80c8bb73c329f1c0c370514c72cd25979a1b5d8aa112b49c24385d558d2d4e53&quot;: &#123;                &quot;Name&quot;: &quot;recursing_leakey&quot;,                &quot;EndpointID&quot;: &quot;8055b00e4981d35b08f39565bde348142785565b3e43055fb719d9f7cef7fae5&quot;,                &quot;MacAddress&quot;: &quot;&quot;,                &quot;IPv4Address&quot;: &quot;192.168.56.32/24&quot;,                &quot;IPv6Address&quot;: &quot;&quot;            &#125;,            &quot;e1f96d16c0e5f9b04cc49b63cc991c89834ec6f0f599a64853bb6dddd26b3f51&quot;: &#123;                &quot;Name&quot;: &quot;confident_hodgkin&quot;,                &quot;EndpointID&quot;: &quot;d1347ff2d6f1d8c2070d1dccad5aa29f3e3c34bc982ab026a352f071f6626dd7&quot;,                &quot;MacAddress&quot;: &quot;&quot;,                &quot;IPv4Address&quot;: &quot;192.168.56.31/24&quot;,                &quot;IPv6Address&quot;: &quot;&quot;            &#125;        &#125;,        &quot;Options&quot;: &#123;            &quot;parent&quot;: &quot;eth0&quot;        &#125;,        &quot;Labels&quot;: &#123;&#125;    &#125;]\n\n1、主机1-&gt; 容器1-2（不通） / 容器1-2 -&gt; 主机1 (不通)\n[root@centos-linux ~]# ping 192.168.56.32 -c 2PING 192.168.56.32 (192.168.56.32) 56(84) bytes of data.From 192.168.56.3 icmp_seq=1 Destination Host UnreachableFrom 192.168.56.3 icmp_seq=2 Destination Host Unreachable--- 192.168.56.32 ping statistics ---2 packets transmitted, 0 received, +2 errors, 100% packet loss, time 1072mspipe 2/ # ping 192.168.56.3 -c 2PING 192.168.56.3 (192.168.56.3): 56 data bytes--- 192.168.56.3 ping statistics ---2 packets transmitted, 0 packets received, 100% packet loss\n\n2、容器1-2-&gt;容器1-1 （通）\n/ # ping 192.168.56.31 -c 2PING 192.168.56.31 (192.168.56.31): 56 data bytes64 bytes from 192.168.56.31: seq=0 ttl=64 time=0.099 ms64 bytes from 192.168.56.31: seq=1 ttl=64 time=0.188 ms--- 192.168.56.31 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.099/0.143/0.188 ms\n\n3、主机2-&gt;主机1 （通）\n[root@centos-4-5 ~]# ping 192.168.56.3 -c 2PING 192.168.56.3 (192.168.56.3) 56(84) bytes of data.64 bytes from 192.168.56.3: icmp_seq=1 ttl=64 time=0.478 ms64 bytes from 192.168.56.3: icmp_seq=2 ttl=64 time=0.551 ms--- 192.168.56.3 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1064msrtt min/avg/max/mdev = 0.478/0.514/0.551/0.042 ms\n\n4、主机2容器2-&gt; 主机1 （通）\n/ # ping 192.168.56.3 -c 2PING 192.168.56.3 (192.168.56.3): 56 data bytes64 bytes from 192.168.56.3: seq=0 ttl=64 time=0.469 ms64 bytes from 192.168.56.3: seq=1 ttl=64 time=0.605 ms--- 192.168.56.3 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.469/0.537/0.605 ms\n\n5、主机2容器2-2-&gt;主机1容器1-2 （通）\n/ # ping 192.168.56.32 -c 2PING 192.168.56.32 (192.168.56.32): 56 data bytes64 bytes from 192.168.56.32: seq=0 ttl=64 time=0.569 ms64 bytes from 192.168.56.32: seq=1 ttl=64 time=0.687 ms--- 192.168.56.32 ping statistics ---2 packets transmitted, 2 packets received, 0% packet lossround-trip min/avg/max = 0.569/0.628/0.687 ms\n\n6、主机2 -&gt; 主机1容器1-2 （通）\n[root@centos-4-5 ~]# ping 192.168.56.32 -c 2PING 192.168.56.32 (192.168.56.32) 56(84) bytes of data.64 bytes from 192.168.56.32: icmp_seq=1 ttl=64 time=0.321 ms64 bytes from 192.168.56.32: icmp_seq=2 ttl=64 time=0.609 ms--- 192.168.56.32 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1022msrtt min/avg/max/mdev = 0.321/0.465/0.609/0.144 ms\n\n总结\n支持跨主机间容器通信(依赖于宿主机之间可以相互通信，其实只要在一个子网下即可)\n不支持单机内的宿主机容器间的通信\n\n3、参考文章linux 网络虚拟化： macvlan\nDocker 跨主机容器间网络通信（一）\nDocker系列（十三）：Docker 跨主机容器间网络通信（二）\nDocker系列（十四）：Docker Swarm集群\n 容器网络：盘点，解释与分析\nMacvlan与ipvlan\n","categories":["云原生"],"tags":["Docker","网络"]},{"title":"Makefile学习","url":"/2021/03/20/a9ec632af8ce6689c201007d3b97b0df/","content":"​    Makefile 在开源项目中还是相当的常见的，熟悉他的基本语法，还是很有必要的，其次是Makefile相对于shell脚本的优点就是他的关联性，和前置条件等都很好的解决的构建链条的问题。有些学c/cpp的同学可能比较熟悉，我们这个核心不关注于这个，主要是使用在日常中\n\n\nmake 一些cli参数\n-n 参数：\n\n　　 使用 -n 参数，让 make 命令输出将要执行的操作步骤，而不是真正执行这些操作；\n➜  makefile git:(master) ✗ touch Makefile2      ➜  makefile git:(master) ✗ make -n        rm -f Makefile1 Makefile2 Makefile3➜  makefile git:(master) ✗ ls Makefile  Makefile1 Makefile2\n\n\n-f 参数：\n\n　　使用 -f 参数，后面可以接一个文件名，用于指定一个文件作为 makefile 文件。如果没有使用 -f 选项，则 make 命令会在当前目录下查找名为 makefile 的文件，如果该文件不存在，则查找名为 Makefile 的文件。 \n\n-C 参数\n​    一般当我们调用其他目录的makefile，可以直接 make -C &lt;dir&gt;  执行完退回当前make命令，类似于shell\n\ninclude  可以引用用其他的makefile，类似于其他编程语言的import，和环境变量 MAKEFILES 等效\n\n\nMakefile文件\ninclude a.make b.makeall: echoa echob\t@echo hello\n\na.make 文件\nechoa:\t@echo hello a\t\n\nb.make 文件\nechob:\t@echo hello b\n\n执行\n1） 可以发现include却是是把它完完全全的copy到了头部\n➜  makefile git:(master) ✗ makehello a\n\n2）继续，完全符合\n➜  makefile git:(master) ✗ make allhello ahello bhello\n\nmakefile一些环境变量MAKE\n​    其实就是你的make环境变量的，which make 即可\n\n.PHONY: allall:\t@echo &quot;make路径: $(MAKE)&quot;\n\n输出\n➜  makefile git:(master) ✗ makemake路径: /Library/Developer/CommandLineTools/usr/bin/make\n\nRM\n​    这个主要是当作 rm -f 参数\n\n.PHONY: allclean:\t$(RM) Makefile1 Makefile2 Makefile3\n\n输出：\n➜  makefile git:(master) ✗ makerm -f Makefile1 Makefile2 Makefile3\n\nMAKEFILE_LIST\n​    MAKEFILE_LIST的变量, 它是个列表变量, 在每次make读入一个make文件时, 都把它添加到最后一项，gnu make 有效。\n\n\nMakefile 文件\n\nall:\t@echo &quot;当前makefile: $(MAKEFILE_LIST)&quot;\t@$(MAKE) -f Makefile2\n\n\nMakefile 文件2\n\nall:\t@echo &quot;当前makefile: $(MAKEFILE_LIST)&quot;\n\n输出\n➜  makefile git:(master) ✗ make当前makefile:  Makefile当前makefile:  Makefile2\n\n所以依靠这个可以获取当前路径，但是目前没有模拟出 MAKEFILE_LIST 多个列表\n.PHONY:first:\t@echo $(MAKEFILE_LIST)second:\t@echo $(lastword $(MAKEFILE_LIST))third:\t@echo $(realpath $(lastword $(MAKEFILE_LIST)))latest: first second third\t@echo $(shell dirname $(realpath $(lastword $(MAKEFILE_LIST))))\n\n执行\n➜  go-source git:(master) ✗ make latest MakefileMakefile/Users/fanhaodong/go/code/go-source/Makefile/Users/fanhaodong/go/code/go-source\n\nmakefile 文件书写规则　    makefile 文件由一组依赖关系和规则构成。每个依赖关系都由一个目标（即将要创建的文件）和一个该目标所依赖的源文件组成；规则描述了如何通过这些依赖文件创建目标。简单的来说，makefile 文件的写法如下：\ntarget: prerequisites    command1    command2    ...\n\n　　其中，target 是即将要创建的目标（通常是一个可执行文件），target 后面紧跟一个冒号，prerequisite 是生成该目标所需要的源文件（依赖），一个目标所依赖的文件可以有多个，依赖文件与目标之间以及各依赖文件之间用空格或制表符 Tab 隔开，这些元素组成了一个依赖关系。随后的命令 command 就是规则，也就是 make 需要执行的命令，它可以是任意的 shell 命令。另外，makefile 文件中，注释以 # 号开头，一直延续到该行的结束。\n比如下面这个，target就是hello, prerequisite是 hello.c的文件\nhello:  hello.c\t$(CC) -o hello.s -S hello.c\t$(CC) -o hello.o -c hello.s\t$(CC) -o hello hello.o\n\n\n构建c项目all: test test: test.o anotherTest.o     gcc -Wall test.o anotherTest.o -o testtest.o: test.c     gcc -c -Wall test.c anotherTest.o: anotherTest.c     gcc -c -Wall anotherTest.c clean:     rm -rf *.o test\n\nGNU的make工作时的执行步骤如下：\n\n读入所有的Makefile。\n读入被include的其它Makefile。\n初始化文件中的变量。\n推导隐晦规则，并分析所有规则。\n为所有的目标文件创建依赖关系链。\n根据依赖关系，决定哪些目标要重新生成。\n执行生成命令。\n\n1-5步为第一个阶段，6-7为第二个阶段。第一个阶段中，如果定义的变量被使用了，那么，make会把其展开在使用的位置。但make并不会完全马上展开，make使用的是拖延战术，如果变量出现在依赖关系的规则中，那么仅当这条依赖被决定要使用了，变量才会在其内部展开。\n当然，这个工作方式你不一定要清楚，但是知道这个方式你也会对make更为熟悉。有了这个基础，后续部分也就容易看懂了。\n申明变量\n= 类似宏一样，他会对变量进行引用，在执行时扩展，允许递归扩展\n:= 如果变量申明符合先来后到，和 =含义一样，但是如果 申明a引用了b但是b还没有申明，此时认为b为空\n\na = $(b) + 1b = 2c := $(d) + 1d = 2all:\t@echo $(a)\t@echo $(c)\n\n输出\n➜  makefile git:(master) ✗ make2 + 1+ 1\n奇怪的现象： 可以发现我们申明a变量后，但是输出的时候却是 100 ，可以发现cli传递的优先级最高，不可以被覆盖\n➜  makefile git:(master) ✗ make a=100        100+ 1\n\n\n\n?= 如果a变量前面已经申明过了，那么后面 a ?= xxx 则因为前面已经申明了a，所以不进行赋值，也就是 a?=xxxx无效，如果前面没有申明则有效\n\nA = helloA ?= hello worldall:\t@echo $(A)\n\n输出：hello\n\n+= 这个类似于 a+=1 ， 意思就是在原来的基础上 += ，很方便，下面提供demo\n\nbuild_args := -raceifeq ($(vendor),true)\tbuild_args += -mod=vendorendifall:\t@echo $(build_args)\n\n输出：\n➜  makefile git:(master) ✗ make vendor=true-race -mod=vendor\n\n命令行参数echo:\t@echo $(arg)\n\n执行：\n➜  makefile git:(master) ✗ make arg=ruoyuruoyu\n\n执行函数1、call + define 宏定义类似于C语言的宏定义\n# 编译生成到bin目录下define build    sh ./build.sh $(1) ./bin/$(strip $(2))endef# 脚手架脚本go-build: pre\t$(call build, cmd/go-build/main.go, go-build)\n\n2、自带函数\n​    格式 $(&lt;命令&gt; &lt;参数&gt;)\n\nall:\t@echo $(lastword 1 2 3)\n\n输出\n➜  makefile git:(master) ✗ make3\n\n3、调用shell函数all:\t@echo $(shell dirname /data/test)\n\n执行\n➜  makefile git:(master) ✗ make/data\n\nMakefile文件的语法&lt;target&gt; : &lt;prerequisites&gt; [tab]  &lt;commands&gt;\n\n\ntarget: 目标，支持模式匹配\nprerequisites：前置条件，可以有多个，支持模式匹配\ncommands: 前面必须有 tab ，是shell命令/makefile函数命令\n\n1、注释​        注释一般使用 # 开头表示，但是如果注释在目标的命令包含\n# 一般all定义了全部all:\t#hello\n\n执行\n➜  makefile git:(master) ✗ make#hello\n\n2、关闭回声这个其实很简单，就是在执行shell命令的时候，往往会打印日志，所以这里提供了很好的解决方式，使用 @ 符号\nall:\techo &quot;hello world&quot;\n\n执行后会发现，每次执行的时候都会打印回声\n➜  makefile git:(master) ✗ makeecho &quot;hello world&quot;hello world\n\n所以可以将makefile文件改成以下\nall:\t@echo &quot;hello world&quot;\n\n输出\n➜  makefile git:(master) ✗ makehello world\n\n3、通配符​    和bash一样，主要有 * 等通配符，主要是在 shell脚本中使用\nnew:\tfor x in &#123;1,2,3,4&#125;;do touch $$x.test ;doneclean:\t$(RM) *.test\n\n执行\n➜  makefile git:(master) ✗ make new for x in &#123;1,2,3,4&#125;;do touch $x.test ;done➜  makefile git:(master) ✗ ls | grep test1.test2.test3.test4.test➜  makefile git:(master) ✗ make clean rm -f *.test➜  makefile git:(master) ✗ ls | grep test\n\n4、模式匹配主要是对文件名的支持！主要是在 目标和依赖中使用, 使用匹配符%，可以将大量同类型的文件，只用一条规则就完成构建。\n%.o: %.c\n\n等同于\nf1.o: f1.cf2.o: f2.c\n\n不懂的可以看一下这篇文章，对比一下 模式匹配和通配符的区别 :   https://blog.csdn.net/BobYuan888/article/details/88640923\n理解模式匹配必须了解下面这四个\n$@：目标的名字\n$^：构造所需文件列表所有所有文件的名字\n$&lt;：构造所需文件列表的第一个文件的名字\n$?：构造所需文件列表中更新过的文件\n大致原理：\n\n我要找f1.o的构造规则，看看Makefile中那个规则符合。\n然后找到了%.o:%.c\n来套一下来套一下\n %.o 和我要找的 f1.o 匹配\n套上了，得到%=f1。\n所以在后面的%.c就表示f1.c了。\nOK进行构造\n\n1、例子一（编译c文件）\n%.o: %.c %.h\t@echo &quot;目标的名字: $@, 依赖的第一个文件: $&lt; , 依赖的全部文件: $^, 所更新的文件: $?&quot;\t$(CC) -o $@ -c $&lt;all: utils.o\t@echo &quot;编译。。。&quot;\tclean:\t$(RM) *.i *.s *.o main\n\n执行，可以看到完全符合我们的例子\n目标的名字: utils.o, 依赖的第一个文件: utils.c , 依赖的全部文件: utils.c utils.h, 所更新的文件: utils.c utils.hcc -o utils.o -c utils.c编译。。。\n\nfor循环1、makefile: foreach循环语法： $(foreach &lt;var&gt;, $(g_var), &lt;command1&gt;;&lt;command2&gt;) ， 这里需要变量引用需要使用 $()\nlist := $(shell ls)all:\t@$(foreach item,$(list),\\\t\techo $(item);\\\t\techo $(realpath $(item));\\\t\techo &quot;====================&quot;;\\\t)\n\n输出：\n➜  makefile git:(master) ✗ makeMakefile/Users/fanhaodong/note/note/demo/makefile/Makefile====================Makefile1/Users/fanhaodong/note/note/demo/makefile/Makefile1====================Makefile2/Users/fanhaodong/note/note/demo/makefile/Makefile2====================\n\n3、shell：for 循环list := $(shell ls)all:\t@for x in $(list); do\\\t\techo $$x;\\\tdone\n\n记住一点就好， $ 符号转移需要使用 $$\n执行\n➜  makefile git:(master) ✗ make mfor MakefileMakefile1Makefile2a.makeb.make\n\nif 函数1、makefile: if 函数命令格式： $(if &lt;condition&gt;, &lt;yes do1&gt;;&lt;yes do2&gt;, &lt;no do1&gt;;&lt;no do2&gt;)\nall:\t@$(if $(shell command -v $(arg)),echo command $(arg) is exist,echo command $(arg) is not exist)\n\n执行\n➜  makefile git:(master) ✗ make arg=gocommand go is exist➜  makefile git:(master) ✗ make arg=go1command go1 is not exist\n\n2、shell: if 函数all:\t@if [ `command -v $(arg)` ];then\\\t\techo &quot;command [$(arg)] is exist&quot;;\\\telse \\\t\techo &quot;command [$(arg)] is not exist&quot;;\\\tfi\n\n执行\n➜  makefile git:(master) ✗ make arg=gocommand [go] is exist➜  makefile git:(master) ✗ make arg=go1command [go1] is not exist\n\n执行多个命令echo:\t@echo hello worldecho2:\t@echo hello world 2\t\n\n执行：\n➜  makefile git:(master) ✗ make echo echo2hello worldhello world 2\n\n宏定义define echo\techo &quot;hello, $(1)!&quot;endefARG := ifdef arg\tARG := $(arg)else\tARG := NULLendif\tall: print\t@$(call echo,&quot;world&quot;)\t@echo $(ARG)print:\t@echo &quot;arg: $(arg)&quot;\n\n执行\n➜  makefile git:(master) ✗ make arg=worldarg: worldhello, world!world\n\n系统环境变量申明推荐： export &lt;变量名称&gt;  ， 获取使用 $&#123;&lt;变量名称&gt;&#125;\nGOPROXY := https://goproxy.cn,directexport GOPROXYall:\t@echo $&#123;GOPROXY&#125;\n\n编译C项目c项目往往很复杂，设计到 预编译，编译，汇编，链接 的过程\n\n1、文件 (头文件、main文件)1、utils.h\n#ifndef _ADD_H_#define _ADD_H_int add (int a,int b);#endif\n\n2、utils.c\nint add(int x ,int y)&#123;    return x+y;&#125;\n\n3、main.c\n注意：头文件的寻找方式\n\n先搜索当前目录\n然后搜索-I指定的目录,例如 -I ./head\n再搜索gcc的环境变量CPLUS_INCLUDE_PATH（C程序使用的是C_INCLUDE_PATH）\n最后搜索gcc的内定目录\n\n#include &lt;stdio.h&gt;#include &quot;utils.h&quot;int main(int argc, char const *argv[])&#123;    printf(&quot;1+2 = %d\\n&quot;,add(1,2));    return 0;&#125;\n\n假如 .h 文件放在 head 目录\n➜  cpp git:(master) ✗ ls head utils.h# 可以发现编译异常，异常时 .h文件未找到➜  cpp git:(master) ✗ gcc -c main.c -o main.omain.c:2:10: fatal error: &#x27;utils.h&#x27; file not found#include &quot;utils.h&quot;         ^~~~~~~~~1 error generated.# 修改 -I 参数可以发现通过➜  cpp git:(master) ✗ gcc -I ./head  -c main.c -o main.o➜  cpp git:(master) ✗ ls | grep main.omain.o\n\n2、预编译 -E-E：预编译，这一步主要是将头文件，宏定义展开到文件，是文本形式\n➜  cpp git:(master) ✗ gcc -E main.c -o main.i➜  cpp git:(master) ✗ tail -f 10 main.i tail: 10: No such file or directory==&gt; main.i &lt;==### 可以看到这里是把 utils.h 的头文件信息 copy 过来了int add (int a,int b);# 3 &quot;main.c&quot; 2int main(int argc, char const *argv[])&#123;    printf(&quot;1+2 = %d\\n&quot;,add(1,2));    return 0;&#125;\n\n3、编译 -S\n编译为汇编代码，是文本形式\n\n➜  cpp git:(master) ✗ gcc -S main.i -o main.s\n\n\n4、汇编 -c\n​    就是编译成二进制的汇编文件，是可重定位目标程序，属于二进制文件\n\n➜  cpp git:(master) ✗ gcc -c main.s -o main.o➜  cpp git:(master) ✗ hexdump -C main.o00000000  cf fa ed fe 07 00 00 01  03 00 00 00 01 00 00 00  |................|00000010  04 00 00 00 08 02 00 00  00 20 00 00 00 00 00 00  |......... ......|00000020  19 00 00 00 88 01 00 00  00 00 00 00 00 00 00 00  |................|00000030  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|00000040  b0 00 00 00 00 00 00 00  28 02 00 00 00 00 00 00  |........(.......|00000050  b0 00 00 00 00 00 00 00  07 00 00 00 07 00 00 00  |................|00000060  04 00 00 00 00 00 00 00  5f 5f 74 65 78 74 00 00  |........__text..|00000070  00 00 00 00 00 00 00 00  5f 5f 54 45 58 54 00 00  |........__TEXT..|00000080  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|00000090  42 00 00 00 00 00 00 00  28 02 00 00 04 00 00 00  |B.......(.......|000000a0  d8 02 00 00 03 00 00 00  00 04 00 80 00 00 00 00  |................|➜  cpp git:(master) ✗ objdump -d main.omain.o: file format Mach-O 64-bit x86-64Disassembly of section __TEXT,__text:0000000000000000 _main:       0: 55                            pushq   %rbp       1: 48 89 e5                      movq    %rsp, %rbp       4: 48 83 ec 20                   subq    $32, %rsp       8: c7 45 fc 00 00 00 00          movl    $0, -4(%rbp)       f: 89 7d f8                      movl    %edi, -8(%rbp)      12: 48 89 75 f0                   movq    %rsi, -16(%rbp)      16: bf 01 00 00 00                movl    $1, %edi      1b: be 02 00 00 00                movl    $2, %esi      20: e8 00 00 00 00                callq   0 &lt;_main+0x25&gt;      25: 48 8d 3d 16 00 00 00          leaq    22(%rip), %rdi      2c: 89 c6                         movl    %eax, %esi      2e: b0 00                         movb    $0, %al      30: e8 00 00 00 00                callq   0 &lt;_main+0x35&gt;      35: 31 c9                         xorl    %ecx, %ecx      37: 89 45 ec                      movl    %eax, -20(%rbp)      3a: 89 c8                         movl    %ecx, %eax      3c: 48 83 c4 20                   addq    $32, %rsp      40: 5d                            popq    %rbp      41: c3                            retq\n\n5、链接对于c/cpp语言来说，最难的就是链接了！这里也设计到隐晦规则了，首先 .o 是符合 main.o, utils.o的，所以会执行 两次 cc，最终链接成功\n# 伪目标,这里定义的目标不会去文件系统里寻找.PHONY: all clean# CC 属于makefile的全局变量，已经定义好了，但是我们使用gcc需要指定CC := gcc# $@ 目前的目标项目名称 也就是 %.o# $&lt; 目前的依赖项目%.o: %.c\t$(CC) -c $&lt; -o $@all: install run clean# 当依赖符合模式匹配时候，会执行上面的 %.o: %.cinstall: utils.o main.o\tgcc -o main utils.o main.orun:\t./mainclean:\t$(RM) *.i *.s *.o main\n\n执行\n➜  cpp git:(master) ✗ makegcc -c utils.c -o utils.ogcc -c main.c -o main.ogcc -o main utils.o main.o./main1+2 = 3rm -f *.i *.s *.o main\n\n帮助如果你想写help，可以使用下面那个表达式\n.PHONY: helpecho: ## 打印echo\t@echo &quot;hello&quot;all: ## 打印echo1help: ## 帮助\t@awk &#x27;BEGIN &#123;FS = &quot;:.*?## &quot;&#125; /^[a-zA-Z_-]+:.*?## / &#123;sub(&quot;\\\\\\\\n&quot;,sprintf(&quot;\\n%22c&quot;,&quot; &quot;), $$2);printf &quot; \\033[36m%-20s\\033[0m  %s\\n&quot;, $$1, $$2&#125;&#x27; $(MAKEFILE_LIST)\n\n其实很简单，了解 awk 语法的话，知道  awk &#39;条件 动作&#39; 文件名 所谓条件就是正则表达式，分隔符是:.*?## ，然后匹配的条件是以  字母开头的\n[root@19096dee708b data]# cat demo.txt11 2211122 33\n\n匹配一下·\n[root@19096dee708b data]# awk  &#x27;&#123;printf &quot;$1=%s $2=%s\\n&quot;,$1,$2&#125;&#x27; demo.txt$1=11 $2=22$1=111 $2=$1=22 $2=33\n\n我们要拿到我们的结果！所以需要匹配有空格的，匹配空格就是 \\s\n[root@19096dee708b data]# awk  &#x27;/\\s/ &#123;printf &quot;$1=%s $2=%s\\n&quot;,$1,$2&#125;&#x27; demo.txt$1=11 $2=22$1=22 $2=33\n\n\n\n","categories":["Linux"],"tags":["Makefile"]},{"title":"Mac 个人开发环境搭建","url":"/2021/08/24/a5ccc7a0e58afc7d2f946516f3e32dd0/","content":"​     个人的Mac环境，主要是解决一些更换电脑时需要重新搞一些东西，以及分享一下个人mac的配置，以及一些命令的推荐！\n\n\n安装常用命令brew和zshsh -c &quot;$(curl -fsSL https://anthony-wangpan.oss-accelerate.aliyuncs.com/software/2021/6-17/brew.sh)&quot;sh -c &quot;$(curl -fsSL https://anthony-wangpan.oss-accelerate.aliyuncs.com/software/2021/6-17/zsh.sh)&quot;\n\n安装GNU命令行主要是解决，我们Linux用户的痛点，发现很多命令macos使用方式不一样！\n# 备份下cp ~/.zshrc ~/.zshrc_copy# install grep sed awk gtarbrew install grepbrew install gnu-sedbrew install gawkbrew install gnu-tar# install coreutils, eg: ls,cd,nc, ...  brew install coreutils# install find utils, eg: find, xargs ..brew install findutils# install mysql-clientbrew install mysql-client\n\n环境变量配置：\n# aliasalias awk=gawk# export gnu binexport PATH=&quot;/usr/local/opt/gnu-sed/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-tar/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/grep/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/coreutils/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/findutils/libexec/gnubin:$PATH&quot;# export softwareexport PATH=&quot;/usr/local/opt/mysql-client/bin:$PATH&quot;\n\n系统工具安装\nbrew install htop\n\n高亮配置vim 高亮\n移动文件，cp /usr/share/vim/vimrc ~/.vimrc\n修改一下 ~/.vimrc 配置，尾部添加\n\nsyntax onset nu!set autoindent\n\nls 高亮alias 下 alias ls=&#39;ls -F --show-control-chars --color=auto&#39;\n维护的个人脚本1. 同步文件脚本\n记得在 $&#123;SYNC_HOME&#125;/.fileignore 创建文件，主要是申明一些不需要同步的文件目录和文件\n\n*.swp*.pyc*.pyo.git.DS_Store.idea.vscode-upload.jsonoutput*.class*.log*mvnw*target*.iml.m2\n\n\n在$&#123;SYNC_HOME&#125;/sync.sh 创建文件，并且copy下面文件\n\n#!/bin/bash########################### 配置开始# 远程服务器配置# 远程服务器的用户名称readonly DEV_USER=&quot;fanhaodong.516&quot;# 远程服务器的地址readonly DEV_IP=&quot;xx.xxx.xxx.xxx&quot;# 远程同步目录，推荐用户的根目录，例如可以执行 echo &quot;$HOME&quot; 查看用户根目录readonly REMOTE_PATH=&quot;/home/fanhaodong.516&quot;# 本地配置# 同步脚本目录readonly SYNC_HOME=&quot;/Users/local/go/bin/sync-devbox&quot;# 同步目录的白名单readonly WHITE_LIST=(&quot;/Users/local/go/src/github.com&quot; &quot;/Users/local/data&quot;)########################### 配置结束## 获取当前路径if [[ -z &quot;$&#123;1&#125;&quot; ]]; then    PWD=$(pwd)else    PWD=$&#123;1&#125;fiPASS=&quot;false&quot;NOT_PASS_DIR=&quot;&quot;for elem in &quot;$&#123;WHITE_LIST[@]&#125;&quot;; do    if echo &quot;$&#123;PWD&#125;&quot; | grep -e &quot;^$&#123;elem&#125;.*&quot;; then PASS=&quot;true&quot;; fi    NOT_PASS_DIR=$&#123;NOT_PASS_DIR&#125;&quot;$elem, &quot;doneif [[ &quot;$&#123;PASS&#125;&quot; == &quot;false&quot; ]]; then echo &quot;$&#123;PWD&#125; 无法同步,原因是目录不在$&#123;NOT_PASS_DIR&#125;目录下!&quot;; exit 1; fiif [[ &quot;$&#123;PWD: -1&#125;&quot; == &quot;/&quot; ]]; then    echo &quot;$&#123;PWD&#125; 无法同步,原因是目录最后包含 &#x27;/&#x27; &quot;    exit 1;fi# 替换 当前路径的 $&#123;HOME&#125; 为 $&#123;REMOTE_PATH&#125;REMOTE_PWD=$&#123;PWD/$&#123;HOME&#125;/$&#123;REMOTE_PATH&#125;&#125;echo &quot;rsync -avz --delete --progress --log-file=$&#123;SYNC_HOME&#125;/sync-devbox.log --log-file-format=&#x27;%t %f %b&#x27; --exclude-from=$&#123;SYNC_HOME&#125;/.fileignore $&#123;PWD&#125;/ $&#123;DEV_USER&#125;@$&#123;DEV_IP&#125;:$&#123;REMOTE_PWD&#125;/&quot;# 用法参考: https://www.ruanyifeng.com/blog/2020/08/rsync.html# -a 递归替换且文件元信息也替换# -v 展示信息# --delete 删除只存在于目标目录、不存在于源目录的文件。rsync -avz \\    --delete \\    --progress \\    --log-file=$&#123;SYNC_HOME&#125;/sync-devbox.log \\    --log-file-format=&#x27;%t %f %b&#x27; \\    --exclude-from=$&#123;SYNC_HOME&#125;/.fileignore \\    &quot;$&#123;PWD&#125;/&quot; &quot;$&#123;DEV_USER&#125;@$&#123;DEV_IP&#125;:$&#123;REMOTE_PWD&#125;/&quot;echo &quot;rsync $&#123;PWD&#125;/ -&gt; $&#123;REMOTE_PWD&#125;/  success!&quot;\n\n\n在远程服务器，配置本地服务的公钥，进行免密登陆！\n\nmac系统配置\n这个不能过快，不然双击无法选中东西！\nvim\n翻页\n\n\ncontrol + f 向下翻一页,  f的意思是 forward\ncontrol + b 向上翻一页, b的意思是 back forward\ncontrol + d 向下翻半页， d的意思是 down\ncontrol + u 向下翻半页， u的意思是 up\ncontrol + e 向下滚动一行， e的意思是 ``\ncontrol + y 向上滚动一行，y的意思是``\n\n\n操作\n\nd删除（Delete），c剪切（Cut），y复制（Yank），p粘贴（Paste）\n","categories":["Linux"],"tags":["mac"]},{"title":"shell技巧介绍介绍","url":"/2021/03/01/bfb83a0f198dea6e73567268963f4e9b/","content":"​        Shell 脚本在我们日常开发和学习都有举足轻重的地位，比如看一些开源项目，比如项目中的各式各样的脚本，对于促进生产力工具有很大帮助！而且shell最大的好处就是依赖比较小，直接可以运行！\n\n\n1、命令小技巧1、-x 命令进行跟踪调试执行#!/bin/shnum1=10num2=20if (($num1 &lt;= $num2)); then    echo num1 lesser equal num2else    echo num1 greater num2fi\n\n执行：\n➜  note git:(master) ✗ sh -x /Users/fanhaodong/Desktop/project/test.sh+ num1=10+ num2=20+ (( 10 &lt;= 20 ))+ echo num1 lesser equal num2num1 lesser equal num2\n\n2、-c 命令 （执行命令参数）➜  note git:(master) ✗ sh -c &lt;&lt; EOF &quot;dquote&gt; echo hello worlddquote&gt; echo hello world2dquote&gt; &quot;heredoc&gt; EOFhello worldhello world2\n\n\n这种经常会在网上下载一个脚本然后直接执行，可以 sh -c &quot;curl xxxx.sh&quot;\n\n3、使用set变量一般就是 set -ex ，或者执行的时候 bash -ex\n#!/bin/sh# -v  Print shell input lines as they are read.# -x  Print commands and their arguments as they are executed.# -e  Exit immediately if a command exits with a non-zero status.set -execho &quot;hello world&quot;exit 1\n\n执行\n➜  makefile git:(master) ✗ sh ./main.sh+ echo &#x27;hello world&#x27;hello world+ exit 1➜  makefile git:(master) ✗ echo $?     1\n\n帮助可以看： sh -c &quot;help set&quot;\n2、语法小技巧1、引用变量一般推荐正确用法是，变量使用 &quot;&quot; 双引号引用，其次就是变量使用 $&#123;&#125;进行引用！very good！\n# 使用 $&#123;&#125; 引用变量，拒绝歧义➜  ~ data=&quot;hello&quot; ;echo $dataa➜  ~ data=&quot;hello&quot; ;echo $&#123;data&#125;ahelloa# 字符串用 &quot;&quot; 引用➜  ~ data=&quot;hello &quot; ;echo &quot;$&#123;data&#125;a&quot;hello a➜  ~ data=hello  ;echo &quot;$&#123;data&#125;a&quot;helloa# 单引号不会进行变量赋值 (注意)➜  ~ data=hello  ;echo &#x27;$&#123;data&#125;a&#x27;$&#123;data&#125;a\n\n2、 $( cmd ) 和 `cmd`  执行命令➜  ~ echo $(uname)Darwin➜  ~ echo `uname`Darwin\n\n3、 cat [&gt;&gt;|&gt;] [file] &lt;&lt; EOF  .... EOF 写入文件\n如果重定向的操作符是&lt;&lt;-，那么分界符（EOF）所在行的开头部分的制表符（Tab）都将被去除。这可以解决由于脚本中的自然缩进产生的制表符。\n\n➜  test cat &gt; glide.yaml &lt;&lt; EOFheredoc&gt; name: tomheredoc&gt; age: 10heredoc&gt; hobby:heredoc&gt; - footballheredoc&gt; EOF➜  test cat glide.yamlname: tomage: 10hobby:- football\n\n4、管道符 和 xargs1. 管道符管道符作用就是把上一个命令的标准输出作为下一个命令个标准输入\n➜  echo &quot;hello wrold&quot; | python -c &#x27;import sys; print(sys.stdin.read())&#x27;hello wrold\n\n2. xargs1 .xargs的作用就是把上个命令的标准输出  作为 下一个命令的参数 \n➜  echo &quot;hello wrold&quot; | xargs python -c &#x27;import sys; print(sys.argv)&#x27;[&#x27;-c&#x27;, &#x27;hello&#x27;, &#x27;wrold&#x27;]\n\n\n如果想替换分隔符号需要输入参数 -d, 同时你想打印所执行的命令 -t\n\n➜  ~ echo &quot;hello:wrold&quot; | xargs -t -d &#x27;:&#x27; python -c &#x27;import sys; print(sys.argv)&#x27;python -c &#x27;import sys; print(sys.argv)&#x27; hello &#x27;wrold&#x27;$&#x27;\\n&#x27;[&#x27;-c&#x27;, &#x27;hello&#x27;, &#x27;wrold\\n&#x27;]# 上面带\\n的原因是echo默认换行，需要➜  ~ echo -e &quot;hello:wrold\\c&quot; | xargs -d &#x27;:&#x27; python -c &#x27;import sys; print(sys.argv)&#x27;[&#x27;-c&#x27;, &#x27;hello&#x27;, &#x27;wrold&#x27;]\n\n\nxargs 是并行执行的，可以通过如下测试**, -P等于0表示不限制进程数**，默认是1， -n等于1表示参数按每一个进行拆分\n\n\n​    这个命令相当棒，就是可以并行执行！\n\n➜  echo &quot;hello world&quot; | xargs -P0 -n1  sh -c &#x27;echo &quot;start $$&quot;; sleep 5s; echo &quot;end $$&quot;&#x27;start 21377start 21378end 21377end 21378\n\n\n-I，可以替换命令行参数\n\n➜  ~ echo &quot;hello wrold&quot; | xargs echohello wrold➜  ~ echo &quot;hello wrold&quot; | xargs -I &#123;&#125;  echo &#123;&#125;hello wrold\n\n5、特殊变量\n$0: 当前脚本的文件名\n$n : 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。\n$#: 传递给脚本或函数的参数个数。\n$*: 传递给脚本或函数的所有参数。\n$@: **传递给脚本或函数的所有参数(推荐使用这个)**，当使用 &quot;&quot; 双引号引用是 $*会变成字符串而不是数组\n$?: 上个命令的退出状态，或函数的返回值。一般情况下，大部分命令执行成功会返回 0，失败返回 1。\n$$: 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n6、[[]] 和 [] 标准 以及基本语法规范具体规范： https://github.com/koalaman/shellcheck/wiki/SC2039\n#!/bin/shname=&quot;&quot;if [[ -z $name ]]; then    echo &quot;is zero&quot;fi\n\n执行后发现\n\n7、/bin/sh 与 /bin/bash 的区别/bin/sh 与 /bin/bash 的区别\n3、获取命令结果 $(cmd)有两种写法，一种是 $()这个并不是所有的shell都支持，但是比较直观， 另外一种是   &quot;``&quot;   （它可是适用更多的平台）\n#!/bin/shecho `ls -a /Users/fanhaodong/note`echo $(ls -a /Users/fanhaodong/note)\n\n输出：\n. .. .DS_Store 1714.jpg docker-rocketmq-cluster gridea-home hexo-home note pdf vuepress-starter. .. .DS_Store 1714.jpg docker-rocketmq-cluster gridea-home hexo-home note pdf vuepress-starter\n\n4、输入输出重定向 2&gt;&amp;1使用程序中经常有，标准输出，但是还有错误输出，因此需要合并到一个流中\n其实Go的程序中正执行脚本的时候可以指定，标准输出和错误输出\ncommand := exec.Command(shell, &quot;-c&quot;, cmd)command.Stdout = os.Stdoutcommand.Stderr = os.Stderr\n\n使用的时候：\n\n默认为标准输出重定向，与 1&gt; 相同\n2&gt;&amp;1  意思是把 标准错误输出 重定向到 标准输出.\n&amp;&gt;file  意思是把标准输出和标准错误输出 都重定向到文件file中\n\n例如：\ncommand &gt;out.file  2&gt;&amp;1 &amp;\ncommand &gt;out.file是将command的标准输出重定向到out.file文件，即输出内容不打印到屏幕上，而是输出到out.file文件中。2&gt;&amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了out.file文件，即将标准出错也输出到out.file文件中。最后一个&amp; ，是让该命令在后台执行。\n参考https://www.cnblogs.com/caolisong/archive/2007/04/25/726896.html\n5、If语句\n​    if 其实就是test 命令\n\n1、格式\n换行写\n\nif [ condition ]; then     # bodyelif [ condition ]; then     # bodyelse     # bodyfi\n\n2）非换行写\nif [ -f &quot;/Users/fanhaodong/note/note/Makefile1&quot; ]; then  echo 111 ; echo 222 ;elif [ -f &quot;/Users/fanhaodong/note/note/README.md&quot; ]; then  echo 333 ; echo 4444 ; else  echo 555 ; echo 666 ; fi\n\n2、结果获取/判断结果输出0 ，表示为真，可以通过$? 来获取结果\n3、例如调试条件➜  note git:(master) ✗ test &quot;abc&quot;!=&quot;def&quot;➜  note git:(master) ✗ echo $?0\n\n4、测试文件是否存在\n如果你要判断一个文件是否存在，只需要 -e 即可，输出0 表示文件存在 （不在判断类型的时候推荐使用这个）\n如果你要判断一个文件是否为文件夹，并且判断是否存在，只需要 -d 即可\n如果你要判断一个文件是否为常规文件 ，并且判断是否存在，只需要-f 即可\n-L filename 如果 filename为符号链接，则为真\n\n[root@019066c0cd63 ~]# ls -allrwxrwxrwx 1 root root    5 Mar  1 09:49 c.txt -&gt; a.txt[root@019066c0cd63 ~]# [ -L &quot;./c.txt&quot; ][root@019066c0cd63 ~]# echo $?0\n\n\n-r filename 如果 filename可读，则为真 \n-w filename 如果 filename可写，则为真 \n-x filename 如果 filename可执行，则为真\n-s filename 如果文件长度不为0，则为真\n-h filename 如果文件是软链接，则为真\n\n➜  note git:(master) ✗ [ -f &quot;/Users/fanhaodong/note/note/Makefile&quot; ]➜  note git:(master) ✗ echo $?0➜  note git:(master) ✗ [ -f &quot;/Users/fanhaodong/note/note/Makefile1&quot; ]➜  note git:(master) ✗ echo $?1\n\n5、字符串操作\n​    字符串推荐加 &quot;&quot; 进行定义\n\n\n判断字符串是否为空 -z (zero)么\n\n#!/bin/shstr=&quot;&quot;if [ -z &quot;$&#123;str&#125;&quot; ]; then    echo str is emptyfi# str is empty\n\n2）判断两个字符串是否相同\n#!/bin/shstr1=&quot;str&quot;str2=&quot;str2&quot;if [ &quot;$str1&quot; = &quot;$str2&quot; ]; then    echo str1 is equal str2else    echo str1 is not equal str2fi# str1 is not equal str2\n\n4、测试一个命令是否存在 command -v $#\n#!/bin/shcmd=goif [ `command -v $cmd` ]; then   echo $cmd command is exists else    echo $cmd command not exists fi# go command is exists\n\n5、获取字符串长度 $&#123;#var&#125;\n#!/bin/shstr=&quot;hello   &quot;  str1=helloecho str 的长度是 $&#123;#str&#125;echo str1 的长度是 $&#123;#str1&#125;#str 的长度是 8#str1 的长度是 5\n\n6、数字比较\n-eq 等于\n-ne 不等于\n-gt 大于\n-ge 大于等于\n-lt 小于\n-le 小于等于\n\n#!/bin/shnum1=10num2=20if (($num1 &lt;= $num2)); then    echo num1 lesser equal num2fiif [ $num1 -le $num2 ]; then    echo num1 lesser equal num2fi# num1 lesser equal num2# num1 lesser equal num2\n\n7、shell脚本中if判断’-a’ - ‘-z’含义https://blog.csdn.net/tootsy_you/article/details/95597376\n\n\n\n6、for循环1、for &lt;item&gt; in &lt;items&gt; ; do &lt;script1&gt;; &lt;script2&gt;;done#!/bin/bashfor item in &#123;1..5&#125;; do echo &quot;$item&quot;; done[Running] /bin/bash &quot;/Users/fanhaodong/note/note/Linux/shell/file.sh&quot;12345\n\n2、for((x=0; x&lt;10; x++));do &lt;script1&gt;; &lt;script2&gt;; donefor((x=0; x&lt;10; x++));do echo &quot;$x&quot; ;done\n\n","categories":["Linux"],"tags":["shell"]},{"title":"grep、awk、sed、正则表达式 开发必备分享","url":"/2022/03/12/c9cb8912930fdc26498e1bf5b085fabf/","content":"grep、awk命令主要是用于我们日常开发中日志检索，问题就是有同学可能会咨询不是有elk、企业内部日志收集过滤系统，那么我为啥要学这些东西！日志收集在系统不稳定的情况下是很容易丢失日志的或者你做一些高精度的过滤日志也不符合，比如我要查看一下latency&gt;10s的接口，你日志咋搜！！所以还是有学习必要性的！\n正则表达式如果你业务中处理文本的需求比较多的话，正则表达式的作用不容小觑，而且正则表达式庞大的知识体系也需要经常练习才可以！\n\n\n1、grep1. 基础概念grep全名叫Global regular expression print, wiki: https://zh.wikipedia.org/zh-tw/Grep，其实就是一个全局的正则表达式过滤然后打印！\n2. 日常使用grep 是我们日常最常见和使用的命令了，主要是做正则匹配做日志过滤！\n这里主要介绍一下常用的命令和技巧吧\ngrep [-abcdDEFGHhIiJLlMmnOopqRSsUVvwXxZz] [-A num] [-B num] [-C[num]]     [-e pattern] [-f file] [--binary-files=value] [--color[=when]]     [--colour[=when]] [--context[=num]] [--label] [--line-buffered]     [--null] [pattern] [file ...]\n\n简单匹配就是 cat biz.log | grep &#39;Error&#39; 过滤所有包含Error的行\n\n-i 可以忽略大小写，比如上面的grep -i error 它可以匹配 error和Error 等！\n-v 取反，比如说grep -v &#39;error&#39;，那么他就可以取info、debug、warn的日志了\n--colour=auto|always|never，一般设置为 --colour=always 就可以高亮展示了！\n-E 是高级正则，比如一些高级的正则 . 或则\\w ，\\d 等，就需要了\n-F为fgrep 其实就是--fixed-strings 本质上就是对于正则表达式不进行转义，比如\n\n\n3. 总结所以一般你是精确字符匹配的话，推荐用 grep -F 或者fgrep , 如果你用的是正则匹配的话推荐用egrep和grep -E , 具体差异可以下我下面正则表达式那个章节！\n4. 参考文章\nGNU grep 介绍\n\n2、awk\nawk 是三个大佬写的一门语言，说是一门语言其实不足为过！因为确实贼厉害！\n\n1. 基础概念介绍awk 整体格式就是有一组的 pattern-action组成，不过也有可能只有action，但是必须要知道这一点很重要！！\n备注: 下列例子可能用到 out.log文件，文件内容如下: \nDan     3.75    0Kathy   4.00    10Mark    5.00    20Mary    5.50    22Susie   4.25    18\n\n\n简单过滤模式 （pattern-action）\n\nawk &#x27;$3&gt;0 &#123;print&#125;&#x27;  # pattern 就是 $3&gt;0 ， &#123;print&#125; 表示行为， 如果不指定 pattern 那么表示无过滤条件，# 换成其他语言就是for x:=0; x&lt;len; x++&#123;\t\tif (pattern) &#123;\t\t\t\taction()\t\t&#125;&#125;\n\n\n(action1) (action2) 模式\n\nawk &#x27;&#123;print&#125; &#123;print&#125;&#x27; # 转换后for x:=0; x&lt; len; x++&#123;\t\taction1()\t\taction2()&#125;\n\n\n内置pattern模式, pattern=BEGIN / END\n\n# pattern=END，表示结束awk &#x27;END &#123;print&#125;&#x27; # 换成其他语言就是for x:=0; x&lt;len; x++&#123;&#125;action()# pattern=BEGIN，表示开始awk &#x27;BEGIN &#123;print&#125;&#x27; # 换成其他语言就是action()for x:=0; x&lt;len; x++&#123;&#125;\n\n\n输出函数\n\nawk &#x27;&#123;print 1, $1; print 2, $1&#125;&#x27;awk &#x27;&#123;print 1, $1&#125; &#123;print 2,$1&#125;&#x27; awk &#x27;&#123;printf &quot;1 %s\\n&quot;, $1; printf &quot;2 %s\\n&quot;, $1&#125;&#x27;...# 上诉例子输出其实是一样的！\n\n\nif / else  \n\n\n前面虽然说了 pattern可以支持条件过滤，但是太过于简单！不支持else语句\n\n➜  yulili cat out.log | awk &#x27;&#123;if ($3&gt;0) printf &quot;%s-%d gt 0\\n&quot;, $1, $3; else printf &quot;%s-%d eq 0\\n&quot;, $1,$3&#125;&#x27;Beth-0 eq 0Dan-0 eq 0Kathy-10 gt 0Mark-20 gt 0Mary-22 gt 0Susie-18 gt 0\n\n\nfor 循环 ，一般会在END语句中执行！\n\n➜  yulili cat out.log | awk &#x27;END &#123; for (x=1; x&lt;NR; x++) printf &quot;row %d\\n&quot;, x&#125;&#x27;row 1row 2row 3row 4row 5\n\n\n数组/map， 可以通过 var[index]=value或者var[key]=value  进行定义！同时可以通过 in进行判断是否存在\n\n# 简单的便利循环➜  yulili cat out.log | awk &#x27;&#123;line[NR]=$0&#125; END &#123; for (x=1; x&lt;NR; x++) printf &quot;row: %s\\n&quot;, line[x]&#125;&#x27;row: Beth    4.00    0row: Dan     3.75    0row: Kathy   4.00    10row: Mark    5.00    20row: Mary    5.50    22# 判断是否存在➜  yulili cat out.log | awk &#x27;&#123;line[NR]=$0&#125;  END &#123;if (1 in line) print &quot;1 in line&quot;&#125; END &#123;if (0 in line) print &quot;0 in line&quot;&#125;&#x27;1 in line\n\n\n正则匹配\n\n# 例如输出M开头的用户信息➜  yulili cat out.log| awk &#x27;$1 ~ &quot;^M&quot; &#123;print&#125;&#x27;Mark    5.00    20Mary    5.50    22# 例如输出非M开头的用户信息➜  yulili cat out.log| awk &#x27;$1 !~ &quot;^M&quot; &#123;print&#125;&#x27;Beth    4.00    0Dan     3.75    0Kathy   4.00    10Susie   4.25    18\n\n\n内置变量\n\n\n\n\n内置变量\n含义\n\n\n\nNR（numeric row）\n表示总行数，已经阅读的行数， BEGIN=0，END=total\n\n\nNF（number field）\n表示没行的列数，BEGIN=0， END=pre_row_column\n\n\nFS (field separator)\n输入的分隔符，默认应该是 &quot; &quot;\n\n\nOFS(out field separator)\n输出的分隔符，默认是&quot; &quot;\n\n\n$0…n\n变量，$0表示整个列，$1表示第一列，注意变量是可以被修改！\n\n\n\n\n\n\n\n例如我修改FS和OFS， FS为空格，输出的OFS是,\n\n➜  yulili cat out.log | awk &#x27;BEGIN &#123; FS=&quot; &quot;; OFS=&quot;,&quot;&#125; &#123;print $1 ,$2 ,$3&#125;&#x27;Beth,4.00,0Dan,3.75,0Kathy,4.00,10Mark,5.00,20Mary,5.50,22Susie,4.25,18\n\n\n内置函数\n\n\n\n\n内置函数\n含义\n\n\n\nprint\n换行输出, eg:  awk &#39;&#123;print $1, $2, $3; print $1, $2&#125;&#39;\n\n\nprintf\nformat输出, eg:  awk &#39;&#123;printf &quot;第一列: %d&quot;, $1&#125;&#39;\n\n\nlength(s)\ns为字符串，输出字符串长度\n\n\nsubstr(s,p)\ns为字符串，p为index，输出从index后截取的字符串\n\n\ngsub(r,s,t)\n将字符串t中的 r 替换为s， 输出字符串\n\n\nstrtonum(s)\ns为字符串，输出为numeric\n\n\nrand()\n输出一个随机数\n\n\nint(x)\n输出x的整数部分\n\n\n\n例如我们使用gsub函数替换，这里可能注意可以正则替换\n\n➜  yulili cat out.log| awk &#x27;&#123;gsub(&quot;\\\\.&quot;,&quot;0&quot;,$2)&#125;&#123;print $2&#125;&#x27;400030754000500050504025\n\n2. 简单例子介绍\n查询工时大于0的记录\n\n➜  yulili cat out.log | awk &#x27;$3&gt;0 &#123;print&#125;&#x27;Kathy   4.00    10Mark    5.00    20Mary    5.50    22Susie   4.25    18\n\n\n查询工时大于0的人员数量 ， 业务中比较适合过滤 latency &gt; xxxms的数量！\n\n➜  yulili cat out.log | awk &#x27;$3&gt;0 &#123;emp=emp+1&#125; END &#123;printf &quot;total emp: %d\\n&quot;, emp&#125;&#x27;total emp: 4\n\n\n查询平均工资 (工时*工时费用/ 人员) ， 其实吧业务中比较适合求avg-latency\n\n➜  yulili cat out.log | awk &#x27;&#123; salary = salary + $2*$3 &#125; END &#123; printf &quot;avg salary: %d\\n&quot;, salary / NR &#125;&#x27;avg salary: 56\n\n3. 使用技巧技巧\n比如经常出现我们要检查 latency &gt; xxx 的access_log ，怎么解决了，由于我们日志中 latency是这么记录的cost=251045，那么我们在过滤的时候需要字符串操作，这时候需要substr(str, index) 函数取出来lantency，然后取出来实际上是字符串类型，那么此时需要通过+0来转换为int！！ 或者通过函数 strtonum进行转换， 下面例子是取出大于200ms的日志的logid\n\n# cat access.log | awk &#x27;strtonum(substr($11,6)) &gt; 200000 &#123;print $6 ,$11, substr($11,6)&#125;&#x27;# cat access.log | awk &#x27;substr($11,6)+0 &gt; 200000 &#123;print $6 ,$11, substr($11,6)&#125;&#x27;20220312000212010212043169032F1158 cost=358144 35814420220312000442010150139043227E02C8 cost=251045 25104520220312002645010150132075097C7676 cost=532952 5329522022031200293601021009615805605CF5 cost=256238 25623820220312002943010211182012276F60AD cost=298612 2986122022031200295801021009615805606647 cost=213975 21397520220312003410010150135045168607FA cost=366926 366926202203120037310101501390291691A893 cost=4882332 4882332202203120039100101501322000F82B0D0 cost=276756 276756\n\n\n文本处理，例如以下文本\n\na,b,cd1,c1,a1d2\n\n需求是需要按, 分割，且要拼接字符串！如 a,b,c 需要输出 t1.a=t2.a and t1.b=t2.b and t1.c=t2.c ， 可以下面这么写！\ncat text.txt| awk &#x27;BEGIN &#123; FS=&quot;,&quot; &#125;$0 ~ /\\S/ &#123;        sql=&quot;&quot;        for (x=1;x&lt;=NF;x++) &#123;                if ( x != NF )&#123;                        sql= sprintf (&quot;%s a.%s=b.%s and&quot;,sql, $x, $x)                &#125;else&#123;                        sql= sprintf (&quot;%s a.%s=b.%s&quot;, sql, $x, $x)                &#125;        &#125;        sqls[NR]=sql&#125;END &#123;        for (x=1;x&lt;=NR;x++)&#123;                if ( x in sqls) &#123;                        printf &quot;sql: %s\\n&quot;, sqls[x] #  todo 拼接sql                &#125;        &#125;&#125;&#x27;\n\n4. 参考文章\nawk 简单介绍\n推荐: awk中文文档\n\n3、sed1. 基础学习sed全名叫stream editor，流编辑器，用程序的方式来编辑文本。sed基本上就是玩正则模式匹配，所以，玩sed的人，正则表达式一般都比较强。其次就是gun的sed函数和mac的sed是有些不同的，mac上玩sed推荐用gsed！\n这里我就介绍一些简单的用法，比如我们经常进行的批量替换比如把代码中某个变量名替换为另一个变量名，或者配置文件之类的，或者进行简单的文本操作！\n\n替换，用法就是 sed  &#39;s/a/b/g&#39; file , 意思就是把a替换为b，全局替换\n\n\ns: substitute\n\n➜  docs cat test.logaaaaaabbbbbbaaaaaacccccc# 把a替换成b，每行第一个➜  docs cat test.log| sed &#x27;s/a/b/&#x27;baaaaabbbbbbbaaaaacccccc# 最后加一个g表示global的意思，表示每行全局替换！➜  docs cat test.log| sed &#x27;s/a/b/g&#x27;bbbbbbbbbbbbbbbbbbcccccc# 表示从第三个字符开始替换➜  docs cat test.log| sed &#x27;s/a/b/3g&#x27;aabbbbbbbbbbaabbbbcccccc# s 可以通过[start,end]来修饰行数，比如 1-3行可以 1,3s， 比如1行可以1s，末尾行可以 $s, 比如2-最后一行可以用2,$表示➜  docs cat test.log| sed &#x27;1,3s/a/b/g&#x27;bbbbbbbbbbbbbbbbbbcccccc# 只替换第一行➜  docs cat test.log| sed &#x27;1s/a/b/g&#x27;bbbbbbbbbbbbaaaaaacccccc# 只替换最后一行➜  docs cat test.log| sed &#x27;$s/c/a/g&#x27;aaaaaabbbbbbaaaaaaaaaaaa\n\n注意：如果你要使用单引号，那么你没办法通过\\这样来转义，就有双引号就可以了，在双引号内可以用\\”来转义。\n\n正则替换，但是一般推荐使用正则直接携带 -E参数，注意会有一些转义字符，需要通过\\来处理\n\n➜  docs cat test.log| sed  -E &#x27;2,$s/\\w/a/g&#x27;aaaaaaaaaaaaaaaaaaaaaaaa\n\n\n添加/插入/删除/替换文本， sed &#39;a1 文本&#39;也就是在第一行后面添加文本，sed &#39;i1 文本&#39;含义就是在第一行插入文本\n\n\na: append\ni: insert\nd: delete\n\n# 在第一行后面添加zzzzzz➜  docs cat test.log | sed &#x27;1a zzzzzz&#x27;aaaaaazzzzzzbbbbbbaaaaaacccccc# 在最后一行添加`zzzzzz`➜  docs cat test.log | sed &#x27;$a zzzzzz&#x27;aaaaaabbbbbbaaaaaacccccczzzzzz# 第一行插入 `zzzzzz`➜  docs cat test.log | sed &#x27;1i zzzzzz&#x27;zzzzzzaaaaaabbbbbbaaaaaacccccc# 删除第一行和最后一行！➜  docs cat test.log | sed &#x27;1d;$d&#x27;bbbbbbaaaaaa\n\n\n截取文本 \n\n# 选择第2-3行文本，注意这里必须加-n参数，否则会重复打印➜  docs cat test.log| sed  -n &#x27;2,3p&#x27;bbbbbbaaaaaa# 打印➜  docs cat test.log| sed  -n &#x27;/b/p&#x27;bbbbbb# 打印b或者c的文本➜  docs cat test.log| sed  -n &#x27;/\\(\\(b\\|c\\)\\)/p&#x27;bbbbbbcccccc\n\n2. 总结\n命令通用格式 [addr]/[regexp]/[flags] 或者 [addr]/[regexp]/[replace content]/[false] \n多个命令可以通过 ;进行分割\n 2addr表示可以通过 1,2进行选择行操作\n1addr只支持1或者$或者 ….\nsed -i 是直接替换原文本！所以不推荐这么使用，可以用重定向符号进行操作！\nsed -E 表示使用拓展正则！如果你使用正则则推荐使用这个！\nmac 上推荐使用gsed命令！\n\n\n\n\n命令\n备注\n\n\n\n[2addr]s/regular expression/replacement/flags\n把regular expression替换成replacement\n\n\nw file\n写入到file中\n\n\nr file\n读取文件\n\n\n[2addr]x\n清空某行 1x表示清空第一行， Swap the contents of the pattern and hold spaces.\n\n\n[1addr]a text\napped text\n\n\n[1addr]i  text\ninsert text\n\n\n[2addr] d\ndelete 指定行\n\n\n/regexp/d\n删除匹配行\n\n\n-n &#39;[2addr]p&#39;\nprint 打印指定行\n\n\n-n /regexp/p\n打印匹配行\n\n\n3. 参考文章\nGNU sed 文档\nsed 简明教程\n\n4、Dash如果你用的是mac作为你的开发环境，我推荐你使用dash进行命令或者代码库检索！比较好用，因为平时比如我们经常遇到写代码忘记api的，可以通过dash进行搜索！\n不过Linux的GNU命令都会携带帮助的！看个人喜好吧！\n\n5、 正则表达式其实不难发现，只要文本处理就离不开 正则表达式  (Regular Expression) ，可能有些同学会说 通配符（wildcard），确实通配符可以解决一部分问题，但是还是有些时候还是正则更加强大和灵活，其实通配符是正则表达式的前身，出生更早!\n1. 通配符\n* 匹配零个或多个字符 （有点像数据库的通配符*）\n\n? 匹配任意一个字符（有点像数据库的通配符_）\n\n[char_list]  匹配char_list中任意单个字符\n\n[^char_list] or [!char_list] 排除 char_list中任意一个字符\n\n\n➜  test_file ls *.filea.file  ab.file  c.file  cd.file➜  test_file ls -a./  ../  a.file  ab.file  c.file  cd.file➜  test_file ls *.filea.file  ab.file  c.file  cd.file➜  test_file ls [a].filea.file➜  test_file ls [a]?.fileab.file➜  test_file ls [a]*.filea.file  ab.file➜  test_file ls [ac]*.filea.file  ab.file  c.file  cd.file➜  test_file ls [^a].filec.file➜  test_file ls [^a]*.filec.file  cd.file\n\n\n&#123;xxx1,xxx2,xxx3&#125;  只能是 xxx1 or xxx2 or xxx3 , 模式, 这个比较常见主要用作创建文件ls文件\n\n➜  test_file ls &#123;a,ab&#125;.filea.file  ab.file➜  test_file ls &#123;a,c&#125;*.filea.file  ab.file  c.file  cd.file➜  test_file touch d&#123;a,b,c,d&#125;.file➜  test_file ls d&#123;a,b,c,d&#125;.fileda.file  db.file  dc.file  dd.file\n\n\n &#123;start..end&#125; 表示匹配 start-&gt;end 中的字符， 比较适合for循环！！其中支持数字和字母\n\n➜  test_file for x in &#123;1..10&#125;; do echo &quot;num: $&#123;x&#125;&quot;; donenum: 1num: 2num: 3num: 4num: 5num: 6num: 7num: 8num: 9num: 10\n\n最后介绍下 通配符执行原理，通配符顾名思义就是执行的实现先进行解释，也就是比如 ls *.file 先解析成ls a.file 再执行 ls a.file， 假如没有匹配会导致报错或者程序不符合预期\n2. 正则表达式一 (基础)基础感觉不用说，可以看下 https://github.com/Anthony-Dong/learn-regex-zh  , 想必看这篇文章的人正则基本都还是可以的！ 这里推荐一个正则表达式的可视化网站 https://regexper.com/\n\n元字符，这类字符会有特殊含义，所以如果你正则中想要不表示特殊含义就需要转义了！ 以下列表 POSIX Extended 和 Perl 全部支持 ！POSIX 部分不支持！\n\n\n\n\n元字符\n描述\n\n\n\n.\n匹配除换行符以外的任意字符。\n\n\n[ ]\n字符类，匹配方括号中包含的任意字符。\n\n\n[^ ]\n否定字符类。匹配方括号中不包含的任意字符\n\n\n*\n匹配前面的子表达式零次或多次\n\n\n+\n匹配前面的子表达式一次或多次\n\n\n?\n匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。\n\n\n{n,m}\n花括号，匹配前面字符至少 n 次，但是不超过 m 次。\n\n\n(xyz)\n字符组，按照确切的顺序匹配字符 xyz。\n\n\n|\n分支结构，匹配符号之前的字符或后面的字符。\n\n\n\\\n转义符，它可以还原元字符原来的含义，允许你匹配保留字符 `[ ] ( ) { } . * + ? ^ $ \\\n\n\n^\n匹配行的开始\n\n\n$\n匹配行的结束\n\n\n\n简写字符集，这个比较常用，因为确实这类简写字符集很方便，省代码！ 以下只要 Perl 全部支持，POSIX 支持不友好！\n\n\n\n\n简写\n描述\n\n\n\n.\n匹配除换行符以外的任意字符\n\n\n\\w\n匹配所有字母和数字的字符：[a-zA-Z0-9_]\n\n\n\\W\n匹配非字母和数字的字符：[^\\w]\n\n\n\\d\n匹配数字：[0-9]\n\n\n\\D\n匹配非数字：[^\\d]\n\n\n\\s\n匹配空格符：[\\t\\n\\f\\r\\p&#123;Z&#125;]\n\n\n\\S\n匹配非空格符：[^\\s]\n\n\n3. 正则表达式二 (分组)说实话，业务中我遇到分组的情况也不少，但是大多数人也基本不会用，也就是写个基础正则罢了！分组作用就是将正则分为多个组，然后我们可以取每个组内部的东西！举个例子，比如我要匹配一个文本 2020年 01月 02日 ，我要第一匹配，第二取出来年月日！\nimport (\t&quot;regexp&quot;\t&quot;testing&quot;\t&quot;github.com/anthony-dong/go-sdk/commons&quot;\t&quot;github.com/stretchr/testify/assert&quot;)func TestMatch(t *testing.T) &#123;\tre := regexp.MustCompile(`^\\d+年\\s*\\d&#123;1,2&#125;月\\s*\\d&#123;1,2&#125;日$`)\tassert.Equal(t, re.MatchString(&quot;2020年 01月 02日&quot;), true)\tassert.Equal(t, re.MatchString(&quot;2020年01月02日&quot;), true)\tassert.Equal(t, re.MatchString(&quot;2020年\t01月\t02日&quot;), true)\tassert.Equal(t, re.MatchString(&quot;01月02日&quot;), false)&#125;func TestGroup(t *testing.T) &#123;\tre := regexp.MustCompile(`^(\\d+)年\\s*(\\d&#123;1,2&#125;)月\\s*(\\d&#123;1,2&#125;)日$`)\tresult := re.FindStringSubmatch(&quot;2020年 01月 02日&quot;)\tt.Logf(&quot;%#v\\n&quot;, result)\tassert.Equal(t, len(result), 4)\tt.Logf(&quot;年: %s, 月 %s, 日: %s\\n&quot;, result[1], result[2], result[3])&#125;// output://    regexp_test.go:22: []string&#123;&quot;2020年 01月 02日&quot;, &quot;2020&quot;, &quot;01&quot;, &quot;02&quot;&#125;//    regexp_test.go:24: 年: 2020, 月 01, 日: 02func TestNameGroup(t *testing.T) &#123;\tre := regexp.MustCompile(`^(?P&lt;year&gt;\\d+)年\\s*(?P&lt;month&gt;\\d&#123;1,2&#125;)月\\s*(?P&lt;day&gt;\\d&#123;1,2&#125;)日$`)\tresult := re.FindStringSubmatch(&quot;2020年 01月 02日&quot;)\tnames := re.SubexpNames()\tfor _, elem := range names &#123;\t\tt.Logf(&quot;sub exp name: %s\\n&quot;, elem)\t&#125;\tmapData := make(map[string]string)\tfor index, elem := range names &#123;\t\tif index == 0 &#123;\t\t\tcontinue\t\t&#125;\t\tmapData[elem] = result[index]\t&#125;\tt.Logf(&quot;%s\\n&quot;, commons.ToJsonString(mapData))&#125;// output://    regexp_test.go:35: sub exp name: //    regexp_test.go:35: sub exp name: year//    regexp_test.go:35: sub exp name: month//    regexp_test.go:35: sub exp name: day//    regexp_test.go:44: &#123;&quot;day&quot;:&quot;02&quot;,&quot;month&quot;:&quot;01&quot;,&quot;year&quot;:&quot;2020&quot;&#125;\n\n不过Go语言也提供了一些高阶用法，这里根据需求进行使用！\n# re 表示正则表达式(re)  最简单的分组使用法，通过index获取(?P&lt;name&gt;re)  可以对分组进行命名(?:re)  \t不会对当前分组进行捕获(?flags)\t设置当前所在分组的标志，不捕获也不匹配\n\n4. 正则表达式标准分类正则表达式也是经历了不断的发展，目前日趋完善，目前主流计算机高级语言都是使用的perl标准，未来perl也会成为正则表达式的标准（不过目前就是）！但是说是标准但是毕竟还是有些工具仍然使用POSIX！ 所以我们讲一下区别！\n\nPOSIX  or BRE( Basic Regular Expression)\nPOSIX Extended  or  ERE (Extended Regular Express)\nPerl or   PCRE (Perl Compatible Regular Expression)\n\n\n目前常见的grep 就是用的  POSIX 标准，而 grep -E 或者 egrep 就是用的 POSIX Extended 标准了！像linux命令目前基本上都是走的POSIX 标准，有些可能会拓展POSIX Extended ！\n\n\n\n主要区别就是转义字符的区别了， 像POSIX 的转义字符有 .、\\、[、^、$、* ， 但是 POSIX Extended  多了7个需要转义的字符 (、)、&#123;、&#125;、+、?、|    其实说白了就是不支持 字符组和花括号还有 +和? !\n\n\n\n\n\nPerl 和 POSIX主要区别也很简单,  就是不支持简写字符集！但是Go语言好像是POSIX完全不允许简写字符集！所以假如我们使用POSIX还是不用简写字符集吧！\n\nfunc TestPOSIX(t *testing.T) &#123;\t// 这里不允许使用 perl 的 `\\d` 之类的....\tassert.Equal(t, regexp.MustCompilePOSIX(`^[0-9]+`).MatchString(&quot;123abc&quot;), true)\t// panic\tassert.Equal(t, assert.Panics(t, func() &#123;\t\tregexp.MustCompilePOSIX(`^[\\d]+`).MatchString(&quot;123abc&quot;)\t&#125;), true)&#125;func TestPerl(t *testing.T) &#123;\tassert.Equal(t, regexp.MustCompile(`^[\\d]+`).MatchString(&quot;123abc&quot;), true)&#125;\n\n5. 总结​    总结一些，假如我们现在要写一个正则，那么需要确定是否使用Perl，如果不是那么我们需要确认是否支持 POSIX Extended ！然后就是我们别用简写字符集就行了！\n还有断言我没有讲到，所以这里就偷懒了！后续补充！日常中确实没用到断言！\n6. 参考文章\n正则表达式学习\n\nBRE和ERE区别\n\nGo语言标准库 regexp 学习\n\n\n","categories":["Linux"],"tags":["Linux","grep","awk","sed","正则表达式"]},{"title":"Elasticsearch 基础、概念、原理学习","url":"/2021/03/17/cacf73d580b314c8a4c95660b46a7178/","content":"​    es作为 db、搜索、alap以及成熟的社区，已经越来越成为后端比较成熟的技术栈了，业务中由于需要大量聚合操作，来弥补传统关系型数据(My-SQL)的性能不足，行数据库的劣势，往往会以es作为辅助的存储工具，因此深入学习es基本概念，原理对于日常开发有很大的帮助！对于SQL-Body来说，es支持SQL语法，还是相当给力的！\n​    由于我们公司es集群基本使用的是 6.8.8版本，所以全部学习资料基于这个版本学习！\n\n\n1、官方文档6.8版本的官方文档，推荐大家学习的时候详细阅读一下！！ ， 中文版可能只有2.x版本的！\n2、docker安装ES环境\n​    这里不去做集群节点，本文只是做练习，所以不去搭建那么多节点！(docker是个好工具，对于本地学习软件)\n\n# 创建bridge网络docker network create elasticsearch# 创建es(signle-node)docker run -d  --rm --name elasticsearch -p 9200:9200 -p 9300:9300 --network elasticsearch -e &quot;discovery.type=single-node&quot; elasticsearch:6.8.8# 创建kibana(web-console)docker run -d --rm --name kibana -p 5601:5601 --network elasticsearch  kibana:6.8.8\n\n3、相关概念1、索引\n​    elastic-search 的基本概念： 索引(index) -&gt; type(类型) -&gt; document(文档) -&gt; field (字段) 和关系型数据库的关系如下：\n\n\nRelational    DB    -&gt;    Databases    -&gt;    Tables    -&gt;    Rows    -&gt;    Columns\nElasticsearch    -&gt;    Indices            -&gt;    Types        -&gt;    Documents    -&gt;    Fields\n\n但是其实开发上实际上不允许一个索引创建多个类型的，所以也就是为什么后期es废弃了type，最终到8.X版本废弃掉了！原因其实根据es底层有关，影响检索效率，这个和es存储于Lucene 的关系了\n\n在6.x版本只支持一个索引一个type，在7.x版本移除了 type ，8.x彻底废弃，主要原因还是因为lucene的底层设置问题，可以看一下官方文档：https://www.elastic.co/guide/en/elasticsearch/reference/6.8/removal-of-types.html\n\n如何创建一个索引呢​        首先先要pass掉那种直接插入数据进行创建索引的，对于线上业务来说不允许开发者去以这种方式去创建索引的，es可以做控制！其次就是创建索引6.x版本后只能创建一个type，推荐type设置为 _doc，其次就是指定属性了\n​        这个例子是创建一个my_index索引，然后创建一个_doc 类型，字段是 full_name，类型为 text\nPUT my_index&#123;  &quot;mappings&quot;: &#123;    &quot;_doc&quot;: &#123;      &quot;properties&quot;: &#123;# 属性        &quot;full_name&quot;: &#123; # 字段名称          &quot;type&quot;:  &quot;text&quot; # 字段属性控制，具体根据官方配置走        &#125;      &#125;    &#125;  &#125;&#125;\n\n关于更多索引的配置可以参考：mapping字段类型  和 mapping 的字段参数\n核心关注的几个点吧，1、字段的类型 type，2、字段是否可以被索引（默认true）由index控制，3、字段的分词器 analyzer，4、fields 属性(text类型特有的)\n索引的类型使用就不介绍了，这个根据经验有关，主要有基本类型，数组，对象，geo，\n以日志收集来说\n&#123;  &quot;filebeat-xxxxxxx-2021.03.11&quot;: &#123;    &quot;mappings&quot;: &#123;      &quot;doc&quot;: &#123;        &quot;properties&quot;: &#123;          &quot;@timestamp&quot;: &#123;            &quot;type&quot;: &quot;date&quot;          &#125;,          &quot;agent&quot;: &#123;            &quot;type&quot;: &quot;object&quot;          &#125;,          &quot;ecs&quot;: &#123;            &quot;type&quot;: &quot;object&quot;          &#125;,          &quot;fields&quot;: &#123;            &quot;properties&quot;: &#123;              &quot;log_type&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;fields&quot;: &#123;                  &quot;keyword&quot;: &#123;                    &quot;type&quot;: &quot;keyword&quot;,                    &quot;ignore_above&quot;: 256                  &#125;                &#125;              &#125;            &#125;          &#125;,          &quot;host&quot;: &#123;            &quot;properties&quot;: &#123;              &quot;name&quot;: &#123;                &quot;type&quot;: &quot;text&quot;,                &quot;fields&quot;: &#123;                  &quot;keyword&quot;: &#123;                    &quot;type&quot;: &quot;keyword&quot;,                    &quot;ignore_above&quot;: 256                  &#125;                &#125;              &#125;            &#125;          &#125;,          &quot;input&quot;: &#123;            &quot;type&quot;: &quot;object&quot;          &#125;,          &quot;log&quot;: &#123;            &quot;properties&quot;: &#123;              &quot;file&quot;: &#123;                &quot;type&quot;: &quot;object&quot;              &#125;            &#125;          &#125;,          &quot;message&quot;: &#123;            &quot;type&quot;: &quot;text&quot;,            &quot;fields&quot;: &#123;              &quot;keyword&quot;: &#123;                &quot;type&quot;: &quot;keyword&quot;,                &quot;ignore_above&quot;: 256              &#125;            &#125;          &#125;        &#125;      &#125;    &#125;  &#125;&#125;\n\n数据：\n\n2、字段业务中通常关注的是字段设置，因为字段关系到你的数据结构设计，掌握好es的数据结构很重要，下面这个例子我会大概展示如何设置一个结构体\n复杂对象如何存储/检索1、存储主要是采用json的扁平化\nPUT my_index/_doc/1&#123;   &quot;region&quot;: &quot;US&quot;,  &quot;manager&quot;: &#123;     &quot;age&quot;:     30,    &quot;name&quot;: &#123;       &quot;first&quot;: &quot;John&quot;,      &quot;last&quot;:  &quot;Smith&quot;    &#125;  &#125;&#125;\n\n=&gt; 存储到es中由于Lucene没有对象检索这种概念，所以会进行扁平化存储\n&#123;  &quot;region&quot;:             &quot;US&quot;,  &quot;manager.age&quot;:        30,  &quot;manager.name.first&quot;: &quot;John&quot;,  &quot;manager.name.last&quot;:  &quot;Smith&quot;&#125;\n\n2、检索的话和普通字段基本就没有差异了，只要准寻扁平化字段进行检索\n参考：https://www.elastic.co/guide/en/elasticsearch/reference/6.8/object.html\n对象数组如何存储/检索es里面叫做 nested ，中文名称叫做嵌套\n类似于下面的数组，对于es来说，到底是怎么存储的呢？？？\nPUT my_index/_doc/1&#123;  &quot;group&quot; : &quot;fans&quot;,  &quot;user&quot; : [     &#123;      &quot;first&quot; : &quot;John&quot;,      &quot;last&quot; :  &quot;Smith&quot;    &#125;,    &#123;      &quot;first&quot; : &quot;Alice&quot;,      &quot;last&quot; :  &quot;White&quot;    &#125;  ]&#125;\n\nes会将其存储为\n&#123;  &quot;group&quot; :        &quot;fans&quot;,  &quot;user.first&quot; : [ &quot;alice&quot;, &quot;john&quot; ],  &quot;user.last&quot; :  [ &quot;smith&quot;, &quot;white&quot; ]&#125;\n\n因为这里就会有个问题了，那么我查询咋查哇，如何确定唯一，比如查询Alice-Smith，但是其实查询出内容\nGET my_index/_search&#123;  &quot;query&quot;: &#123;    &quot;bool&quot;: &#123;      &quot;must&quot;: [        &#123; &quot;match&quot;: &#123; &quot;user.first&quot;: &quot;Alice&quot; &#125;&#125;,        &#123; &quot;match&quot;: &#123; &quot;user.last&quot;:  &quot;Smith&quot; &#125;&#125;      ]    &#125;  &#125;&#125;\n\nfields 字段的作用\n​    是我基于官方文档对于这个概念的理解，文档: https://www.elastic.co/guide/en/elasticsearch/reference/6.8/multi-fields.html\n\n功能一：聚合1、加入要做keyword了，比如说你的日志可能分类型记录，比如请求超时，请求无权限，请求参数错误，对于这种简单的参数进行聚合统计，但是由于日志需要做全文检索，所以不能设置为 keyword，这里就使用 fields ！\nDELETE /my_indexPUT /my_index&#123;  &quot;settings&quot;: &#123;    &quot;number_of_replicas&quot;: 1,    &quot;number_of_shards&quot;: 5  &#125;,   &quot;mappings&quot;:&#123;    &quot;_doc&quot;:&#123;      &quot;properties&quot;:&#123;        &quot;message&quot;:&#123;          &quot;type&quot;:&quot;text&quot;,          &quot;fields&quot;:&#123;            &quot;keyword&quot;: &#123;              &quot;type&quot;: &quot;keyword&quot;,              &quot;ignore_above&quot;: 10            &#125;          &#125;        &#125;      &#125;    &#125;  &#125;&#125;POST /my_index/_doc&#123;  &quot;message&quot;:&quot;请求超时&quot;&#125;POST /my_index/_doc&#123;  &quot;message&quot;:&quot;业务日志：name: xiaoli, id: 111&quot;&#125;POST /my_index/_doc&#123;  &quot;message&quot;:&quot;请求无权限&quot;&#125;POST /my_index/_doc&#123;  &quot;message&quot;:&quot;请求参数错误&quot;&#125;\n\n2、进行检索：\n2.1、使用kibana会自动告诉你keywork，进行聚合统计\n\n2.2、我还可以通过日志进行全文检索\n\n3、但是对于es来说，如果你没有指定mapping去创建一个索引，\nPOST /test_index/_doc&#123;  &quot;message&quot;:&quot;hello&quot;&#125;GET /test_index/_mapping&#123;  &quot;test_index&quot; : &#123;    &quot;mappings&quot; : &#123;      &quot;_doc&quot; : &#123;        &quot;properties&quot; : &#123;          &quot;message&quot; : &#123;            &quot;type&quot; : &quot;text&quot;,            &quot;fields&quot; : &#123;              &quot;keyword&quot; : &#123;                &quot;type&quot; : &quot;keyword&quot;,                &quot;ignore_above&quot; : 256              &#125;            &#125;          &#125;        &#125;      &#125;    &#125;  &#125;&#125;\n\n可以看到对于 text类型，默认会支持 256个字符的keyword，聚合检索\n功能二：分词\n​    业务上一个字段可能使用多种分词，这里就支持分词属性\n\nPUT my_index&#123;  &quot;mappings&quot;: &#123;    &quot;_doc&quot;: &#123;      &quot;properties&quot;: &#123;        &quot;text&quot;: &#123;           &quot;type&quot;: &quot;text&quot;,          &quot;fields&quot;: &#123;            &quot;english&quot;: &#123;               &quot;type&quot;:     &quot;text&quot;,              &quot;analyzer&quot;: &quot;english&quot;            &#125;          &#125;        &#125;      &#125;    &#125;  &#125;&#125;\n\n3、相关操作1、插入\n\n​    megacorp 表示index，employee 表示类型，3表示id-document\n\nPUT \t/megacorp/employee/3&#123;    &quot;first_name&quot;: &quot;Douglas&quot;,    &quot;last_name&quot;: &quot;Fir&quot;,    &quot;age&quot;: 35,    &quot;about&quot;: &quot;I like to build cabinets&quot;,    &quot;interests&quot;: [        &quot;forestry&quot;    ]&#125;\n\n2、查询\nGET \t/megacorp/employee/_search&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;first_name&quot;: &quot;Anthony&quot;    &#125;  &#125;&#125;\n\n3、过滤查询\n\n过滤查询已被弃用，并在ES 5.0中删除。现在应该使用bool / must / filter查询。\n\n4、更新\nPOST /megacorp/employee/3/_update&#123;  &quot;doc&quot;:&#123;    &quot;age&quot;:22,    &quot;deatil&quot;:&quot;my name is ....&quot;  &#125;&#125;\n\n加入添加一个字段，但是这个索引的mapping不变\n健康状态：Elasticsearch 集群和索引健康状态及常见错误说明\n","categories":["存储"],"tags":["Elasticsearch"]},{"title":"Protocol Buffers协议讲解","url":"/2022/01/16/cc45d69abc6417303d451f43acf099d9/","content":"​     Protobuf 主要是以数据编码小为著名，主要是用于数据交互和数据存储等，降低带宽、磁盘、移动端网络环境较差减少报文大小等场景，关于序列化速度主要是取决于你用的sdk，所以本文不会关心序列化速度！本文将以proto3语法进行介绍！并且也介绍了如何使用pb规范的定义接口，以及对比了pb2/pb3差别！如果你还对Thrift感兴趣，可以看我这边文章: Thrift协议讲解！\n\n\n1. 协议讲解\npb3 与 pb2差别：\n\n\npb3 对于基本类型已经约定了默认值，会把 0/ &quot;&quot;/false/枚举为0的值 在序列化的时候不进行编码，也就是无法区分这个值是否设置了！\npb3 后期支持了 optional，但是需要在编译的时候指定--experimental_allow_proto3_optional !\npb3 不支持 required 关键字，不推荐业务定义required！ \npb3 不支持默认值设置，pb3中默认值都是约定好的，以及不支持group message！\npb3 的枚举类型的第一个字段必须为 0！\npb3 和 pb2 是可以混合使用的！pb3和pb2基本上压缩率和性能上无差别！\n\n\nlabels\npb2\npb3\n备注\n\n\n\nrequired\n支持\n不支持\n\n\n\noptional\n支持\n支持\n\n\n\nsingular (类似于thrift default)\n不支持\n支持\n\n\n\nrepeated\n支持\n支持\n\n\n\noneof\n支持\n支持\n\n\n\nmap\n支持\n支持\n\n\n\nextend\n支持\n不支持\n\n\n\n\n\n选择上来说就是看你是否需要 null和默认值！如果需要那就pb2，不行就pb3！\n\npb3基本上语法如下，具体可以看官方文档: https://developers.google.com/protocol-buffers/docs/proto3 ， 例如下面的test.proto 文件\n\nsyntax = &quot;proto3&quot;;message TestData &#123;  enum EnumType &#123;    UnknownType = 0; // 必须以0开始！    Test1Type = 1;    Test2Type = 2;  &#125;  message TestObj &#123;    int64 t_int64 = 1;  &#125;  string t_string = 1;  int64 t_int64 = 2;  bool t_bool = 3;  fixed64 t_fix64 = 4;  repeated int64 t_list_i64 = 5;  map&lt;int64, string&gt; t_map = 6;  EnumType t_enum = 7;  TestObj t_obj = 8 ;  repeated TestObj t_list_obj = 9 ;  map&lt;string, TestData&gt; t_map_obj = 10;  repeated string  t_list_string = 11;&#125;\n\n\n如何编译了？ 如果是Go的话可以下面这种方式编译！记住提前下载好 protoc-gen-go 和 protoc-gen-go-grpc , 源码地址: protobuf-go\n\n# install  protoc &amp; protoc-gen-go &amp; protoc-gen-go-grpcwget https://github.com/protocolbuffers/protobuf/releases/download/v3.17.3/protoc-3.17.3-osx-x86_64.zipgo get -v google.golang.org/protobuf/cmd/protoc-gen-gogo get -v google.golang.org/grpc/cmd/protoc-gen-go-grpc# 编译上面的&#x27;test.proto&#x27;文件protoc \\--experimental_allow_proto3_optional \\--proto_path=. \\--plugin=protoc-gen-go=$&#123;HOME&#125;/go/bin/protoc-gen-go \\--go_opt=Mtest.proto=github.com/anthony-dong/go-tool/internal/example/protobuf/test \\--go_out=$&#123;HOME&#125;/go/src \\--plugin=protoc-gen-go-grpc=$&#123;HOME&#125;/go/bin/protoc-gen-go-grpc \\--go-grpc_opt=Mtest.proto=github.com/anthony-dong/go-tool/internal/example/protobuf/test \\--go-grpc_out=$&#123;HOME&#125;/go/src \\test.proto\n\n\npb 序列化核心用到的思想就是varint + zigzap,  具体可以看官方文章: https://developers.google.com/protocol-buffers/docs/encoding\n本文的目标是可以做到简单的序列化 message 和 反序列化message！\n目前Go主要有两个PB库，一个是V1版本的: https://github.com/golang/protobuf，一个是V2版本的: https://github.com/protocolbuffers/protobuf-go , 都属于官方实现！\n\n2. 编码+解码关于消息各个类型的编码逻辑: https://github.com/protocolbuffers/protobuf-go/tree/master/internal/impl\n核心思想： \n\nvarint，根据数字的大小进行动态编码，可以减少字节数的占用，采用 msb(the Most Significant Bit) 最高有效位，整个过程可以理解为大端-&gt;小端转换，具体可以看后面讲述！\nzigzag 由于负数的最高高位永远是1，导致-1占用8字节，比较浪费，所以zigzag做了一个映射，负数可以映射成正数，正数还是正数，具体可以看后面讲述！\n\n1. 简单例子（学习目标）下面是一个测试用例，可以看到一个是通过PB自带的库编码，一个是我们自己实现的编码，我们这篇文章目标是可以自己实现编码！\n// 使用pb 序列化func Test_Marshal_Data(t *testing.T) &#123;\tvar request = test.TestData&#123;\t\tTString: &quot;hello&quot;, // 1:string\t\tTInt64:  520,     //8:int64\t\tTObj: &amp;test.TestData_TestObj&#123; //8:message\t\t\tTInt64: 520, // 1:int64\t\t&#125;,\t&#125;\tmarshal, err := proto.Marshal(&amp;request)\tif err != nil &#123;\t\tt.Fatal(err)\t&#125;\tt.Log(hex.Dump(marshal))\t// 00000000  0a 05 68 65 6c 6c 6f 10  88 04 42 03 08 88 04     |..hello...B....|&#125;// 自己编码完成！func TestMarshal_Data_Custom_Test(t *testing.T) &#123;\t// 注释语法\t// field_id:field_type:wire_type\t// size(field_value)\t// field_type=field_value\tbuffer := bytes.NewBuffer(make([]byte, 0, 1024))\tbinary.Write(buffer, binary.BigEndian, uint8(0x0a))     // 1:string:WireBytes, 0000 1010  = 0x0a\tbinary.Write(buffer, binary.BigEndian, uint8(0x05))     // size(string) = 5\tbinary.Write(buffer, binary.BigEndian, []byte(&quot;hello&quot;)) // string=&#x27;hello&#x27;, 68 65 6c 6c 6f\tbinary.Write(buffer, binary.BigEndian, uint8(0x10))     // 2:int64:WireVarint, 0001 0000 = 0x10\tbinary.Write(buffer, binary.BigEndian, uint16(0x8804))  // int64=520, 0000 0010 0000 1000 =&gt; 1000 1000 0000 0100 = 0x8804\tbinary.Write(buffer, binary.BigEndian, uint8(0x42))    // 8:message:WireBytes, 0100 0010 = 0x42\tbinary.Write(buffer, binary.BigEndian, uint8(0x03))    // size(message) = 3\tbinary.Write(buffer, binary.BigEndian, uint8(0x08))    // 1:int64:WireVarint, 0000 1000=0x08\tbinary.Write(buffer, binary.BigEndian, uint16(0x8804)) // int64=520, 0000 0010 0000 1000 =&gt; 1000 1000 0000 0100 = 0x8804\tt.Log(hex.Dump(buffer.Bytes()))\t// 00000000  0a 05 68 65 6c 6c 6f 10  88 04 42 03 08 88 04     |..hello...B....|&#125;\n\n2. Message 编码介绍1. 介绍消息是由 field_id 和 field_value组成，但是pb支持的类型比较多，考虑到编码的时候很多类型其实有相似的逻辑，因此pb对于类型进行了二次归类，叫做wire type，也就是 field_id和wire_type 组合成一个字段用varint 进行编码！\nfield id, wire_type used varint encode+--------+...+--------+--------+--------+...+--------+| field id            |dddddttt| field value         |+--------+...+--------+--------+--------+...+--------+\n\n\nfield id + dddddttt 一共是 1-4个字节，用的是 varint 编码！具体Go的代码实现如下\n\n// EncodeTagAndWireType encodes the given field tag and wire type to the// buffer. This combines the two values and then writes them as a varint.func (b *Buffer) EncodeTagAndWireType(fieldId int32, wireType int8) error &#123;\tv := uint64((int64(fieldId) &lt;&lt; 3) | int64(wireType))\treturn b.EncodeVarint(v)&#125;// DecodeTagAndWireType decodes a field tag and wire type from input.// This reads a varint and then extracts the two fields from the varint// value read.func (cb *Buffer) DecodeTagAndWireType() (tag int32, wireType int8, err error) &#123;\tvar v uint64\tv, err = cb.DecodeVarint()\tif err != nil &#123;\t\treturn\t&#125;\t// low 7 bits is wire type\twireType = int8(v &amp; 7)\t// rest is int32 tag number\tv = v &gt;&gt; 3\tif v &gt; math.MaxInt32 &#123;\t\terr = fmt.Errorf(&quot;tag number out of range: %d&quot;, v)\t\treturn\t&#125;\ttag = int32(v)\treturn&#125;\n\n\nttt 为3bit表示wire_type，也就是最多表示1&lt;&lt;3 -17种类型，包含000 ，也就是8种类型，具体可以看官方文档： wire types 介绍！\n\n\nconst (\tWireVarint     = 0\tWireFixed32    = 5\tWireFixed64    = 1\tWireBytes      = 2\tWireStartGroup = 3\tWireEndGroup   = 4)// 映射关系，就是 字段真实类型 -&gt; 序列化类型func MustWireType(t descriptor.FieldDescriptorProto_Type) int8 &#123;\twireType, err := GetWireType(t)\tif err != nil &#123;\t\tpanic(err)\t&#125;\treturn wireType&#125;func GetWireType(t descriptor.FieldDescriptorProto_Type) (int8, error) &#123;\tswitch t &#123;\tcase descriptor.FieldDescriptorProto_TYPE_ENUM,\t\tdescriptor.FieldDescriptorProto_TYPE_BOOL,\t\tdescriptor.FieldDescriptorProto_TYPE_INT32,\t\tdescriptor.FieldDescriptorProto_TYPE_SINT32,\t\tdescriptor.FieldDescriptorProto_TYPE_UINT32,\t\tdescriptor.FieldDescriptorProto_TYPE_INT64,\t\tdescriptor.FieldDescriptorProto_TYPE_SINT64,\t\tdescriptor.FieldDescriptorProto_TYPE_UINT64:\t\treturn proto.WireVarint, nil\tcase descriptor.FieldDescriptorProto_TYPE_FIXED32,\t\tdescriptor.FieldDescriptorProto_TYPE_SFIXED32,\t\tdescriptor.FieldDescriptorProto_TYPE_FLOAT:\t\treturn proto.WireFixed32, nil\tcase descriptor.FieldDescriptorProto_TYPE_FIXED64,\t\tdescriptor.FieldDescriptorProto_TYPE_SFIXED64,\t\tdescriptor.FieldDescriptorProto_TYPE_DOUBLE:\t\treturn proto.WireFixed64, nil\tcase descriptor.FieldDescriptorProto_TYPE_BYTES,\t\tdescriptor.FieldDescriptorProto_TYPE_STRING,\t\tdescriptor.FieldDescriptorProto_TYPE_MESSAGE:\t\treturn proto.WireBytes, nil\tcase descriptor.FieldDescriptorProto_TYPE_GROUP:\t\treturn proto.WireStartGroup, nil\tdefault:\t\treturn 0, fmt.Errorf(&quot;not support pb type: %d&quot;, t)\t&#125;&#125;\n\n\nfield value 就是字段内容了，下面会详细介绍每一种对应的！\n\nWireVarint 写的时候采用varint 编码，可变1-10字节WireFixed32 写的时候会进行小端转换，固定4字节WireFixed64 写的时候会进行小端转换，固定8字节WireBytes 写的时候正常写出字节流即可！WireStartGroup / WireEndGroup 不进行介绍了！\n\n2. 总结\n这里谈个小技巧，其实看协议编码这种源码的时候，很多位运算，其实一般来说 |表示set bit操作， &amp;表示get bit操作！\n这里再补充下为啥最大字段是2^29-1，是因为nuber最大是ui32编码，然后有3bit用作msb，就剩余29位了，所以就是 2^29-1了！\n这就是为什么pb中1-15字段可以使用一个字节存储，是因为 var int只有7字段存储数据，但是3bit存储wire_type ，所以剩余的4bit存储字段ID，也就是 1&lt;&lt;4 -1 = 15   个字段了！\n\n3. varint 编码介绍wiki介绍 https://en.wikipedia.org/wiki/Variable-length_quantity ，整体概述一下就是对于无符号整数来说，很多时候都是浪费字节，比如uint64 占用 8字节，值为1是占用8字节，值为1&lt;&lt;64 - 1也是一样，那么varint就是解决这个问题了，可以用1-10个字节进行表示！核心思想就是使用低位的7bit表示数据，高位1bit表示msb（The Most Significant Bit， 最高有效位），最小1个字节，最大10个字节表示 int64 ！\npb中类型为如下类型都会采用varint 编码 , 枚举等同于int32!\nvarint       := int32 | int64 | uint32 | uint64 | bool | enum, encoded as varints\n\n1. 例子1比如: data=15 -&gt; 0000 1111,  \n编码逻辑：\nvarint 表示为 0000 1111，是因为他能够用7字节表示！所以不需要设置 msb!\n解析逻辑：\n我们拿到 0000 1111 取出msb 发现1 ，这里拿到msb有多种方式，可以比较大小，也能通过位运算进行取，比如 0000 1111 &amp; 1&lt;&lt;7 == 0 就可以说明没有设置msb，然后取出低7位即是真实数据，这里由于8位也是0其实可以忽略这个操作！\n2. 例子2比如 data=520 -&gt; 0000 0010 0000 1000     (大端表示法，低位在高地址)\n编码逻辑：\n首先确定520是7个bit放不下，所以先取出 前7个字节( data &amp; (1&lt;&lt;7) - 1)  =  000 1000，然后设置msb 1000 1000, 这个是第一轮；\n第二轮剩余字节 0000 0010 0= 4 , 发现4可以用7个字节放下，所以是 0000 0100\n所以最终结果是 1000 1000 0000 0100  ，也就是 [136,4]，这个过程可以理解为是大端 -&gt; 小端的一个过程！\n解析逻辑：\n首先varint 其实输出的是一个小端表示法，因此我们需要从低位开始！\n首先是取出第一个字节1000 1000 ，发现msb，然后得到结果是 000 1000 = 8 \n然后是取出第二个字节0000 0100，发现不是msb，然后得到结果 000 0100，我们需要将它放到 000 1000后面去！怎么做了，其实跟简单 000 0100 &lt;&lt; 7 | 000 1000 即可得到结果是 000 0100 000 1000 = 0000 0010 0000 1000 。 这个逻辑可以理解为是小端-&gt;大端的一个过程\n3. 代码实现func (p *pbCodec) EncodeVarInt(data int64) error &#123;\t// 1. 取出低7位（如果7个字节不可以放下！）\t// 2. 然后设置高8位标识符号\t// 3. 然后右移\tfor data &gt; (1&lt;&lt;7 - 1) &#123;\t\tp.buffer = append(p.buffer, byte(data&amp;(1&lt;&lt;7-1)|(1&lt;&lt;7)))\t\tdata &gt;&gt;= 7\t&#125;\tp.buffer = append(p.buffer, byte(data))\treturn nil&#125;func (p *pbCodec) DecodeVarInt() (int64, error) &#123;\tvar (\t\tx int64\t\tn = 0\t)\tdefer func() &#123;\t\tp.buffer = p.buffer[n:]\t&#125;()\tfor shift := uint(0); shift &lt; 64; shift += 7 &#123; // 偏移量从0开始，每次+7\t\tif n &gt;= len(p.buffer) &#123;\t\t\treturn 0, fmt.Errorf(&quot;not enough buffer&quot;)\t\t&#125;\t\t// 1. 取出第一个自己\t\t// 2. 然后取出低7位\t\t// 3. 然后由于数据是小端，所以取出的数据需要移动偏移量\t\t// 4. 然后设置进去原来的数据中！\t\tb := int64(p.buffer[n])\t\tn++\t\tx |= (b &amp; 0x7F) &lt;&lt; shift\t\tif (b &amp; 0x80) == 0 &#123;\t\t\treturn x, nil\t\t&#125;\t&#125;\treturn 0, fmt.Errorf(&quot;proto integer overflow&quot;)&#125;\n\n4. 非 varint 编码类型1. fixed 64/32 类型 (小端)其实就是用小端进行传输！例如fixed64 = 520 小端编码后如下，为此为了和varint进行区分，所以定了两个wire type=WireFixed32|WireFixed64\n# fix64 520 占用 8 字节00 00 00 00 00 00 02 08# 编码后08 02 00 00 00 00 00 00\n\n例如Go代码的具体实现， 这里以 64位为例子\nimport &quot;encoding/binary&quot;// 写的时候可以通过如下binary.Write(bf, binary.LittleEndian, uint64(520))// 读的时候可以通过如下实现var data uint64binary.Read(bf, binary.LittleEndian, &amp;data)\n\n2. double / float 类型同上面的fixed 64/32  ，double需要转换为 fixed64 , float需要转换为fixed32， 具体 float -&gt; uint Go的转换代码实现：\nimport &quot;math&quot;math.Float32bits(v)math.Float64bits(v)\n\n3. string / bytes / message / packed 类型string 和 bytes 都是变长，所以需要先写长度(var int)编码，再写payload，如果是string的话需要utf-8编码！\nmessage 类型也是采用的如下编码，所以在PB里无法通过二进制报文直接解析！\ndelimited := size (message | string | bytes | packed), size encoded as varintmessage   := valid protobuf sub-messagestring    := valid UTF-8 string (often simply ASCII); max 2GB of bytesbytes     := any sequence of 8-bit bytes; max 2GB\n\ndelimited := size (message | string | bytes | packed), size encoded as varint# size bytes+--------+...+--------+--------+...+--------+| byte length         | bytes               |+--------+...+--------+--------+...+--------+\n\n5. zigzag 编码 ( sint32 / sint64)前面讲的varint并不是万能的，因为数据往存在负数，而负数二进制最高位都是1，所以导致varint编码后数据都很大，所以需要zigzag编码，它可以帮负数转换成正数，正数转换成正数！而且基于位运算效率很高，所以pb提出了sint32、sint64编码，解决这个问题，核心其实就是使用了 zigzag 编码！\n例如: int64 类型，值为 -1， varint 编码是：ff ff ff ff ff ff ff ff ff 01 满满的占用了10个字节！ 但是假如是 sint64 类型，值为 -1， zigzag 编码后值为01，然后varint编码后是 01, 此时就节省了9个字节！\nzigzag 编码其实很简单就是类似于做了层映射！用无符号的一半表示正数一半表示负数！\n\n具体算法用Go写大改如下：\n// EncodeZigZag64 does zig-zag encoding to convert the given// signed 64-bit integer into a form that can be expressed// efficiently as a varint, even for negative values.func EncodeZigZag64(v int64) uint64 &#123;\treturn (uint64(v) &lt;&lt; 1) ^ uint64(v&gt;&gt;63)&#125;// EncodeZigZag32 does zig-zag encoding to convert the given// signed 32-bit integer into a form that can be expressed// efficiently as a varint, even for negative values.func EncodeZigZag32(v int32) uint64 &#123;\treturn uint64((uint32(v) &lt;&lt; 1) ^ uint32((v &gt;&gt; 31)))&#125;// DecodeZigZag32 decodes a signed 32-bit integer from the given// zig-zag encoded value.func DecodeZigZag32(v uint64) int32 &#123;\treturn int32((uint32(v) &gt;&gt; 1) ^ uint32((int32(v&amp;1)&lt;&lt;31)&gt;&gt;31))&#125;// DecodeZigZag64 decodes a signed 64-bit integer from the given// zig-zag encoded value.func DecodeZigZag64(v uint64) int64 &#123;\treturn int64((v &gt;&gt; 1) ^ uint64((int64(v&amp;1)&lt;&lt;63)&gt;&gt;63))&#125;\n\n\n异或：相同为0，相异为1\n\n例如下面例子，将-1 和 1 进行zigzag 编码后:\n# -11111 1111 1111 1111 1111 1111 1111 1111# d1=uint32(n) &lt;&lt; 11111 1111 1111 1111 1111 1111 1111 1110# d2=uint32(n &gt;&gt; 31) (负数左移添加1)1111 1111 1111 1111 1111 1111 1111 1111# d1 ^ d20000 0000 0000 0000 0000 0000 0000 0001# 10000 0000 0000 0000 0000 0000 0000 0001#n&lt;&lt;10000 0000 0000 0000 0000 0000 0000 0010#n&gt;&gt;310000 0000 0000 0000 0000 0000 0000 0000# 输出0000 0000 0000 0000 0000 0000 0000 0010\n\n6. repeated （list）上文都没有讲解到 集合类型，protbuf 提供了 repeated关键字来提供list类型！关于 repeated 具体编码实现有两种：\n\npacked （ pb3默认会根据字段类型选择packed,  pb2 v2.1.0 引入的,具体可以参考官方文档: packed介绍 ）\n\nunpacked \n\n\n目前pb中支持 wire_type=WireVarint|WireFixed32|WireFixed64进行 packed编码！\n其实可以思考一下为啥！首先假如是WireBytes 类型，那么我数据量很大，比如一个bytes数据最大可以写2G，那么我写出的时候假如用packed编码，会存在一个问题就是我写3条数据，需要内存中积压6G数据，然后算出总大小，再写出去，占用内存很大，而且解码的时候也是！PB考虑的可真细致！\n1. packed 编码可以根据官网提供的demo为例子：\nmessage Test4 &#123;  repeated int32 d = 4 [packed=true];&#125;\n\n假如d= [3, 270,86942] ，编码d字段的时候，会进行如下操作，先写 field_number 和 wire_type  然后再去写整个payload 大小，最后再写每一个元素！\n22        // key (field number = 4, wire type = 2 WireBytes)06        // payload size (6 bytes)03        // first element (varint 3)8E 02     // second element (varint 270)9E A7 05  // third element (varint 86942)\n\n2. unpacked 编码message Test5 &#123;  repeated int32 d = 4 [packed = false];&#125;\n\n还是以字段d= [3, 270,86942] 进行编码，可以看到是会把每个元素作为单独的整体进行写出，比如元素一会写field_type and wire_type，然后再写 field_value，依次！！\n00000000  20 03 20 8e 02 20 9e a7  05                       | . .. ...|20  // key (field number 4, wire type=proto.WireVarint)03 // (varint 3)20 //  key (field number 4, wire type=proto.WireVarint)8e 02 // (varint 270)20 //  key (field number 4, wire type=proto.WireVarint)9e a7  05 // (varint 86942)\n\n7. map其实在PB中map实际上就是 repeated kv message，可以通过FieldDescriptor可以看到！\n&#123;    &quot;name&quot;: &quot;TestData&quot;,    &quot;field&quot;: [        &#123;            &quot;name&quot;: &quot;t_map&quot;,            &quot;number&quot;: 6,            &quot;label&quot;: 3,            &quot;type&quot;: 11,            &quot;type_name&quot;: &quot;.TestData.TMapEntry&quot;,            &quot;json_name&quot;: &quot;tMap&quot;        &#125;,    ],    &quot;nested_type&quot;: [        &#123;            &quot;name&quot;: &quot;TMapEntry&quot;,            &quot;field&quot;: [                &#123;                    &quot;name&quot;: &quot;key&quot;,                    &quot;number&quot;: 1,                    &quot;label&quot;: 1,                    &quot;type&quot;: 3,                    &quot;json_name&quot;: &quot;key&quot;                &#125;,                &#123;                    &quot;name&quot;: &quot;value&quot;,                    &quot;number&quot;: 2,                    &quot;label&quot;: 1,                    &quot;type&quot;: 9,                    &quot;json_name&quot;: &quot;value&quot;                &#125;            ],            &quot;options&quot;: &#123;                &quot;map_entry&quot;: true            &#125;        &#125;    ],    &quot;enum_type&quot;: []&#125;\n\n所以编码的时候也很简单，例如\nmessage TestMapData1 &#123;// 这里无法定义 TMapEntry，会报错！  map&lt;int64, string&gt; t_map = 6;&#125;==&gt; 实际上是生成了这个代码！message TestMapData2 &#123;  message TMapEntry &#123;    int64 key = 1;    string value = 2;  &#125;  repeated TMapEntry t_map = 6;&#125;\n\n所以编码过程是一个repeated k v message的序列化方式！例如下面\nt_map= &#123;1:&quot;1&quot;,2:&quot;2&quot;&#125;=&gt;32 05 08 01 12 01 31 32  05 08 02 12 01 32=&gt; 32 // field_number=6 and wire_type=proto.WireBytes05 // entry data length=508 // entry data key field_number=1 and wire_type=proto.WireVarint01 // entry data key_value=varint(1)12 // entry data value field_number=2 and wire_type=proto.WireBytes01 // entry data value len= varint(1)31 // entry data value=&quot;1&quot;32  // field_number=6 and wire_type=proto.WireBytes05  // entry data length=508 02 12 01 32 // 同上！\n\n8. field orderpb编码不在意字段的编码顺序，也就是encode的字段顺序不一样会导致输出的数据不一样！但是解析出来的数据是一样的！\n还有就是map的key顺序也会影响！\n所以一般api都会指定是否支持 deterministic，如果设置为true，结果一般都会保证一样，否则可能不一样！\n但是你懂得，实际上效果吧，就是开启之后一定比不开启慢，因为需要进行order！\n3. pb 协议整体概括下面这个是一个类似于bnf范式的东西，具体可以参考: PB Encode 算法\nmessage   := (tag value)*     You can think of this as “key value”tag       := (field &lt;&lt; 3) BIT_OR wire_type, encoded as varintvalue     := (varint|zigzag) for wire_type==0 |             fixed32bit      for wire_type==5 |             fixed64bit      for wire_type==1 |             delimited       for wire_type==2 |             group_start     for wire_type==3 | This is like “open parenthesis”             group_end       for wire_type==4   This is like “close parenthesis”varint       := int32 | int64 | uint32 | uint64 | bool | enum, encoded as                varintszigzag       := sint32 | sint64, encoded as zig-zag varintsfixed32bit   := sfixed32 | fixed32 | float, encoded as 4-byte little-endian;                memcpy of the equivalent C types (u?int32_t, float)fixed64bit   := sfixed64 | fixed64 | double, encoded as 8-byte little-endian;                memcpy of the equivalent C types (u?int64_t, double)delimited := size (message | string | bytes | packed), size encoded as varintmessage   := valid protobuf sub-messagestring    := valid UTF-8 string (often simply ASCII); max 2GB of bytesbytes     := any sequence of 8-bit bytes; max 2GBpacked    := varint* | fixed32bit* | fixed64bit*,             consecutive values of the type described in the protocol definitionvarint encoding: sets MSB of 8-bit byte to indicate “no more bytes”zigzag encoding: sint32 and sint64 types use zigzag encoding.\n\n4. protoc 命令讲解这里讲解一下protoc 的架构图，生成架构图\n\n第一个节点protoc其实是 c++写的， https://github.com/protocolbuffers/protobuf\n第二个节点是 protoc 输出的二进制报文CodeGeneratorRequest    ，具体可以看 CodeGeneratorRequest IDL定义\n第三个节点是plugin生成逻辑，可以通过标准输入获取CodeGeneratorRequest,通过标准输出写入CodeGeneratorResponse\n第四个节点输出 CodeGeneratorResponse，具体可以看 CodeGeneratorResponse IDL定义\n目前虽然有很多项目在解析protoc 的 ast时，都是自己实现的词法解析和语法解析，所以假如可以把protoc封装个lib库就好了！\n5. pb 其他细节讲解\npackage（包），一个包下不能存在相同定义的message和枚举以及枚举字段！\n\n\n一般来说定义规则是 common.prefix + 文件路径 , 其实和Java的Package定义很像！这个是比较推荐的方案！\n\n\ninclude（import），基于include_path 作为根目录的relative pata\n\noption，可以理解为是一些注解，可以对于字段、消息、枚举、method进行标记！但是必须注解定义文件必须使用pb2语法！\n\n\n\n这里不推荐在idl里定义 option go_package=xxx  java php py 之类的，因为pb在编译期可以指定！如果你们有自己的pb gen plugin可以拓展 descriptor!\n\nsyntax = &quot;proto2&quot;;package api;option go_package = &quot;github.com/anthony-dong/go-tool/internal/example/protobuf/idl_example/pb_gen/api&quot;;import &quot;google/protobuf/descriptor.proto&quot;;extend google.protobuf.FieldOptions &#123;  optional HttpSourceType source = 50101; // 来自于http 请求的哪个部位  optional string key = 50102; // http 请求的header 还是哪  optional bool unbox = 50103; // 是否平铺开结构体，除body外，默认处理第一层&#125;enum HttpSourceType &#123;  Query = 1;  Body = 2;  Header = 3;&#125;extend google.protobuf.MethodOptions &#123;  optional HttpMethodType method = 50201; // http method  optional string path = 50202; // http path&#125;enum HttpMethodType&#123;  GET = 1;  POST = 2;  PUT = 3;&#125;// extend google.protobuf.EnumValueOptions &#123;// &#125;// extend google.protobuf.EnumOptions &#123;// &#125;// extend google.protobuf.MessageOptions &#123;// &#125;// extend google.protobuf.ServiceOptions &#123;// &#125;\n\n具体可以看我的写的例子：protobuf\n6. proto any 类型例如pb文件\nimport &quot;google/protobuf/any.proto&quot;;message TestAnyType &#123;  optional google.protobuf.Any any = 1;&#125;message Type1 &#123;  string  value = 1;&#125;message Type2 &#123;  int64  value = 1;&#125;message Type3 &#123;  float value = 1;&#125;\n\n此时Value可能是很多类型，比如 Type1 或者Type2或者Type3，所以此时需要一个any类型\n首先我们写代码创建一个 TestAnyType 经过pb编码\nfunc encodeData(t *testing.T) []byte &#123;\t// import &quot;google.golang.org/protobuf/types/known/anypb&quot;\tdata := test.TestAnyType&#123;\t\tAny: &amp;anypb.Any&#123;&#125;,\t&#125;\tif err := data.Any.MarshalFrom(&amp;test.Type1&#123;\t\tValue: &quot;11111&quot;,\t&#125;); err != nil &#123;\t\tt.Fatal(err)\t&#125;\t// import &quot;google.golang.org/protobuf/proto&quot;\tif result, err := proto.Marshal(&amp;data); err != nil &#123;\t\tt.Fatal(err)\t\treturn nil\t&#125; else &#123;\t\treturn result\t&#125;&#125;\n\n如何使用了？\nfunc TestAnyType(t *testing.T) &#123;\tdata := encodeData(t)\tresult := test.TestAnyType&#123;&#125;\tif err := proto.Unmarshal(data, &amp;result); err != nil &#123;\t\tt.Fatal(err)\t&#125;\tt.Log(result.String())\tany := result.Any\t// 通过 any.MessageIs 判断类型！记住可以使用 ”伪空对象“ 即可！\tif any.MessageIs((*test.Type1)(nil)) &#123;\t\ttype1 := test.Type1&#123;&#125;\t\tif err := any.UnmarshalTo(&amp;type1); err != nil &#123;\t\t\tt.Fatal(err)\t\t&#125;\t\t// handler type1 func\t\tt.Logf(&quot;type1: %s\\n&quot;, type1.String())\t&#125;\tif any.MessageIs((*test.Type2)(nil)) &#123;\t\ttype2 := test.Type2&#123;&#125;\t\tif err := any.UnmarshalTo(&amp;type2); err != nil &#123;\t\t\tt.Fatal(err)\t\t&#125;\t\t// handler type2 func\t\tt.Logf(&quot;type2: %s\\n&quot;, type2.String())\t&#125;\tif any.MessageIs((*test.Type3)(nil)) &#123;\t\ttype2 := test.Type3&#123;&#125;\t\tif err := any.UnmarshalTo(&amp;type2); err != nil &#123;\t\t\tt.Fatal(err)\t\t&#125;\t\t// handler type3 func\t\tt.Logf(&quot;type3: %s\\n&quot;, type2.String())\t&#125;&#125;\n\n7. 参考文章\nprotobuf 编码介绍\nprotobuf编码之varint/zigzag\n微软 API设计规范\nGoogle API设计规范\nrestful api设计指南\n\n","categories":["RPC"],"tags":["GRPC","API","Protobuf"]},{"title":"git 日常用法","url":"/2020/03/08/e29180bc3d76b959abec41c7fc18c142/","content":"​    日常开发中经常使用git作为版本控制，常用的话就是git命令，也可以使用第三方的 sourcetree 工具，对于常用命令来说，其实git命令基本够用了，但是当你大量阅读代码的时候，依托于ide，速度太慢了！\n\n\n1、常用命令git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt;\ngit push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; ,  和git pull 都是 src:dest\n git fetch &lt;远程主机名&gt; &lt;分支名&gt;  其实就是拉去远程分支到本地版本库，然后再使用 git merge\ngit merge &lt;branch&gt;  合并分支，将&lt;branch&gt; 合并到当前所在的分支， 比如git merge master ，将本地master与自己的分支合并，比如git merge origin/branch ，就是将远程的origin/branch与本地的分支合并 , 比如不自动commit，可以git merge --no-commit &lt;branch&gt; 。 其实git merge 可以一次合并多个分支，比如 git merge &lt;branch&gt; origin/&lt;branch&gt; 其实就是管你远程和本地了全部合到我的分支上。\ngit diff &lt;branch1&gt; &lt;branch2&gt;  在两个分支之间比较\ngit diff --cached    比较 git add . 与 工作区之间的比较， 也就是本地暂存区与工作区之间的比较\n\ngit diff\t            工作区 vs 暂存区git diff head\t        工作区 vs 版本库git diff –cached        暂存区 vs 版本库\n\ngit reset --mixed  将暂存区的分支直接回到到工作区， 也就是比如git add .  你想回退到本地，直接 `git resrt –mixed\ngit reset --mixed HEAD~1 回退一个版本，比如你本地commit/远程已经push了，那么你本地和远程是一样的，如果你想回退一个版本，此时需要reset操作，主要是解决回退的操作，上面就是commit一次后需要回退一个版本，所以是HEAD～1, 比如commit了两次就是HEAD~2 ， 此时有4种选项，一般分为--hard 和 --mixed  ，--soft  , --hard 硬reset，回退回来你的这次修改全部没有了，也就是直接回到了上一个版本，而--mixed 回退到你没有git add . 操作的时候，--soft 是回退到你git add . 操作完后的时候。 看需求吧。一般只用--hard 和 --mixed .\ngit commit --amend  主要是处理 你 git commit -m &#39;&#39; 想要修改 commit的desc/comment了。\ngit rm -r --cached .  比如修改了 gitignore ,但是其实你的版本库/暂存区是没有 ignore的，所以需要直接删除 暂存区的缓存。\ngit rm file 也就是删除本地开发的一个文件，硬删除，直接删没了，回退也需要硬回退。\ngit checkout .  清空本地所有修改的代码\ngit checkout -b &lt;branch&gt; 将本地的这个分支，checkout 出一个新的分支，名字为&lt;branch&gt;git checkout -b &lt;branch&gt;  origin/&lt;branch&gt; ，将远程的&lt;branch&gt; 分支上 checkout一个新的本地分支名字为`\n有些场景可能需要打tag，所以一般是 git pull ,拉去远程的所有代码(记得切换到master上)，然后 git tag 查看tag 历史，创建一个新的tag ，比如git tag v1.1.0，然后直接推送到远程git push origin v1.1.0 就好了（一般是别人给你合master了，上线可能需要打新的tag）\n文件权限发生变更需要配置：git diff old mode 100644 new mode 100755 的问题 ：需要设置 git config –add core.filemode false\n git log -p README.md 查看文件的变更详细历史， git log &lt;file&gt; 查看文件的变更历史，另外有可能查看某一行的变更，这个是指你没有ide的情况下，所以需要指定\n➜  ebike-**** git:(master) ✗ cat -n  cmd/main.go 1  package main 2   3  import ( ## ........18  )19  20  func main() &#123;# ......24          // 启动RocketMQ25          rq.RocketmqInit()## ......53          r.Run(fmt.Sprintf(&quot;:%s&quot;, host))54  &#125;55  ## .............83  &#125;\n\n然后\n➜  ebike-op-helios git:(master) ✗ git log -L 25:cmd/main.go\n\n\ngit shortlog -sn 查看提交者\ngit submodel add remote_addr local_dir 子模块\n# 将远程项目https://github.com/maonx/vimwiki-assets.git克隆到本地assets文件夹。git submodule add https://github.com/maonx/vimwiki-assets.git assets\t\n\n2、子模块\n​    有种情况我们经常会遇到：某个工作中的项目需要包含并使用另一个项目。 也许是第三方库，或者你独立开发的，用于多个父项目的库。 现在问题来了：你想要把它们当做两个独立的项目，同时又想在一个项目中使用另一个。\n\n文档：Git-工具-子模块\n1、在父项目新建子模块\ngit submodule add https://github.com/chaconinc/DbConnector  ./submodule/DbConnector\n\n2、提交子模块\n\n如果在父项目(父项目无任何变更)中提交子模块，会出现：\n\n➜  test-dir git:(master) gitpush masterOn branch masterYour branch is up to date with &#x27;origin/master&#x27;.Changes not staged for commit:\tmodified:   submodule-01 (modified content)no changes added to commitEverything up-to-date\n\n\n父项目更更提交 （可以提交变更，但是子项目并没有提交）\n\n➜  test-dir git:(master) ✗ gitpush master[master f00fa83] fanhaodong 提交与2021-03-08 15:54:09 1 file changed, 1 insertion(+)## ......To gitee.com:Anthony-Dong/parent-report.git   53487e2..f00fa83  master -&gt; master\n\n\n提交子项目(需要切换到子项目目录，然后切换到父项目提交)\n\n➜  submodule-01 git:(master) ✗ gitpush master[master 969f9ea] fanhaodong 提交与2021-03-08 15:52:08## ....To gitee.com:Anthony-Dong/submodule-01.git   6ac8e7d..969f9ea  master -&gt; master   ➜  test-dir git:(master) ✗ gitpush master[master 53487e2] fanhaodong 提交与2021-03-08 15:52:12 1 file changed, 1 insertion(+), 1 deletion(-)## ....To gitee.com:Anthony-Dong/parent-report.git   14e259d..53487e2  master -&gt; maste   \n\n问题就是，提交流程过于复杂！！\n参考\nProGit, 最好的Git指南\nAdvanced Git\nGit and GitHub Secrets\nGIT子模块\n\n","categories":["Linux"],"tags":["git"]},{"title":"singleflight和backoff包介绍和组合使用","url":"/2022/02/28/efabb79e15af38ef629520bf36df0adf/","content":"​    业务中我们经常遇到一些重复使用的轮子代码，本篇介绍了 singleflight 和 backoff 以及本地缓存！来提高我们平时业务开发的效率和代码的精简度！\n\n\nsingleflight介绍\n源码位置: https://github.com/golang/groupcache/tree/master/singleflight 或者 golang.org/x/sync/singleflight\n\n主要是google 开源的group cache 封装的sdk，目的是为了解决 cache 回源的时候，容易出现并发加载一个或者多个key，导致缓存击穿\n\n其中 golang.org/x/sync/singleflight 它提供了更多方法，比如异步加载等！但是代码量增加了很多，比如很多异步的bug之类的！\n\n\n简单使用\n简单模拟100个并发请求去加载k1\n\npackage mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;github.com/golang/groupcache/singleflight&quot;)var (\tcache sync.Map\tsf    = singleflight.Group&#123;&#125;)func main() &#123;\tkey := &quot;k1&quot; // 假如现在有100个并发请求访问 k1\twg := sync.WaitGroup&#123;&#125;\twg.Add(100)\tfor x := 0; x &lt; 100; x++ &#123;\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\tloadKey(key)\t\t&#125;()\t&#125;\twg.Wait()\tfmt.Printf(&quot;result key: %s\\n&quot;, loadKey(key))&#125;func loadKey(key string) (v string) &#123;\tif data, ok := cache.Load(key); ok &#123;\t\treturn data.(string)\t&#125;\tdata, err := sf.Do(key, func() (interface&#123;&#125;, error) &#123;\t\tdata := &quot;data&quot; + &quot;|&quot; + key\t\tfmt.Printf(&quot;load and set success, data: %s\\n&quot;, data)\t\tcache.Store(key, data)\t\treturn data, nil\t&#125;)\tif err != nil &#123;\t\t// todo handler\t\tpanic(err)\t&#125;\treturn data.(string)&#125;// output//load and set success, data: data|k1//load and set success, data: data|k1//result key: data|k1\n\n可以看到输出中，其中有2次去 loadKeyFromRemote 去加载，并没有做到完全防止得到的作用\n\n如何解决上诉问题了，问题出在哪了？我们进行简单的源码分析\n\n源码分析\n数据结构\n\n// call is an in-flight or completed Do calltype call struct &#123;\twg  sync.WaitGroup\tval interface&#123;&#125;\terr error&#125;// Group represents a class of work and forms a namespace in which// units of work can be executed with duplicate suppression.type Group struct &#123;\tmu sync.Mutex       // protects m\tm  map[string]*call // lazily initialized // 懒加载&#125;\n\n\n主逻辑\n\nfunc (g *Group) Do(key string, fn func() (interface&#123;&#125;, error)) (interface&#123;&#125;, error) &#123;\tg.mu.Lock() // lock\tif g.m == nil &#123; // 懒加载\t\tg.m = make(map[string]*call)\t&#125;  // 如果key存在，则wait\tif c, ok := g.m[key]; ok &#123;\t\tg.mu.Unlock()\t\tc.wg.Wait()\t\treturn c.val, c.err\t&#125;  // new caller + wg add  + set\tc := new(call)\tc.wg.Add(1)\tg.m[key] = c\tg.mu.Unlock()\t  // 调用方法\tc.val, c.err = fn()  // notify\tc.wg.Done()\t  // 删除key,防止内存泄漏\tg.mu.Lock()\tdelete(g.m, key)\tg.mu.Unlock()\treturn c.val, c.err&#125;\n\n\n(1) 首先会去初始化一个 caller，然后waitgroup ++ ，然后set  [锁]\n(2) 然后调用方法，再done [无锁]\n(3) 最后删除 key [锁]\n(4) 其他同一个key并发请求，会发现key存在，则直接wait了!\n\n假如现在并发请求，那么此时假如都加载同一个key，那么只有一个key先经过，但是计算机执行的很快，在第(2)和(3)步执行的很快，导致key已经删除，但是还有请求未开始 Do 方法或者到了 g.m[key] 这一步，都是会再次重新走一遍\n\n问题? 能不能使用读写锁优化加锁了？\n\n假如读取key加的读锁，那么此时最长流程变为: 读锁 + 写锁 + 写锁， 最短流程变为: 读锁， 当特别高的并发才会有较为大的提升！\n优化后用法package mainimport (\t&quot;fmt&quot;\t&quot;sync&quot;\t&quot;github.com/golang/groupcache/singleflight&quot;)var (\tcache sync.Map\tsf    = singleflight.Group&#123;&#125;)func main() &#123;\tkey := &quot;k1&quot; // 假如现在有100个并发请求访问 k1\twg := sync.WaitGroup&#123;&#125;\twg.Add(100)\tfor x := 0; x &lt; 100; x++ &#123;\t\tgo func() &#123;\t\t\tdefer wg.Done()\t\t\tloadKey(key)\t\t&#125;()\t&#125;\twg.Wait()\tfmt.Printf(&quot;result key: %s\\n&quot;, loadKey(key))&#125;func loadKey(key string) (v string) &#123;\tif data, ok := cache.Load(key); ok &#123;\t\treturn data.(string)\t&#125;\tdata, err := sf.Do(key, func() (interface&#123;&#125;, error) &#123;\t\tif data, ok := cache.Load(key); ok &#123; // 双重检测\t\t\treturn data.(string), nil\t\t&#125;\t\tdata := &quot;data&quot; + &quot;|&quot; + key\t\tfmt.Printf(&quot;load and set success, data: %s\\n&quot;, data)\t\tcache.Store(key, data)\t\treturn data, nil\t&#125;)\tif err != nil &#123;\t\t// todo handler\t\tpanic(err)\t&#125;\treturn data.(string)&#125;// output//load and set success, data: data|k1//result key: data|k1\n\nbackoff介绍\n源码地址: github.com/cenkalti/backoff\n\n主要是解决补偿的操作，当业务/方法遇到异常的情况，通常会有补偿的操作，一般就是业务继续重试\n\n我经常使用这个包做重试，感觉比较好用！不用自己写for循环了\n\n\n简单使用\n模拟一个异常，去加载一个data数据，当遇到偶数的时候就爆异常！\n\npackage mainimport (\t&quot;fmt&quot;\t&quot;math/rand&quot;\t&quot;time&quot;\t&quot;github.com/cenkalti/backoff&quot;)func main() &#123;\tvar (\t\tdata interface&#123;&#125;\t)\tif err := backoff.Retry(func() error &#123;\t\tif rand.Int()%2 == 0 &#123; // 模拟异常\t\t\terr := fmt.Errorf(&quot;find data mod 2 is zero&quot;)\t\t\tfmt.Printf(&quot;find err, err: %s\\n&quot;, err)\t\t\treturn err\t\t&#125;\t\tdata = &quot;load success&quot;\t\treturn nil\t&#125;, backoff.WithMaxRetries(backoff.NewConstantBackOff(time.Millisecond*1), 3)); err != nil &#123;\t\tpanic(err)\t&#125;\tfmt.Printf(&quot;data: %s\\n&quot;, data)&#125;//output//find err, err: find data mod 2 is zero//data: load success\n\n结果可以看到很好的解决了重试的问题！代码很优雅！\n\n关于为啥业务中重试都喜欢等待一下，其实比较佛学！\n\nsdk介绍\nback off\n\ntype BackOff interface &#123;\t// NextBackOff returns the duration to wait before retrying the operation,\t// or backoff. Stop to indicate that no more retries should be made.\t// 是否下一次，以及下一次需要等待的时间！\tNextBackOff() time.Duration\t// Reset to initial state.\tReset()&#125;\n\n\n封装了四个基本的Backoff\n\n// 不需要等待，继续重试type ZeroBackOff struct&#123;&#125;func (b *ZeroBackOff) Reset() &#123;&#125;func (b *ZeroBackOff) NextBackOff() time.Duration &#123; return 0 &#125;// 不允许重试type StopBackOff struct&#123;&#125;func (b *StopBackOff) Reset() &#123;&#125;func (b *StopBackOff) NextBackOff() time.Duration &#123; return Stop &#125;// 每次重试等待相同的时间type ConstantBackOff struct &#123;\tInterval time.Duration&#125;func (b *ConstantBackOff) Reset()                     &#123;&#125;func (b *ConstantBackOff) NextBackOff() time.Duration &#123; return b.Interval &#125;func NewConstantBackOff(d time.Duration) *ConstantBackOff &#123;\treturn &amp;ConstantBackOff&#123;Interval: d&#125;&#125;// 重试back off，主要是计数重试的次数，以及基于委托代理模型，实现比较好的拓展// max=0 会无限重试下去func WithMaxRetries(b BackOff, max uint64) BackOff &#123;\treturn &amp;backOffTries&#123;delegate: b, maxTries: max&#125;&#125;type backOffTries struct &#123;\tdelegate BackOff\tmaxTries uint64\tnumTries uint64&#125;func (b *backOffTries) NextBackOff() time.Duration &#123;\tif b.maxTries &gt; 0 &#123;\t\tif b.maxTries &lt;= b.numTries &#123;\t\t\treturn Stop\t\t&#125;\t\tb.numTries++\t&#125;\treturn b.delegate.NextBackOff()&#125;func (b *backOffTries) Reset() &#123;\tb.numTries = 0\tb.delegate.Reset()&#125;\n\n\n自适应backoff\n\n\n整个时间 &lt; 15min，重试时间从500ms开始增长，每次增长1.5倍，直到60s每次！\n\n// NewExponentialBackOff creates an instance of ExponentialBackOff using default values.func NewExponentialBackOff() *ExponentialBackOff &#123;\tb := &amp;ExponentialBackOff&#123;\t\tInitialInterval:     DefaultInitialInterval,\t\tRandomizationFactor: DefaultRandomizationFactor,\t\tMultiplier:          DefaultMultiplier,\t\tMaxInterval:         DefaultMaxInterval,\t\tMaxElapsedTime:      DefaultMaxElapsedTime,\t\tClock:               SystemClock,\t&#125;\tb.Reset()\treturn b&#125;\n\n组合使用，构建一个本地缓存！这个应该是日常开发中经常用到的，本地缓存可以有效解决高频数据但是数据整体占用并不是特别的大，但是每次加载都需要额外的开销，所以基于本地缓存去构建一个可用性比较高的缓存框架！\n\n核心代码\n\npackage mainimport (\t&quot;context&quot;\t&quot;fmt&quot;\t&quot;time&quot;\t&quot;github.com/cenkalti/backoff&quot;\t&quot;golang.org/x/sync/singleflight&quot;)var (\tlocalCacheCallbackIsNil = fmt.Errorf(&quot;cache callback func is nil&quot;))type CacheOption interface &#123;&#125;type Cache interface &#123;\tGet(key string) (value interface&#123;&#125;, isExist bool)\tSet(key string, value interface&#123;&#125;, opts ...CacheOption)&#125;type WrapperCache interface &#123;\tGetData(ctx context.Context, key string, callback func(ctx context.Context) (interface&#123;&#125;, error)) (v interface&#123;&#125;, err error)&#125;type wrapperCache struct &#123;\tname           string\tcache          Cache\tsingleflight   singleflight.Group\tretrySleepTime time.Duration\tretryNum       uint64&#125;func NewWrapperCache(name string, cache Cache) WrapperCache &#123;\treturn &amp;wrapperCache&#123;\t\tname:           name,\t\tcache:          cache,\t\tretryNum:       3,\t\tretrySleepTime: time.Millisecond * 10,\t&#125;&#125;// emitHitCachedMetric 计算缓存命中率func (c *wrapperCache) emitHitCachedMetric(hit bool) &#123;&#125;func (c *wrapperCache) GetData(ctx context.Context, key string, callback func(ctx context.Context) (interface&#123;&#125;, error)) (v interface&#123;&#125;, err error) &#123;\tif result, isExist := c.cache.Get(key); isExist &#123;\t\tc.emitHitCachedMetric(true)\t\treturn result, nil\t&#125;\tif callback == nil &#123;\t\treturn nil, localCacheCallbackIsNil\t&#125;\tc.emitHitCachedMetric(false)\tresult, err, _ := c.singleflight.Do(key, func() (interface&#123;&#125;, error) &#123;\t\t// 双重检测，防止singleflight 锁的key失效\t\tif result, isExist := c.cache.Get(key); isExist &#123;\t\t\treturn result, nil\t\t&#125;\t\tvar callBackData interface&#123;&#125;\t\tif err := backoff.Retry(func() error &#123;\t\t\tif data, err := callback(ctx); err != nil &#123;\t\t\t\treturn err\t\t\t&#125; else &#123;\t\t\t\tcallBackData = data\t\t\t\treturn nil\t\t\t&#125;\t\t&#125;, backoff.WithMaxRetries(backoff.NewConstantBackOff(c.retrySleepTime), c.retryNum)); err != nil &#123;\t\t\t// todo add log\t\t\treturn nil, err\t\t&#125;\t\tc.cache.Set(key, callBackData)\t\treturn callBackData, nil\t&#125;)\tif err != nil &#123;\t\treturn nil, err\t&#125;\treturn result, nil&#125;\n\n\ncache 实现\n\n这里介绍一下sync.Map为一个无过期的本地缓存和 go-cache有ttl的缓存框架！或者你自己去实现一个也可以！\nimport (  &quot;sync&quot;\t&quot;github.com/patrickmn/go-cache&quot;)type localCache struct &#123;\tsync.Map&#125;func (l *localCache) Get(key string) (value interface&#123;&#125;, isExist bool) &#123;\treturn l.Load(key)&#125;func (l *localCache) Set(key string, value interface&#123;&#125;, opts ...CacheOption) &#123;\tl.Store(key, value)&#125;type goCache struct &#123;\t*cache.Cache&#125;func (l goCache) Set(key string, value interface&#123;&#125;, opts ...CacheOption) &#123;\tl.SetDefault(key, value)&#125;\n\n\n测试用例\n\nimport (\t&quot;context&quot;\t&quot;strconv&quot;\t&quot;sync&quot;\t&quot;sync/atomic&quot;\t&quot;testing&quot;\t&quot;time&quot;\t&quot;github.com/patrickmn/go-cache&quot;\t&quot;github.com/stretchr/testify/assert&quot;)func TestNewCached(t *testing.T) &#123;\tcached := NewWrapperCache(&quot;test&quot;, goCache&#123;\t\tCache: cache.New(time.Second*10, time.Second*30),\t&#125;)\t//cached := NewWrapperCache(&quot;test&quot;, &amp;localCache&#123;&#125;)\tctx := context.Background()\twg := sync.WaitGroup&#123;&#125;\tvar (\t\tloadTime uint64 = 0\t\tcurrG           = 20\t)\twg.Add(currG)\tfor x := 0; x &lt; currG; x++ &#123;\t\tgo func(x int) &#123;\t\t\tdefer wg.Done()\t\t\tfor y := 0; y &lt; 200000; y++ &#123;\t\t\t\tkey := y % 10\t\t\t\tresult, err := cached.GetData(ctx, strconv.Itoa(key), func(ctx context.Context) (interface&#123;&#125;, error) &#123;\t\t\t\t\tatomic.AddUint64(&amp;loadTime, 1)\t\t\t\t\tt.Logf(&quot;load key: %s, num: %d, g_id: %d\\n&quot;, strconv.Itoa(key), y, x)\t\t\t\t\treturn int(key), nil\t\t\t\t&#125;)\t\t\t\tif err != nil &#123;\t\t\t\t\tt.Fatal(err)\t\t\t\t&#125;\t\t\t\tif result.(int) != key &#123;\t\t\t\t\tt.Fatal(&quot;data is not eq err&quot;)\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;(x)\t&#125;\twg.Wait()\tfor x := 0; x &lt; 10; x++ &#123;\t\tresult, _ := cached.GetData(ctx, strconv.Itoa(x), nil)\t\tt.Log(result)\t\tassert.Equal(t, result.(int), int(x))\t&#125;\tassert.Equal(t, int(loadTime), int(10))&#125;\n\n","categories":["Golang"],"tags":["singleflight","backoff"]},{"title":"Golang的调度模型","url":"/2021/05/27/ed44e381cbc098d95c5091eb11450b7e/","content":"Go有四大核心模块，基本全部体现在runtime，有调度系统、GC、goroutine、channel，那么深入理解其中的精髓可以帮助我们理解Go这一门语言！\n\n\n1、Go调度模型发展历史\n单线程调度器 (0.x 版本)\n只包含 40 多行代码；\n程序中只能存在一个活跃线程，由 G-M 模型组成；\n\n\n多线程调度器 ·（1.0版本）\n允许运行多线程的程序；\n全局锁导致竞争严重；\n\n\n任务窃取调度器 · （1.1版本）\n引入了处理器 P，构成了目前的 G-M-P 模型；\n在处理器 P 的基础上实现了基于工作窃取的调度器；\n在某些情况下，Goroutine 不会让出线程，进而造成饥饿问题；(单个p+空转)\n时间过长的垃圾回收（Stop-the-world，STW）会导致程序长时间无法工作；\n\n\n抢占式调度器 · （1.2版本~ 至今）\n基于协作的抢占式调度器 - 1.2 ~ 1.13\n通过编译器在函数调用时插入抢占检查指令，在函数调用时检查当前 Goroutine 是否发起了抢占请求，实现基于协作的抢占式调度；\nGoroutine 可能会因为垃圾回收和循环长时间占用资源导致程序暂停；\n\n\n基于信号的抢占式调度器 - 1.14 ~ 至今\n实现基于信号的真抢占式调度；\n垃圾回收在扫描栈时会触发抢占调度；\n抢占的时间点不够多，还不能覆盖全部的边缘情况；\n\n\n\n\n非均匀存储访问调度器 · 提案\n对运行时的各种资源进行分区；\n实现非常复杂，到今天还没有提上日程；\n\n\n\n上面说到的1.3版本以前历史，其实都是go的非发行版本，所以我们关注与的是go的发行版本，也就是go的gpm模型！\n\nG: Goroutine，即我们在 Go 程序中使用 go 关键字创建的执行体；\nM: Machine，或 worker thread，即传统意义上进程的线程；\nP: Processor，即一种人为抽象的、用于执行 Go 代码被要求局部资源。只有当 M 与一个 P 关联后才能执行 Go 代码。除非 M 发生阻塞或在进行系统调用时间过长时，没有与之关联的 P。\n\n参考: 调度系统设计精要\n2、GM模型\n​    P的作用不光光是队列这种抽象，如果理解为队列，那么它的地位只是M的一个子集，GM模型，我们核心关注的是G和M，这也是一般线程池的模型！目标就是高效的调度G在M上！\n\n下面是我用Go语言简单写的一个调度器，大家可以看看设计思路，以及存在的问题！\npackage mainimport (\t&quot;fmt&quot;\t&quot;go.uber.org/atomic&quot;\t&quot;os&quot;\t&quot;os/signal&quot;\t&quot;time&quot;)func main() &#123;\tsig := make(chan os.Signal, 0) // 监听程序的信号\tsignal.Notify(sig, os.Interrupt, os.Kill)\tdown := make(chan struct&#123;&#125;, 0) // 程序down机信号\tthreadNum := 2                        // 运行的线程\ttaskQueue := make(chan func(), 1&lt;&lt;20) // 任务队列大小限制\taddTask := func(foo func()) &#123;\t\tselect &#123;\t\tcase &lt;-down:\t\tcase taskQueue &lt;- foo:\t\t&#125;\t&#125;\tschedule := func() &#123;\t\tfor x := 0; x &lt; threadNum; x++ &#123;\t\t\tgo func() &#123;\t\t\t\tfor &#123;\t\t\t\t\tselect &#123;\t\t\t\t\tcase &lt;-down:\t\t\t\t\t\treturn\t\t\t\t\tcase foo := &lt;-taskQueue:\t\t\t\t\t\tfoo()\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t&#125;()\t\t&#125;\t&#125;\tschedule() // 启动调度器\tcount := &amp;atomic.Int64&#123;&#125;\tfor x := 0; x &lt; 1; x++ &#123;\t\taddTask(func() &#123; // 添加一个任务，循环的塞入任务\t\t\tfor &#123;\t\t\t\taddTask(func() &#123;\t\t\t\t\tcount.Add(1)\t\t\t\t&#125;)\t\t\t&#125;\t\t&#125;)\t&#125;\t// 等待程序结束\tselect &#123;\tcase &lt;-sig:\t\tclose(down)\t\tfmt.Println(&quot;程序退出, exec ctrl+c&quot;)\tcase &lt;-time.After(time.Second):\t\tclose(down)\t\tfmt.Printf(&quot;调用量: %v\\n&quot;, count.Load())\t\treturn\t&#125;&#125;\n\n1、现象1、测试条件，调度器只启动两个线程，然后一个线程主要是负责循环的添加任务，一个线程循环的去执行任务\n➜  go-tool git:(master) ✗ bin/app                         调用量: 5078714➜  go-tool git:(master) ✗ bin/app调用量: 5043506\n\n2、测试条件，调度器启动三个线程，然后两个线程去执行任务，一个添加任务\n➜  go-tool git:(master) ✗ bin/app                         调用量: 4333959➜  go-tool git:(master) ✗ bin/app调用量: 4359804\n\n3、继续测试，启动十个线程，一个添加任务，九个执行任务\n➜  go-tool git:(master) ✗ bin/app                         调用量: 1663691➜  go-tool git:(master) ✗ bin/app调用量: 1692096\n\n4、我们添加一些阻塞的任务\naddTask(func() &#123;  count.Inc()  time.Sleep(time.Second * 2)&#125;)\n\n执行可以看到完全不可用\n➜  go-tool git:(master) ✗ bin/app                            调用量: 9\n\n2、问题​     1、 可以看到随着M的不断的增加，可以发现执行任务的数量也不断的减少，原因是什么呢？有兴趣的同学可以加一个pprof可以看看，其实大量的在等待锁的过程！    \n​      2、如果我的M运行了类似于Sleep操作的方法如何解决了，我的调度器还能支撑这个量级的调度吗？\n关于pprof如何使用：在代码头部加一个这个代码：\nfile, err := os.OpenFile(&quot;/Users/fanhaodong/go/code/go-tool/main/prof.pporf&quot;, os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0644)if err != nil &#123;  panic(err)&#125;if err := pprof.StartCPUProfile(file); err != nil &#123;  panic(err)&#125;defer pprof.StopCPUProfile()\n\n我们查看一下 go tool pprof main/prof.pporf\nShowing top 10 nodes out of 36      flat  flat%   sum%        cum   cum%     2.45s 63.80% 63.80%      2.45s 63.80%  runtime.usleep     0.40s 10.42% 74.22%      0.40s 10.42%  runtime.pthread_cond_wait     0.28s  7.29% 81.51%      0.28s  7.29%  runtime.(*waitq).dequeueSudoG     0.25s  6.51% 88.02%      0.25s  6.51%  runtime.pthread_cond_signal     0.17s  4.43% 92.45%      0.94s 24.48%  main.main.func2.1     0.10s  2.60% 95.05%      0.10s  2.60%  runtime.procyield     0.07s  1.82% 96.88%      0.07s  1.82%  runtime.(*waitq).dequeue     0.03s  0.78% 97.66%      0.03s  0.78%  runtime.madvise     0.02s  0.52% 98.18%      0.99s 25.78%  main.main.func3     0.02s  0.52% 98.70%      1.72s 44.79%  runtime.selectgo\n\n可以看到真正执行代码的时间只有 0.17s  + 0.02s 其他时间都被阻塞掉了！\n3、GPM模型1、GM模型问题1、GM模型中的所有G都是放入到一个queue，那么导致所有的M取执行任务时都会去竞争锁，我们插入G也会去竞争锁，所以解决这种问题一般就是减少对单一资源的竞争，那就是桶化，其实就是每个线程都分配一个队列\n2、GM模型中没有任务状态，只有runnable，假如任务遇到阻塞，完全可以把任务挂起再唤醒\n\n运行队列去存放所有的可以运行的任务，runnable\n所有线程执行运行中的任务，running \n运行中的任务被阻塞的任务，需要放弃运行权利，挂起到等待队列，blocking\n\n2、GPM如何优化GM的（核心）1、引入P​      这里其实会遇到一个问题，假如要分配很多个线程，那么此时随着线程的增加，也会造成队列的增加，其实也会造成调度器的压力，因为它需要遍历全部线程的队列去分配任务以及后续会讲到的窃取任务！\n​      因为我们知道CPU的最大并行度其实取决于CPU的核数，也就是我们没必要为每个线程都去分配一个队列，因为就算是给他们分配了，他们自己去那执行调度，其实也会出现大量阻塞，原因就是CPU调度不过来这些线程！\n​       Go里面是只分配了CPU个数的队列，这里就是P这个概念，你可以理解为P其实是真正的资源分配器，M很轻只是执行程序，所有的资源内存都维护在P上！M只有绑定P才能执行任务（强制的）！\n\n这样做的好处：\n\n如果线程很轻，那么销毁和创建会变得很简单，也就是后面会讲到的内核阻塞调用创建线程\n如果全部资源分配在固定数量的P上，那么可以充分利用CPU并行度\n\n2、GPM调度器1、首先调度程序其实就是调度不同状态的任务，go里面为Go标记了不同的状态，其实大概就是分为：runnable，running，block等，所以如何充分调度不同状态的G成了问题，那么关于阻塞的G如何解决，其实可以很好的解决G调度的问题！\n\n在channel上发送和接收\n网络I/O操作\n阻塞的系统调用\n使用定时器或者Sleep\n使用互斥锁 sync.Mutex\n\n上面这些情况其实就分为：\n\n用户态阻塞\n内核态阻塞但是不会挂起当前线程\n内核态阻塞会挂起当前线程\n\n2、用户态阻塞，一般Go里面依靠gopark 函数去实现，大体的代码逻辑基本上和go的调度绑定死了\n源码在：https://golang.org/src/runtime/proc.go\nfunc gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) &#123;\tif reason != waitReasonSleep &#123;\t\tcheckTimeouts() // timeouts may expire while two goroutines keep the scheduler busy\t&#125;\tmp := acquirem()\tgp := mp.curg\tstatus := readgstatus(gp)\tif status != _Grunning &amp;&amp; status != _Gscanrunning &#123;\t\tthrow(&quot;gopark: bad g status&quot;)\t&#125;\tmp.waitlock = lock\tmp.waitunlockf = unlockf\tgp.waitreason = reason\tmp.waittraceev = traceEv\tmp.waittraceskip = traceskip\treleasem(mp)\t// can&#x27;t do anything that might move the G between Ms here.\tmcall(park_m)&#125;// park continuation on g0.func park_m(gp *g) &#123;\t_g_ := getg()\tif trace.enabled &#123;\t\ttraceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip)\t&#125;\tcasgstatus(gp, _Grunning, _Gwaiting)\tdropg()\tif fn := _g_.m.waitunlockf; fn != nil &#123;\t\tok := fn(gp, _g_.m.waitlock)\t\t_g_.m.waitunlockf = nil\t\t_g_.m.waitlock = nil\t\tif !ok &#123;\t\t\tif trace.enabled &#123;\t\t\t\ttraceGoUnpark(gp, 2)\t\t\t&#125;\t\t\tcasgstatus(gp, _Gwaiting, _Grunnable)\t\t\texecute(gp, true) // Schedule it back, never returns.\t\t&#125;\t&#125;\tschedule() // 调度程序&#125;\n\n\n他会标记当前的g的状态从 running -&gt; waiting 状态\n然后开始执行调度:  schedule()  方法\n首先就是看看有没有其他特殊情况：比如GC或者trace\n其次就是可能先去获取全局队列的(代码里写的偶尔，根据随机性去执行的)\n获取当前g绑定的p队列里获取g\n从其他地方获取可以运行的g (优先级是：从本地队列-&gt;全局队列-&gt;网络轮巡器-&gt;窃取其他P的G，具体可以看 findrunnable 方法)\n最后执行那个唤醒的G\n\n\n最后就是unpark，就是将当前goroutine置于等待状态并解锁锁。 可以通过调用goready方法使goroutine再次运行。\n\n3、其实对于netpool 这种nio模型，其实内核调用是非阻塞的，所以go开辟了一个网络轮训器队列，来存放这些被阻塞的g，等待内核被唤醒！那么什么时候会被唤醒了，其实就是需要等待调度器去调度了！\nn, err := syscall.Read(fd.Sysfd, p)if err != nil &#123;  n = 0  if err == syscall.EAGAIN &amp;&amp; fd.pd.pollable() &#123;    if err = fd.pd.waitRead(fd.isFile); err == nil &#123; // 这里会等待读，其实就是挂起了当前g，也就是主动让出了m      continue    &#125;  &#125;  // 。。。。。。。&#125;\n\n4、如果是内核态阻塞了（内核态阻塞一般都会将线程挂起，线程需要等待被唤醒），我们此时P只能放弃此线程的权利，然后再找一个新的线程去运行P！\n关于着新线程：找有没有idle的线程，没有就会创建一个新的线程！\n关于当内核被唤醒后的操作：因为GPM模型所以需要找到个P绑定，所以G会去尝试找一个可用的P，如果没有可用的P，G会标记为runnable放到全局队列中！\n\n​    关于内核唤醒后G如何执行的代码我没有找到，不好意思，逻辑没有看太清晰！其实疑问点：如何找到可用的P，所以固定数量的P的好处就是查询时间比较可控！为何不找到上一次绑定的P呢？为何切换上下文了！\n\n5、其实了解上面大致其实就了解了Go的基本调度模型\n\nG运行的优先级是啥\nP和M啥时候会接触绑定\nP啥时候会窃取G\n\n答案文章里慢慢品味！\n3、如何防止G长时间占用P如果某个 G 执行时间过长，其他的 G 如何才能被正常的调度？ 这便涉及到有关调度的两个理念：协作式调度与抢占式调度。协作式和抢占式这两个理念解释起来很简单： 协作式调度依靠被调度方主动弃权；抢占式调度则依靠调度器强制将被调度方被动中断。\n1、空转代码例如下面的代码，我本地的版本是go1.13.5\npackage mainimport (\t&quot;fmt&quot;\t&quot;runtime&quot;)func main() &#123;\tgo func() &#123;\t\tfor &#123;\t\t\t&#123;\t\t\t&#125;\t\t&#125;\t&#125;()\truntime.Gosched() // 表示主线程让出当前线程，可以理解为先让go执行\tfmt.Println(&quot;close&quot;)&#125;\n\n2、存在的问题执行: GOMAXPROCS=1 配置全局只能有一个P\n➜  go-tool git:(master) ✗ GODEBUG=schedtrace=1 GOMAXPROCS=1 bin/appSCHED 0ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=0 [2]SCHED 1ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 2ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 4ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 7ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 13ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]\n\n可以看到main函数无法执行!也就是那个go 空转抢占了整个程序\n备注：\n\nGODEBUG=schedtrace=1  表示1ms打印一次\n\nSCHED：调试信息输出标志字符串，代表本行是goroutine scheduler的输出；1ms：即从程序启动到输出这行日志的时间；gomaxprocs: P的数量；idleprocs: 处于idle状态的P的数量；通过gomaxprocs和idleprocs的差值，我们就可知道执行go代码的P的数量；threads: os threads的数量，包含scheduler使用的m数量，加上runtime自用的类似sysmon这样的thread的数量；spinningthreads: 处于自旋状态的os thread数量；idlethread: 处于idle状态的os thread的数量；runqueue=1： go scheduler全局队列中G的数量；[3 4 0 10]: 分别为4个P的local queue中的G的数量。\n\n3、升级1.14+版本解决但是假如我换为用 1.14+版本执行，有兴趣的话可以使用我的docker镜像，直接可以拉取： fanhaodong/golang:1.15.11 和  fanhaodong/golang:1.13.5\n[root@647af84b3319 code]# GODEBUG=schedtrace=1 GOMAXPROCS=1 bin/appSCHED 0ms: gomaxprocs=1 idleprocs=0 threads=2 spinningthreads=0 idlethreads=0 runqueue=0 [0]SCHED 1ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=0 [0]SCHED 2ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=0 [0]SCHED 3ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 4ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 5ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 6ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 7ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 8ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 10ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]SCHED 13ms: gomaxprocs=1 idleprocs=0 threads=3 spinningthreads=0 idlethreads=1 runqueue=1 [1]close\n\n4、关于G上内存分配的问题首先我们知道G/M/P，G可能和M也可能和P解除绑定，那么关于数据变量放在哪哇！其实这个就是逃逸分析！\n1、什么情况下会逃逸package maintype Demo struct &#123;\tMain string&#125;func main() &#123;\tgo func() &#123;\t\tdemo := Demo&#123;&#125;\t\tgo func() &#123;\t\t\ttest(demo)\t\t&#125;()\t&#125;()&#125;func test(demo Demo) &#123;&#125;\n\n输出可以看到其实没有发生逃逸，那是因为 demo被拷贝它自己的栈空间内\n[root@647af84b3319 code]#  go build -gcflags &quot;-N -l -m&quot; -o bin/app deno/main2.go# command-line-argumentsdeno/main2.go:13:11: demo does not escapedeno/main2.go:6:5: func literal escapes to heapdeno/main2.go:8:6: func literal escapes to heap\n\n备注：\n -gcflags &quot;-N -l -m&quot; 其中 -N 禁用优化 -l禁止内联优化，-m打印逃逸信息\n那么继续改成这个\npackage maintype Demo struct &#123;\tMain string&#125;func main() &#123;\tgo func() &#123;\t\tdemo := Demo&#123;&#125;\t\tgo func() &#123;\t\t\ttest(&amp;demo)\t\t&#125;()\t&#125;()&#125;func test(demo *Demo) &#123;&#125;\n\n可以看到发现 demo对象其实被逃逸到了堆上！这就是不会出现类似于G如果被别的M执行，其实不会出现内存分配位置的问题！\n[root@647af84b3319 code]#  go build -gcflags &quot;-N -l -m&quot; -o bin/app deno/main2.go# command-line-argumentsdeno/main2.go:13:11: demo does not escapedeno/main2.go:7:3: moved to heap: demodeno/main2.go:6:5: func literal escapes to heapdeno/main2.go:8:6: func literal escapes to heap\n\n2、for循环中申明g内存引用问题所以可以看到demo其实是copy到了堆上！这就是g逃逸的问题，和for循环一样的\nfunc main() &#123;\tfor x := 0; x &lt; 10; x++ &#123;\t\tgo func() &#123;\t\t\tfmt.Println(x)\t\t&#125;()\t&#125;&#125;\n\n执行可以发现，其实x已经逃逸到了堆上，所以你所有的g都引用的一个对象，如何解决了\n➜  go-tool git:(master) ✗ go build -gcflags &quot;-l -m&quot; -o bin/app deno/main2.go# command-line-argumentsdeno/main2.go:10:6: moved to heap: xdeno/main2.go:11:6: func literal escapes to heapdeno/main2.go:12:15: main.func1 ... argument does not escapedeno/main2.go:12:15: x escapes to heapdeno/main2.go:16:11: test demo does not escape\n\n如何解决了，其实很简单\n\n直接copy一份数据\n\nfor x := 0; x &lt; 10; x++ &#123;  x := x // clone  go func() &#123;    fmt.Println(x)  &#125;()&#125;\n\n\n通过参数传递(推荐)\n\nfor x := 0; x &lt; 10; x++ &#123;go func(x int) &#123;  fmt.Println(x)&#125;(x)&#125;\n\n参考文章也谈goroutine调度器\n图解Go运行时调度器\nGo语言回顾：从Go 1.0到Go 1.13\nGo语言原本\n调度系统设计精要\nScalable Go Scheduler Design Doc\n","categories":["Golang"],"tags":["Golang","调度器"]},{"title":"Go的runtime.SetFinalizer函数介绍","url":"/2022/02/28/f2436dad6e7955374f33b91fcf1ddca0/","content":"​      业务中我们经常遇到需要进行手动回收的操作，虽然Go提供了defer操作可以用来手动回收，但是有些时候确实会出现一些case用户忘记手动回收，并且大量内存泄漏或者goroutine泄口的问题，而且只能通过线上工具进行事后定位！本文介绍一下 runtime.SetFinalizer 来解决对象回收释放资源的问题！本文只是根据简单的例子进行阐述，例子选择不一定的好！\n\n\n介绍\nruntime.SetFinalizer 是Go提供对象被GC回收时的一个注册函数，可以在对象被回收的时候回掉函数\n此方法类似于JAVA的finalize 方法和C++的析构函数！\n当存在多层引用时，类似于A-&gt;B-&gt;C 这种关系的时候，是如何解决呢？\nGo函数内部原理介绍\n\nfunc SetFinalizer(obj interface&#123;&#125;, finalizer interface&#123;&#125;) &#123;    ....  // 对象的低5位是对象类型，这里检测一下是否是指针类型\tif etyp.kind&amp;kindMask != kindPtr &#123;\t\tthrow(&quot;runtime.SetFinalizer: first argument is &quot; + etyp.string() + &quot;, not pointer&quot;)\t&#125;  // 第二个参数必须是函数\tif ftyp.kind&amp;kindMask != kindFunc &#123;\t\tthrow(&quot;runtime.SetFinalizer: second argument is &quot; + ftyp.string() + &quot;, not a function&quot;)\t&#125;   //\t// make sure we have a finalizer goroutine\tcreatefing()      // finally add finalizer\tsystemstack(func() &#123;\t\tif !addfinalizer(e.data, (*funcval)(f.data), nret, fint, ot) &#123;\t\t\tthrow(&quot;runtime.SetFinalizer: finalizer already set&quot;)\t\t&#125;\t&#125;)&#125;// 最后启动调度池子，也就是只有一个G去回收整个应用程序的finalize函数!func createfing() &#123;\t// start the finalizer goroutine exactly once\tif fingCreate == 0 &amp;&amp; atomic.Cas(&amp;fingCreate, 0, 1) &#123;\t\tgo runfinq()\t&#125;&#125;// 1. addfinalizer 就是给对象的指针指向的内存加了个特殊标记！此标记此对象是finalizer对象，内部实现就是拿到对象的span，然后span里面有个链表维护对象的特殊标记！// 2. runfinq 函数，就是遍历一个队列，然后回收队列中的对象，一个死循环罢了！如果没有等待回收的对象，就park住// 3. 每次当GC sweep 阶段，会先标记，然后第二次GC才要被回收（清理）！具体逻辑可以看mspan#sweep\n\n简单使用package mainimport (\t&quot;fmt&quot;\t&quot;runtime&quot;\t&quot;time&quot;)type object intfunc (o object) Ptr() *object &#123;\treturn &amp;o&#125;var (\tcacheData = make(map[string]*object, 1024))func deleteData(key string) &#123;\tdelete(cacheData, key)&#125;func setData(key string, v object) &#123;\tdata := v.Ptr()\truntime.SetFinalizer(data, func(data *object) &#123;\t\tfmt.Printf(&quot;runtime invoke Finalizer data: %d, time: %s\\n&quot;, *data, time.Now().Format(&quot;15:04:05.000&quot;))\t\ttime.Sleep(time.Second)\t&#125;)\tcacheData[key] = data&#125;func main() &#123;\tsetData(&quot;key1&quot;, 1)\tsetData(&quot;key2&quot;, 2)\tsetData(&quot;key3&quot;, 3)\tdeleteData(&quot;key1&quot;)\tdeleteData(&quot;key2&quot;)\tdeleteData(&quot;key3&quot;)\tfor x := 0; x &lt; 5; x++ &#123;\t\tfmt.Println(&quot;invoke runtime.GC()&quot;)\t\truntime.GC()\t\ttime.Sleep(time.Second)\t&#125;&#125;// output://invoke runtime.GC()//runtime invoke Finalizer data: 1, time: 23:44:49.013//invoke runtime.GC()//runtime invoke Finalizer data: 3, time: 23:44:50.019//invoke runtime.GC()//runtime invoke Finalizer data: 2, time: 23:44:51.020//invoke runtime.GC()//invoke runtime.GC()\n\n\n并没有看出第二次才会GC掉，可能是系统在delele过程中触发过一次GC\n可以看到GC后调用Finalizer 函数是串行执行的！\n\n日常使用注意点\nGC注册的Finalizer函数执行时间不适合过长！\nFinalizer 函数返回结果是系统会忽略，所以你返回error也无所谓，但是切记不可以panic，程序是无法recover的！\n如果对象在Finalizer函数再次被引用，是不会被再次回收调用Finalizer函数的！\n当存在 A-&gt;B-&gt;C 的引用时，回收顺序是引用顺序，当回收A后，然后再回收B，然后再回收C，应该没啥问题吧\n如果你对象被goroutine 引用而分配到堆上，goroutine 又没办法关闭，导致你需要包装一层对象进行回收！例如下列例子，导致业务函数结束后忘记了Close，导致G泄漏，虽然注册了Finalizer函数，但是没有被回收！我就犯过这样的错误，不过在写测试用例的时候就发现了！！\n\ntype cacheData struct &#123;\tname     string\tdataLock sync.RWMutex\tdata     map[string]interface&#123;&#125;\treporter func(data *cacheData)\tcloseOnce sync.Once\tdone      chan struct&#123;&#125;&#125;func NewCacheData(name string) *cacheData &#123;\tdata := &amp;cacheData&#123;\t\tname: name,\t\tdata: map[string]interface&#123;&#125;&#123;&#125;,\t\treporter: func(data *cacheData) &#123;\t\t\tlog.Println(&quot;reporter&quot;)\t\t&#125;,\t\tdone: make(chan struct&#123;&#125;, 0),\t&#125;\tdata.init()\truntime.SetFinalizer(data, (*cacheData).Close)\treturn data&#125;// init 注册reporter函数，比如上报一些缓存的信息func (c *cacheData) init() &#123;\tgo func() &#123;\t\tc.reporter(c)\t\tt := time.NewTicker(time.Second)\t\tfor &#123;\t\t\tselect &#123;\t\t\tcase &lt;-c.done:\t\t\t\tt.Stop()\t\t\t\treturn\t\t\tcase &lt;-t.C:\t\t\t\tc.reporter(c)\t\t\t&#125;\t\t&#125;\t&#125;()&#125;// Close 函数主要是防止goroutine泄漏func (c *cacheData) Close() &#123;\tc.closeOnce.Do(func() &#123;\t\tclose(c.done)\t&#125;)&#125;func BizFunc() &#123;\tcache := NewCacheData(&quot;test&quot;)\tcache.Set(&quot;k1&quot;, &quot;v1&quot;)\t// biz ....\t// 但是忘记关闭cache了，或者等等的没有close，导致G泄漏&#125;func main() &#123;\tBizFunc()\tfor x := 0; x &lt; 10; x++ &#123;\t\truntime.GC()\t\tlog.Println(&quot;runtime.GC&quot;)\t\ttime.Sleep(time.Second)\t&#125;&#125;\n\n如何解决了？？ 可以看 NewSafeCacheData\npackage mainimport (\t&quot;log&quot;\t&quot;runtime&quot;\t&quot;sync&quot;\t&quot;time&quot;)func init() &#123;\tlog.SetFlags(log.Ltime)&#125;func (c *cacheData) Set(key string, v interface&#123;&#125;) &#123;\tc.dataLock.Lock()\tdefer c.dataLock.Unlock()\tc.data[key] = v&#125;type CacheData struct &#123;\t*cacheData&#125;type cacheData struct &#123;\tname     string\tdataLock sync.RWMutex\tdata     map[string]interface&#123;&#125;\treporter func(data *cacheData)\tcloseOnce sync.Once\tdone      chan struct&#123;&#125;&#125;func NewCacheData(name string) *cacheData &#123;\tdata := &amp;cacheData&#123;\t\tname: name,\t\tdata: map[string]interface&#123;&#125;&#123;&#125;,\t\treporter: func(data *cacheData) &#123;\t\t\tlog.Println(&quot;reporter&quot;)\t\t&#125;,\t\tdone: make(chan struct&#123;&#125;, 0),\t&#125;\treturn data&#125;// NewSafeCacheData 安全的函数func NewSafeCacheData(name string) *CacheData &#123;\tdata := NewCacheData(name)\tdata.init()\tresult := &amp;CacheData&#123;\t\tcacheData: data,\t&#125;\truntime.SetFinalizer(result, (*CacheData).Close)\treturn result&#125;// init 注册reporter函数，比如上报一些缓存的信息func (c *cacheData) init() &#123;\tgo func() &#123;\t\tc.reporter(c)\t\tt := time.NewTicker(time.Second)\t\tfor &#123;\t\t\tselect &#123;\t\t\tcase &lt;-c.done:\t\t\t\tt.Stop()\t\t\t\treturn\t\t\tcase &lt;-t.C:\t\t\t\tc.reporter(c)\t\t\t&#125;\t\t&#125;\t&#125;()&#125;// Close 函数主要是防止goroutine泄漏func (c *cacheData) Close() &#123;\tc.closeOnce.Do(func() &#123;\t\tclose(c.done)\t&#125;)&#125;func BizFunc() &#123;\tcache := NewSafeCacheData(&quot;test&quot;)\tcache.Set(&quot;k1&quot;, &quot;v1&quot;)\t// biz ....\t// 但是忘记关闭cache了，或者等等的没有close，导致G泄漏&#125;func main() &#123;\tBizFunc()\tfor x := 0; x &lt; 10; x++ &#123;\t\truntime.GC()\t\tlog.Println(&quot;runtime.GC&quot;)\t\ttime.Sleep(time.Second)\t&#125;&#125;\n\n","categories":["Golang"],"tags":["Golang"]},{"title":"接口mock平台","url":"/2021/03/02/f86786a14802b2f17d560d87387e8690/","content":"​        接口Mock平台主要实践在项目的开发团队太多，业务需要对接各个下层服务，而下层服务提供的API时间线的偏差，往往需要Mock接口提供给需求方(前端)，进行联调，提高交付质量。最后再由我们去对接下层服务来保证交付质量，同时下层服务也需要提供mock来格式化响应参数，但是往往省略这部分工作导致接口文档可用性太低。\n\n\n1、Yapi\n由去哪儿网大前端技术中心 开源的项目\n官方文档：https://hellosean1025.github.io/yapi/documents/index.html\ngithub：https://github.com/ymfe/yapi\n\n1、界面介绍：\n​     请求 Mock 数据时，规则匹配优先级：Mock 期望 &gt; 自定义 Mock 脚本 &gt; 项目全局 mock 脚本 &gt; 普通 Mock。如果前面匹配到 Mock 数据，后面 Mock 则不返回。\n\n1、预览界面\n​    大概介绍，无其他用处，唯一用处就是接口Mock\n\n\n2、编辑界面功能 (优先级 level-3)1、特点这个是数据Mock，支持基本的语法，这个语法来自于 Mock数据占位符定义规范 DPD , 他支持调用 Mock.Random 的任何方法，比如调用 Random.datetime(&#39;yy-MM-dd a HH:mm:ss&#39;), 你只需要写 @data(&#39;yy-MM-dd a HH:mm:ss&#39;) 即可\n2、适用场景\n比较适用于请求参数的Mock\n响应字段不复杂，没有复杂的数组结构，不需要定制化处理\n\n\n3、运行页面1、特点\n支持多种环境的支持\n\n\n\n支持测试mock接口\n支持调试大部分环境\n\n\n2、适用场景\n接口调试（但是无历史记录，这个比较坑）\n和配置进行比较\n\n4、高级Mock-期望 (优先级最高-level 1)1、特点可以对于数据的响应进行期望值设定，完全支持 Mock.js 的语法，语法文档: http://mockjs.com/examples.html\n2、适用场景\n对于数据mock需要定制化处理的，比如我们需要将list进行指定mock\n但是它不适合对于数据进行脚本处理，比如要对于请求参数进行校验等等\n可以对于响应时长进行mock\n可以对于\n\n例子：\n&#123;  &quot;code&quot;: 0,  &quot;message&quot;: &quot;success&quot;,  &quot;data&quot;: &#123;    &quot;list|40-50&quot;: [      &#123;        &quot;worker_name&quot;: &quot;@cname&quot;,        &quot;id&quot;: &quot;@integer(0)&quot;,        &quot;create_time&quot;: &quot;@date(&#x27;yyyy-MM-dd HH-mm-ss&#x27;)&quot;,        &quot;status&quot;: &quot;@integer(1,4)&quot;,        &quot;discover_place&quot;: &quot;@city&quot;      &#125;    ],    &quot;nums_list&quot;: [      &#123;        &quot;status&quot;: 1,        &quot;num&quot;: &quot;@integer(1,1000)&quot;      &#125;,      &#123;        &quot;status&quot;: 2,        &quot;num&quot;: &quot;@integer(1,1000)&quot;      &#125;,      &#123;        &quot;status&quot;: 3,        &quot;num&quot;: &quot;@integer(1,1000)&quot;      &#125;,      &#123;        &quot;status&quot;: 3,        &quot;num&quot;: &quot;@integer(1,1000)&quot;      &#125;    ],    &quot;page_index&quot;: 1,    &quot;page_size&quot;: 10,    &quot;total_count&quot;: 50,    &quot;is_more&quot;: 1  &#125;&#125;\n\n\n5、高级Mock - 脚本 （优先级 level-2）1、特点脚本带来的强大功能，可以各种定制化处理，比如说请求参数，比如说请求头等等，比如说各种逻辑判断\n请求\n\nheader 请求的 HTTP 头\nparams 请求参数，包括 Body、Query 中所有参数\ncookie 请求带的 Cookies\n\n响应\n\nmockJson 接口定义的响应数据 Mock 模板\nresHeader 响应的 HTTP 头\nhttpCode 响应的 HTTP 状态码\ndelay Mock 响应延时，单位为 ms\nRandom Mock.Random 方法，可以添加自定义占位符,详细使用方法请查看 Wiki\n\n2、使用场景\n响应结果需要对于请求参数有依赖的\n\ndemo\nlet data=[]for (let x =0 ; x&lt;100;x++)&#123;    data[x]=&#123;        name:Random.string(),    &#125;&#125;mockJson=&#123;    list: data&#125;\n\n\n2、语法介绍英文（中文前缀为c，例如cfirst）名字：Random.first()\n英文性：Random.last()\n全名字：Random.name()\n随机的时间搓(ms)：Random.datetime(‘T’)\n随机日期：Random.datetime(‘yyyy-MM-dd  HH:mm:ss’)\n随机时间：Random.now(‘yyyy-MM-dd HH:mm:ss’)\n随机文本：Random.csentence(length)\n随机的http-url： Random.url(‘http’, ‘nuysoft.com’)\n随机的ip： Random.ip()\n随机的email： Random.email(‘nuysoft.com’) ，Random.email()\n随机的地址： 随机城市：Random.city(true) 随机县城：Random.county(true) 随机省份：Random.province()\nUUID： Random.guid()\n随机身份证：Random.id()\n随机数：Random.range(1, 10, 2)\n随机英文串串：Random.string( 5 )\n随机bool：Random.bool()\n","categories":["API"],"tags":["yapi","mock"]}]