<!DOCTYPE html>
<html lang="en">
<head>
	<link rel="shortcut icon"href="https://anthony-dong.github.io/favicon.ico"type="image/x-icon"/><meta name="viewport"content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"/><meta name="apple-mobile-web-app-capable"content="yes"/><meta name="apple-mobile-web-app-status-bar-style"content="black"/><meta name="format-detection"content="telephone=no"/><meta name="renderer"content="webkit"/><meta name="description"content="Anthony-Dong的个人博客"/><meta charset="UTF-8"/><title>快速入门 Kafka (Java客户端版本) | Anthony-Dong</title><link href="https://anthony-dong.github.io/styles/main.css"type="text/css"rel="stylesheet"/><script src="https://anthony-dong.github.io/media/js/magnify.min.js"></script>
	<link rel="canonical" href="https://anthony-dong.github.io/post/ZW64Jh2NE/" />
</head>
<body>
	<div class="progress"></div><style>.progress{background:linear-gradient(to right,#87ceeb var(--scroll),transparent 0);background-repeat:no-repeat;position:fixed;width:100%;height:4px;z-index:1}</style><div class="darkmode-background"></div><div class="darkmode-layer"></div>
<noscript><p class="warn" >本页面需要浏览器支持（启用）JavaScript</p></noscript><div class="header"><div class="logo_title"><div class="title animated fadeInDown"><a href="https://anthony-dong.github.io"><img alt="logo" style="display:inline-block;" src="https://anthony-dong.github.io/images/avatar.png"/></a><h1 title="Anthony-Dong" class="weaklink shift"><a  href="/">Anthony-Dong</a></h1>

<div class="navbar weaklink">
<div class="normal_nav">
<div class="bitcron_nav_container"><div class="bitcron_nav"><div class="bitcron_nav"><div style="display:flex;justify-content:center;"><nav class="mixed_site_nav_wrap site_nav_wrap"><ul class="mixed_site_nav site_nav sm sm-base">	<li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/" class="selected active current nav__item" >首页</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/archives" class="selected active current nav__item" >归档</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/tags" class="selected active current nav__item" >标签</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/about" class="selected active current nav__item" >关于</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/link" class="selected active current nav__item" >友链</a></li></ul></nav>
<div style="float:right;margin-top:1em"><form id="gridea-search-form" data-update="1578893743252" action="/search/index.html"><input class="search-input" autocomplete="off" spellcheck="false" name="q" placeholder="Search..."></form></div>
<div style="margin-left:0.5em;margin-top:1.2em"><input id="switch_default" onclick="mobileBtn()" type="checkbox" class="switch_default"><label for="switch_default" class="toggleBtn"></label></div></div>
<div class="clear clear_nav_inline_end"></div></div></div><div class="clear clear_nav_end"></div></div></div><div class="hamberger" href="javascript:void(0)" onclick="btn_toggle();"><i class="iconfont icon-category"></i></div></div></div></div>
<div id="hn" class="no-js hidden_nav animated fadeInDown"><div class="bitcron_nav_container"><div class="bitcron_nav"><nav class="mixed_site_nav_wrap site_nav_wrap"><ul class="mixed_site_nav site_nav sm sm-base">	<li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/" class="selected active current nav__item" >首页</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/archives" class="selected active current nav__item" >归档</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/tags" class="selected active current nav__item" >标签</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/about" class="selected active current nav__item" >关于</a></li><li><a id="d2ef19af68cc211e98f8a0242ac110003" href="/post/link" class="selected active current nav__item" >友链</a></li></ul><div class="clear clear_nav_inline_end"></div></nav></div><div class="clear clear_nav_end"></div></div>
<div style="display:flex;justify-content:center;inline-block;text-align:center;margin-top:7%"><div><form id="gridea-search-form-1" data-update="1614223299317" action="/search/index.html"><input class="search-input" autocomplete="off" spellcheck="false" name="q"  placeholder="Search..." /></form></div><div style="margin-left:0.5em"><input id="switch_default_h" onclick="mobileBtn()" type="checkbox" class="switch_default"><label for="switch_default" class="toggleBtn"></label></div></div>
</div></div>
<script>function enableDarkmode(){document.body.classList.add("darkmode"),document.getElementById("switch_default").checked=1,document.getElementById("switch_default_h").checked=1}function removeDarkmode(){document.body.classList.remove("darkmode"),document.getElementById("switch_default").checked=0,document.getElementById("switch_default_h").checked=0}function getCookie(a){var b,c=new RegExp("(^| )"+a+"=([^;]*)(;|$)");return(b=document.cookie.match(c))?unescape(b[2]):null}cookie=getCookie("darkmode"),"enable"==cookie&&enableDarkmode(),window.matchMedia("(prefers-color-scheme: dark)").matches&&"disable"!==cookie&&(enableDarkmode(),document.cookie="darkmode=enable; path=/");var mobileBtn=function(){1==document.getElementById("switch_default").checked?(enableDarkmode(),document.cookie="darkmode=enable; path=/"):(removeDarkmode(),document.cookie="darkmode=disable; path=/")};</script>

	<div class="main">
		<div class="main-inner">
			<div class="content">
				<article class="post">
					<script src='https://anthony-dong.github.io/media/js/Valine.min.js'></script><style>.v .vlist .vcard .vh .vmeta .vat{font-size:.8125em;color:#9d7873;cursor:pointer;float:right}.v .vlist .vcard .vhead .vsys{display:none}</style ><script type="text/javascript">new Valine(ValineInfo)</script>
					<h2 class="post_title sm_margin"><a>快速入门 Kafka (Java客户端版本)</a></h2>
					<script>
						function lan() {
							if (document.getElementById("lan").innerText == "繁") {
								var s = document.getElementById("tongwenlet_cn");
								if (s != null) {
									document.body.removeChild(s)
								}
								var s = document.createElement("script");
								s.language = "javascript";
								s.type = "text/javascript";
								s.src = "https://cdn.jsdelivr.net/gh/qyxtim/Static@1.1/bookmarklet_tw.js";
								s.id = "tongwenlet_cn";
								document.body.appendChild(s);
								document.getElementById("lan").innerHTML = "简"
							} else {
								if (document.getElementById("lan").innerText == "簡") {
									var s = document.getElementById("tongwenlet_cn");
									if (s != null) {
										document.body.removeChild(s)
									}
									var s = document.createElement("script");
									s.language = "javascript";
									s.type = "text/javascript";
									s.src = "https://cdn.jsdelivr.net/gh/qyxtim/Static@1.1/bookmarklet_cn.js";
									s.id = "tongwenlet_cn";
									document.body.appendChild(s);
									document.getElementById("lan").innerHTML = "繁"
								}
							}
						};
					</script>
					<section class="post_details"><i class="iconfont icon-calendar"></i><span style="margin-right:15px">
							2020-02-29</span><i class="iconfont icon-browse"></i>
							<span class="leancloud_visitors" style="margin-right:15px" id="/post/ZW64Jh2NE/">views <i class="leancloud-visitors-count" style="font-style: normal"></i></span>
							<span class="weaklink" style="margin-right:15px"><i class="iconfont icon-category"></i> <a
								href="https://anthony-dong.github.io/tag/L7uvsRrdmkM/"
								class="tag">Kafka</a></span><i class="iconfont icon-caret-down"></i><span
							style="margin-right:15px">4420字</span><i
							class="iconfont icon-naozhong"></i><span
							style="margin-right:15px">21 min read</span><a id="lan"
							href="javascript:void(0);" onclick="lan();" title="调整简繁体" style="margin-right:15px;">繁</a>
						</section>

						<div style="display:flex">
							<div class="md_block" id="md_block">
								<div class="round-shape-one"></div>
								<blockquote>
<p>​	官网 :  <a href="http://kafka.apachecn.org/documentation.html">http://kafka.apachecn.org/documentation.html</a>  开始学习吧.</p>
</blockquote>
<p>先启动zk , 然后启动kafka .就行了, 安装不做介绍了, 都是简单修改下配置就行了. 相信都会. 不过我担忧下载的网速(真的坑,先下载不懂,所以我找了个老版本).  前提环境就是有Java环境就可以了.</p>
<p>kafka版本号 前面部分是scala版本,后面部分是kafka版本, 我是用的是<code>0.11.0.3</code> 版本, 所以客户端最好跟着一致.</p>
<pre><code class="language-java">[admin@hadoop1 kafka]$ ll
total 0
drwxr-xr-x 7 admin admin 94 Nov 10 06:18 kafka_2.11-0.11.0.3
</code></pre>
<p>启动命令 :</p>
<pre><code class="language-java">// 1. 测试环境推荐, 可以实时看日志报错.
./kafka-server-start.sh ../config/server.properties

// 2.线上推荐, 后台模式
./kafka-server-start.sh -daemon ../config/server.properties
</code></pre>
<h2 id="快速开始">快速开始</h2>
<blockquote>
<p>​	最好加入日志框架, 让后放入配置文件, 看日志很重要.</p>
</blockquote>
<pre><code class="language-xml">&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
        &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
        &lt;version&gt;0.11.0.3&lt;/version&gt;
    &lt;/dependency&gt;
	// LOG4J 配置...
&lt;/dependencies&gt;
</code></pre>
<p>服务器端,</p>
<p><code>org.apache.kafka.clients.CommonClientConfigs</code>    下面就是客户端/服务器的通用配置</p>
<p><code>org.apache.kafka.clients.producer.ProducerConfig</code>  是生产者的配置信息.</p>
<p><code>org.apache.kafka.clients.consumer.ConsumerConfig</code>  是消费者配置.</p>
<p><code>org.apache.kafka.common.config.TopicConfig</code> 是topic的通用配置信息.</p>
<p><code>org.apache.kafka.common.config.SslConfigs</code>  SSL配置</p>
<p>这些配置信息都是 _Config表示的配置的key , _Doc表示解释. 我表示不理解为啥呢. 哈哈哈不浪费内存吗</p>
<p>一般只是用 <code>ConsumerConfig</code>  和 <code>ProducerConfig</code> 足矣了.</p>
<p>配置太多. 但是有个技巧. 我这里写了个程序反射获取他的成员变量. 然后可以输出他的配置信息.</p>
<pre><code class="language-java">Field field = ConsumerConfig.class.getDeclaredField(&quot;CONFIG&quot;);
field.setAccessible(true);
ConfigDef def = (ConfigDef) field.get(null);
String htmlTable = def.toHtmlTable();
FileOutputStream stream = new FileOutputStream(&quot;consumer.html&quot;);
stream.write(htmlTable.getBytes());
stream.close();
</code></pre>
<p>如果配置不懂的这个官方网站也可以看  <a href="http://kafka.apachecn.org/documentation.html#producerconfigs">http://kafka.apachecn.org/documentation.html#producerconfigs</a></p>
<p>基本就是文档了.,很详细./  那么开始吧.</p>
<p>服务端代码:</p>
<pre><code class="language-java">public class Producer {

    public static void main(String[] args) {
         final String url = &quot;hadoop1:9092&quot;;
		final String topic = &quot;topic-1&quot;;
        // 配置.
        HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;();

        // 连接地址
        config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, url);

        // ACK
        config.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);
        // 相应超时.
        config.put(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG, 5000);

        // 缓冲区大小. (发送给服务器的)
        config.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 1024 * 1024 * 10);
        // 每次最多发10K
        config.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 1024 * 10);
        // 不重试,有些非幂等性可以.
        config.put(ProducerConfig.RETRIES_CONFIG, 0);

        // snappy 压缩..
        config.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, &quot;snappy&quot;);

        // 序列化
        config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);

        // ok了.
        KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(config);
        IntStream.range(0, 10).forEach(value -&gt; {
            // 发送
            producer.send(new ProducerRecord&lt;&gt;(topic, &quot;cur-time&quot;, String.format(&quot;id: %d, time : %d.&quot;, value, System.currentTimeMillis())), (metadata, exception) -&gt; {
                
            });
        });
        // 最后记得刷新出去.
        producer.flush();
    }
}
</code></pre>
<p>消费端 :</p>
<pre><code class="language-java">public class Consumer {

    public static void main(String[] args) {

        final String topic = &quot;topic-1&quot;;
        final String group = &quot;consumer-1&quot;;
        final String url = &quot;hadoop1:9092&quot;;

        HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;();
        config.put(ConsumerConfig.GROUP_ID_CONFIG, group);
        config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, url);
        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);
        config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
        config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(config);
        consumer.subscribe(Collections.singletonList(topic));
        while (true) {
            ConsumerRecords&lt;String, String&gt; poll = consumer.poll(500);
            poll.forEach(record -&gt;
                    System.out.println(String.format(&quot;topic: %s, key: %s, value: %s, offset:%d.&quot;,
                            record.topic(), record.key(), record.value(), record.offset())));
            // 提交偏移量.
            consumer.commitSync();
        }
    }
}
</code></pre>
<p>结果 :  消费端输出:</p>
<pre><code class="language-java">topic: topic-1, key: cur-time, value: id: 0, time : 1582971209662., offset:0.
topic: topic-1, key: cur-time, value: id: 1, time : 1582971209859., offset:1.
topic: topic-1, key: cur-time, value: id: 2, time : 1582971209859., offset:2.
topic: topic-1, key: cur-time, value: id: 3, time : 1582971209859., offset:3.
topic: topic-1, key: cur-time, value: id: 4, time : 1582971209859., offset:4.
topic: topic-1, key: cur-time, value: id: 5, time : 1582971209859., offset:5.
topic: topic-1, key: cur-time, value: id: 6, time : 1582971209860., offset:6.
topic: topic-1, key: cur-time, value: id: 7, time : 1582971209860., offset:7.
topic: topic-1, key: cur-time, value: id: 8, time : 1582971209866., offset:8.
topic: topic-1, key: cur-time, value: id: 9, time : 1582971209867., offset:9.
</code></pre>
<p>我们可以发现kafka的偏移量是从0开始的.</p>
<p>我们发现服务端日志:</p>
<pre><code class="language-java">// 先去创建一个topic,去zk中.
[2020-03-01 02:10:26,840] INFO Topic creation {&quot;version&quot;:1,&quot;partitions&quot;:{&quot;0&quot;:[0]}} (kafka.admin.AdminUtils$)
[2020-03-01 02:10:26,845] INFO [KafkaApi-0] Auto creation of topic topic-1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-01 02:10:26,891] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions topic-1-0 (kafka.server.ReplicaFetcherManager)
[2020-03-01 02:10:26,896] INFO Loading producer state from offset 0 for partition topic-1-0 with message format version 2 (kafka.log.Log)
// 创建日志文件.分区号是0
[2020-03-01 02:10:26,896] INFO Completed load of log topic-1-0 with 1 log segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-01 02:10:26,897] INFO Created log for partition [topic-1,0] in /home/admin/kafka/kafka_2.11-0.11.0.3/logs with properties {compression.type -&gt; producer, message.format.version -&gt; 0.11.0-IV2, file.delete.delay.ms -&gt; 60000, max.message.bytes -&gt; 1000012, min.compaction.lag.ms -&gt; 0, message.timestamp.type -&gt; CreateTime, min.insync.replicas -&gt; 1, segment.jitter.ms -&gt; 0, preallocate -&gt; false, min.cleanable.dirty.ratio -&gt; 0.5, index.interval.bytes -&gt; 4096, unclean.leader.election.enable -&gt; false, retention.bytes -&gt; -1, delete.retention.ms -&gt; 86400000, cleanup.policy -&gt; [delete], flush.ms -&gt; 9223372036854775807, segment.ms -&gt; 604800000, segment.bytes -&gt; 1073741824, retention.ms -&gt; 604800000, message.timestamp.difference.max.ms -&gt; 9223372036854775807, segment.index.bytes -&gt; 10485760, flush.messages -&gt; 9223372036854775807}. (kafka.log.LogManager)
    
    
// 消费者推出
[2020-03-01 02:12:03,532] INFO [GroupCoordinator 0]: Member consumer-1-f17da2c9-71ad-4035-b366-76bdebba5951 in group consumer-1 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)    
</code></pre>
<h2 id="topic">topic</h2>
<p>topic的概念就是最小的主题单位, 不能比他在小了. 最起码也要有一个topic.  是消费的最小主题. 如果你学过RocketMQ那么他可能还有很多方式.</p>
<p>我们要知道kafka是一个读写均衡的中间件, 所以他所做的  将top分区处理, 让</p>
<h2 id="组分区-究竟做什么">组/分区 究竟做什么</h2>
<p>我们继续测试. 我们将服务器端不断发送.</p>
<p>此时客户端同时有两个客户端再一个组内. 就是都是 <code>consumer-1</code></p>
<p>此时发现只有最先接入的那个组可以收到消息, 第二个不可以,  当第一个客户端退出的时候, 第二个客户端才去消费.</p>
<p>我这里有一张图 :</p>
<p>客户端二先去消费去了. 然后挂掉了.</p>
<figure data-type="image" tabindex="1"><img src="https://tyut.oss-accelerate.aliyuncs.com/image/2020-20-22/8b645a15-a457-4603-97e8-9fc4238c43eb.png?x-oss-process=style/template01" alt="" loading="lazy"></figure>
<p>客户端一此时就终于可以收到消息了.</p>
<figure data-type="image" tabindex="2"><img src="https://tyut.oss-accelerate.aliyuncs.com/image/2020-20-22/1463f5ff-0af8-459f-bf9e-130b42cf44fe.png?x-oss-process=style/template01" alt="" loading="lazy"></figure>
<p>此时我们发现客户端2成功拉去到了 397.</p>
<p>服务器日志是 :</p>
<pre><code class="language-java">[2020-03-01 02:13:41,787] INFO [GroupCoordinator 0]: Preparing to rebalance group consumer-1 with old generation 4 (__consumer_offsets-6) (kafka.coordinator.group.GroupCoordinator)
</code></pre>
<p>我们发现一个组内,是不可以同时消费的, 而且他限制组内只允许一个人访问.</p>
<p><strong>kafka会帮助我们记住这个组的偏移量, 以组名字做区分, 所以一个新的组, 必须最开始开始读, 不能设置为&quot;null&quot;</strong></p>
<h3 id="偏移量">偏移量</h3>
<pre><code class="language-java">long offset = producer.send(new ProducerRecord&lt;&gt;(&quot;topic-1&quot;, &quot;cur-time&quot;, String.format(&quot;id: %d, time : %d.&quot;, value, System.currentTimeMillis())), (metadata, exception) -&gt; {
}).get().offset();
logger.info(&quot;偏移量 : {}&quot;, offset);
</code></pre>
<p>我们可以通过以下方式来每次获取偏移量.</p>
<p>消费端 偏移量,是通过这个参数设计的,  第一初始化组的时候不能使用&quot;none&quot; (因为Broker没有记录此消费者组的offset), 但是可以使用&quot;earliest&quot; .  如果其组内已经有人启动了, 那么此时就算你设置&quot;earliest&quot; , 也会根据组内人士偏移量决定的.</p>
<pre><code class="language-java">config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);
</code></pre>
<h3 id="分区-和-组的关系">分区 和 组的关系</h3>
<p>我们单机上再拷贝一个 kafka , 改成 partition为2 ,  只需要改以下三个参数 ,根据情况改,  (懒得开台虚拟机,外网测试根本连不上,不知道为啥哈哈哈.)</p>
<pre><code class="language-properties"># 第一台我的是0 , 第二台是1
broker.id=1 
listeners=PLAINTEXT://:9093
log.dirs=/home/admin/kafka_2/kafka_2.11-0.11.0.3/logs
num.partitions=2
</code></pre>
<p>代码:</p>
<pre><code class="language-java">final String url = &quot;hadoop1:9092,hadoop1:9093&quot;;
final String topic = &quot;topic-2&quot;;
// 同时我们打印partition的位置
// 服务端
RecordMetadata future = producer.send(new ProducerRecord&lt;&gt;(&quot;topic-2&quot;, &quot;cur-time&quot; + value, String.format(&quot;id: %d, time : %d.&quot;, value, System.currentTimeMillis())), (metadata, exception) -&gt; {
}).get();
logger.info(&quot;偏移量 : {} , 分区 : {}.&quot;, future.offset(), future.partition());

// 客户端
ConsumerRecords&lt;String, String&gt; poll = consumer.poll(500);
poll.forEach(record -&gt;
        System.out.println(String.format(&quot;topic: %s, key: %s, value: %s, offset:%d , partition:%d.&quot;,
                record.topic(), record.key(), record.value(), record.offset(), record.partition())));
consumer.commitAsync();
</code></pre>
<p>启动. 一台生产者  , 三个消费者在同一个组内.</p>
<p>我们发现 :</p>
<p>生产者 :</p>
<pre><code class="language-java">2020-02-29 20:40:25,590 390057 [  main] INFO   com.example.producer.Producer  - 偏移量 : 610 , 分区 : 1.
2020-02-29 20:40:26,112 390579 [  main] INFO   com.example.producer.Producer  - 偏移量 : 611 , 分区 : 1.
2020-02-29 20:40:26,629 391096 [  main] INFO   com.example.producer.Producer  - 偏移量 : 508 , 分区 : 0.
2020-02-29 20:40:27,153 391620 [  main] INFO   com.example.producer.Producer  - 偏移量 : 612 , 分区 : 1.
2020-02-29 20:40:27,657 392124 [  main] INFO   com.example.producer.Producer  - 偏移量 : 613 , 分区 : 1.
2020-02-29 20:40:28,164 392631 [  main] INFO   com.example.producer.Producer  - 偏移量 : 509 , 分区 : 0.
</code></pre>
<p>消费者1:</p>
<pre><code class="language-java">topic: topic-2, key: cur-time756, value: id: 756, time : 1582980020546., offset:502 , partition:0.
topic: topic-2, key: cur-time757, value: id: 757, time : 1582980021048., offset:503 , partition:0.
topic: topic-2, key: cur-time758, value: id: 758, time : 1582980021552., offset:504 , partition:0.
topic: topic-2, key: cur-time759, value: id: 759, time : 1582980022056., offset:505 , partition:0.
topic: topic-2, key: cur-time760, value: id: 760, time : 1582980022561., offset:506 , partition:0.
</code></pre>
<p>消费者2:</p>
<pre><code class="language-jaa">topic: topic-2, key: cur-time804, value: id: 804, time : 1582980044811., offset:633 , partition:1.
topic: topic-2, key: cur-time810, value: id: 810, time : 1582980047837., offset:634 , partition:1.
topic: topic-2, key: cur-time812, value: id: 812, time : 1582980048844., offset:635 , partition:1.
topic: topic-2, key: cur-time813, value: id: 813, time : 1582980049347., offset:636 , partition:1.
topic: topic-2, key: cur-time815, value: id: 815, time : 1582980050352., offset:637 , partition:1.
topic: topic-2, key: cur-time820, value: id: 820, time : 1582980052870., offset:638 , partition:1.
</code></pre>
<p>消费者3: 显然是死的, 卡着不动, 此时当我们断掉消费者2 , 此时会打印如下日志. 成功均衡.</p>
<pre><code class="language-java">020-02-29 20:41:49,409 454117 [  main] INFO  .internals.AbstractCoordinator  - (Re-)joining group consumer-1
2020-02-29 20:41:51,850 456558 [  main] INFO  .internals.AbstractCoordinator  - Successfully joined group consumer-1 with generation 41
2020-02-29 20:41:51,851 456559 [  main] INFO  .internals.ConsumerCoordinator  - Setting newly assigned partitions [topic-2-1] for group consumer-1
topic: topic-2, key: cur-time912, value: id: 912, time : 1582980099342., offset:690 , partition:1.    
</code></pre>
<h3 id="模拟down机保证可靠性">模拟down机,保证可靠性</h3>
<p>当我们把一台机器关闭 , 生产者消费者都会抛出一下异常.</p>
<pre><code class="language-java">2020-02-29 20:56:11,733 202726 [ucer-1] WARN  he.kafka.clients.NetworkClient  - Connection to node 1 could not be established. Broker may not be available.
2020-02-29 20:56:13,785 204778 [ucer-1] WARN  he.kafka.clients.NetworkClient  - Connection to node 1 could not be established. Broker may not be available.
// 抛出一次. 就是无法和topic-2-0 也就是第0个分区联系.会等待30S超时,这个属性我们可以自己设置.
Caused by: org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for topic-2-0: 30084 ms has passed since batch creation plus linger time
2020-02-29 20:56:40,313 231306 [  main] INFO   com.example.producer.Producer  - 偏移量 : 836 , 分区 : 1.
</code></pre>
<p>这个会不断的重试. 失败就放弃,继续重试, 其实这个partition策略我们可以自己写.</p>
<p>由于我们模拟的单线程操作, 也就是会阻塞. 所以很正常. 正常开发都是多线程. 但是这个超时是逃避不了的. 比如一个web 请求, 你这里超时30S, 这个绝对不行.</p>
<p>所以我们调整参数,   改成3S.</p>
<pre><code class="language-java"> config.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 3000);
</code></pre>
<p>此时报错就是 , 这个超时时间自己根据业务把握, 不一定越小越好.</p>
<pre><code class="language-java">Caused by: org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for topic-2-0: 3058 ms has passed since batch creation plus linger time
</code></pre>
<p>所以kafka的可靠性是极高的, 不会因为一个broker挂掉了,业务就无法进行了 . 此时连不上会将数据全部写到另外一个分区中, 当重新启动又会恢复平衡, 所以可靠性极高.</p>
<h3 id="分区策略">分区策略</h3>
<p>简单实现一个 <code>org.apache.kafka.clients.producer.Partitioner</code> 接口吧.</p>
<pre><code class="language-java">public class OrderPartitioner implements Partitioner {

    // topic计数器. 每个topic都维护一个计数器. 这里可以考虑把map设置为安全的, 因为会出现并发问题.
    private HashMap&lt;String, AtomicInteger&gt; map = new HashMap&lt;&gt;();

    private static final Function&lt;String, AtomicInteger&gt; provider = s -&gt; new AtomicInteger(0);

    // 这里业务逻辑其实不对,如果写入失败,那么永远也是
    @Override
    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
        List&lt;PartitionInfo&gt; list = cluster.availablePartitionsForTopic(topic);
        AtomicInteger integer = map.computeIfAbsent(topic, provider);
        return integer.incrementAndGet() % list.size();
    }

    @Override
    public void close() {
        // 清空释放内存
        map.clear();
    }

    @Override
    public void configure(Map&lt;String, ?&gt; configs) {
    }
}
</code></pre>
<p>简单的加入到 生成者的配置中去,</p>
<pre><code class="language-java">config.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, OrderPartitioner.class);
</code></pre>
<p>结果就是 :  发现很均匀.</p>
<pre><code class="language-java">2020-02-29 21:38:53,309 1358   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1224 , 分区 : 1.
2020-02-29 21:38:53,813 1862   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1006 , 分区 : 0.
2020-02-29 21:38:54,318 2367   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1225 , 分区 : 1.
2020-02-29 21:38:54,820 2869   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1007 , 分区 : 0.
2020-02-29 21:38:55,323 3372   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1226 , 分区 : 1.
</code></pre>
<h3 id="拦截器功能">拦截器功能</h3>
<pre><code class="language-java">// 拦截器, 必须传入一个集合,
config.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, Collections.singletonList(MyProducerInterceptor.class));
</code></pre>
<p>简单写一个吧,</p>
<pre><code class="language-java">public class MyProducerInterceptor implements ProducerInterceptor {
    // 调用send方法会回调到这里.
    @Override
    public ProducerRecord onSend(ProducerRecord record) {
        System.out.println(&quot;MyProducerInterceptor-onSend &quot;);
        return record;
    }

    // 当服务器返回数据会调用这里.
    @Override
    public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
        System.out.println(&quot;MyProducerInterceptor-onAcknowledgement&quot;);
    }

    @Override
    public void close() {
    }

    @Override
    public void configure(Map&lt;String, ?&gt; configs) {
    }
}
</code></pre>
<p>我们再看看打印日志 :</p>
<pre><code class="language-java">MyProducerInterceptor-onSend
OrderPartitioner
MyProducerInterceptor-onAcknowledgement
2020-02-29 21:52:29,262 3371   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1238 , 分区 : 1.
</code></pre>
<p>就是先拦截.  后给分区去处理, 如果你把send 方法返回一个null. 我的程序反正直接退出了, 哈哈哈哈.  因为<code>org.apache.kafka.clients.producer.KafkaProducer#send</code> 这里往下走, 有个sendon方法里需要处理这个结果. 所以基本上这个是用作包装或者统计, 或者实现回调 , 让主线程可以不使用get,使其阻塞. 就这个.</p>
<h3 id="总结一下">总结一下.</h3>
<p>一 . 一个分区只能被同一个组内某一个人消费.</p>
<p>其实就是 一个消费者组  和分区是一一对应的, 也就是上面那个问题.</p>
<p>两个分区, 但是一个消费组确有三个人/或者更多人消费. 此时只会有两个人,俩人各连一个分区.</p>
<p>二. 分区数, 比如我第一个topic-1, 一开始是一个分区, 就算我服务器改成了两个分区, 此时也无法俩分区发送.</p>
<p>三 . 一个分区默认就是有序的. 不用考虑顺序性.  对于顺序性比较强的业务可以考虑将其设置为一个分区, 获取通过接口编写你所需要的需求. 分区可以解决down机等问题, 所以并不推荐</p>
<p>四. 高可靠性, 可以保证一台服务器down机,其他仍然可以处理(主机从机一样,他会自行选举,我两台机器都没啥问题).</p>
<p>五. 分区策略, 灵活性. 相信我这些基本满足你开发, .</p>
<p>以上虽然有大量的日志, 是让大家方便理解. 谢谢.  其实对于大多数概念来说, 比如自己练习练习 , 概念毕竟是概念,</p>
<h2 id="如何修改分区副本数量">如何修改分区/副本数量</h2>
<p>分区 / 副本是两个不同的概念.   分区属于leader , 副本属于follower , 所以这里就是一个防止leader  Down机的问题, follower只会做一件事就是同步leader.   但是follower不对外提供读写服务的 , 这里是为了防止数据不一致问题, 因为从机跟随会有延时的.  但是有些场景我感觉是满足的, 因为kafka这种一个分区对应一个组的一个消费者很好地捆绑并不会发生不一致问题 , 最多也就是一个读慢了, 个人觉得.</p>
<p>在线修改配置. 这个简单 , 其实有些小伙伴经常查看zk的话, 发现他就是将信息保存在zk中 ,, 其实修改zk就可以了 ,</p>
<p>比如查看 topic-2的主题信息</p>
<pre><code class="language-java">[admin@hadoop1 bin]$ ./kafka-topics.sh --zookeeper localhost:2181 --describe  --topic topic-2
Topic:topic-2	PartitionCount:2	ReplicationFactor:1	Configs:
	Topic: topic-2	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
	Topic: topic-2	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
</code></pre>
<p>Leader: 分区0的leader是主机1 上,分区1的leader是主机0.</p>
<p>Replicas : 分区0的副本在主机1上, 分区1的副本在主机0上</p>
<p>ISR : 表示副本跟随的进度. 如果和副本主机号一致 ,说明跟随一致 .</p>
<p>副本1的主机是</p>
<p>如果我们想修改分区数量 :</p>
<pre><code class="language-java">./kafka-topics.sh --zookeeper localhost:2181 -alter --partitions 2 --topic topic-1
</code></pre>
<p>修改会有一个警告信息 , 就是分区可能影响你原来的业务逻辑.  不过提示成功了.</p>
<pre><code class="language-java">[admin@hadoop1 bin]$ ./kafka-topics.sh --zookeeper localhost:2181 -alter --partitions 2 --topic topic-1
WARNING: If partitions are increased for a topic that has a key, the partition logic or ordering of the messages will be affected
Adding partitions succeeded!
</code></pre>
<p>修改完赶紧测试一下.. 发现 , 其实不同分区的偏移量都是独立计算的. 不过也无所谓,</p>
<pre><code class="language-java">2020-02-29 22:32:59,876 1456   [  main] INFO   com.example.producer.Producer  - 偏移量 : 0 , 分区 : 1.
2020-02-29 22:33:00,408 1988   [  main] INFO   com.example.producer.Producer  - 偏移量 : 638 , 分区 : 0.
2020-02-29 22:33:00,915 2495   [  main] INFO   com.example.producer.Producer  - 偏移量 : 1 , 分区 : 1.
</code></pre>
<p>从机选举成主机的过程, 两台机器无法实现, 必须是 至少一个leader 和 两个follower才可以选举成功. 实在懒得测试请求理解.  哈哈哈哈. 其实这些都是运维做的. 可以感兴趣再测试一下. 很简单的.</p>
<h2 id="下一期-深入理解kafka">下一期 深入理解kafka</h2>
<p>这一节只是了解了如何使用, 这个根本不够我们需要学习kafka是如何做的 . 实现高读写, 高可靠性, 高拓展性 , 这是一个分布式设计必备的.</p>

								<span id="footnote"></span>
								<div id="warn"></div>
							</div>
							<div class="toc-container"><ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B">快速开始</a></li>
<li><a href="#topic">topic</a></li>
<li><a href="#%E7%BB%84%E5%88%86%E5%8C%BA-%E7%A9%B6%E7%AB%9F%E5%81%9A%E4%BB%80%E4%B9%88">组/分区 究竟做什么</a>
<ul>
<li><a href="#%E5%81%8F%E7%A7%BB%E9%87%8F">偏移量</a></li>
<li><a href="#%E5%88%86%E5%8C%BA-%E5%92%8C-%E7%BB%84%E7%9A%84%E5%85%B3%E7%B3%BB">分区 和 组的关系</a></li>
<li><a href="#%E6%A8%A1%E6%8B%9Fdown%E6%9C%BA%E4%BF%9D%E8%AF%81%E5%8F%AF%E9%9D%A0%E6%80%A7">模拟down机,保证可靠性</a></li>
<li><a href="#%E5%88%86%E5%8C%BA%E7%AD%96%E7%95%A5">分区策略</a></li>
<li><a href="#%E6%8B%A6%E6%88%AA%E5%99%A8%E5%8A%9F%E8%83%BD">拦截器功能</a></li>
<li><a href="#%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B">总结一下.</a></li>
</ul>
</li>
<li><a href="#%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC%E6%95%B0%E9%87%8F">如何修改分区/副本数量</a></li>
<li><a href="#%E4%B8%8B%E4%B8%80%E6%9C%9F-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3kafka">下一期 深入理解kafka</a></li>
</ul>
</li>
</ul>
</div>
						</div>
						<div id="fullPage"><canvas id="canvas"></canvas></div>
				</article>
				<div id="eof"><span>EOF</span></div>
				<div class="round-shape-one"></div>
				<section>
					<div class="doc_comments">
							<div id="valine-container"></div>
					</div>
				</section>
			</div>
		</div>
	</div>
	<script>
		"use strict";
		! function () {
			for (var n = document.getElementsByTagName("pre"), e = n.length, s = 0; s < e; s++) {
				n[s].innerHTML = '<span class="line-number"></span>' + n[s].innerHTML + '<span class="cl"></span>';
				for (var a = n[s].innerHTML.split(/\n/).length, r = 0; r < a - 1; r++) {
					n[s].getElementsByTagName("span")[0].innerHTML += "<span>" + (r + 1) + "</span>"
				}
			}
		}();
		let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");
		window.addEventListener("scroll", event => {
			let fromTop = window.scrollY;
			mainNavLinks.forEach((link, index) => {
				let section = document.getElementById(decodeURI(link.hash).substring(1));
				let nextSection = null
				if (mainNavLinks[index + 1]) {
					nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(
						1));
				}
				if (section.offsetTop <= fromTop) {
					if (nextSection) {
						if (nextSection.offsetTop > fromTop) {
							link.classList.add("currentToc");
						} else {
							link.classList.remove("currentToc");
						}
					} else {
						link.classList.add("currentToc");
					}
				} else {
					link.classList.remove("currentToc");
				}
			});
		});
		var list = document.querySelectorAll(".katex");
		for (var i = 0; i < list.length; i++) {
			list[i].style.display = "unset"
		};
		var h = document.documentElement,
			b = document.body,
			st = "scrollTop",
			sh = "scrollHeight",
			progress = document.querySelector(".progress"),
			scroll;
		document.addEventListener("scroll", function () {
			scroll = (h[st] || b[st]) / ((h[sh] || b[sh]) - h.clientHeight) * 100;
			progress.style.setProperty("--scroll", scroll + "%")
		});
		var wxScale = new WxScale({
			fullPage: document.querySelector("#fullPage"),
			canvas: document.querySelector("#canvas")
		});
		var imgBox = document.querySelectorAll("#md_block img");
		for (var i = 0; i < imgBox.length; i++) {
			imgBox[i].onclick = function (e) {
				wxScale.start(this)
			}
		};
	</script>
	<style>
		#magnifyImg {
			position: fixed;
			left: 0;
			top: 0;
			text-align: center;
			width: 100%;
			display: none;
			z-index: 9999
		}

		#magnifyImg img {
			object-fit: contain;
			background: #eaecef;
			padding: 15px;
			border-radius: 10px;
			height: auto;
			width: auto;
			vertical-align: middle
		}
	</style>
	<a id="scrollUp"href="#top"style="position: fixed; z-index: 2147483647; display: block;"></a><div class="footer animated fadeInDown"><div class="site_footer"><div class="mysocials"><div class="my_socials"><a href="https://github.com/Anthony-Dong"title="github"><i class="iconfont icon-github"></i></a><a href="fanhaodong516@gmail.com"title="envelope"><i class="iconfont icon-envelope"></i></a></div></div><div class="copyright"id="copyright">You Are My Everything. <a href="mailto:574986060@qq.com" target="blank">Send Email</a>Copyright©2018-2020<a href="https://anthony-dong.github.io"style="margin:0;">Serence</a>.</div><span style="display: inline;margin-right:15px;">👁<strong><span id="count-page">168271</span></strong></span><span id="busuanzi_container_page_pv"style="display: inline;"><span>📚<strong>186</strong>posts</span></div></div><script>console.log("\n %c \u26a1Anthony-Dong's Blog:https://anthony-dong.gitee.io ,Github:https://github.com/Anthony-Dong ,Email:574986060@qq.com ,有事情欢迎联系. \n\n","color: #ffffff; background: rgba(49, 49, 49, 0.85); padding:5px 0;border-radius:5px;",);</script>
	<script type="text/javascript" async src="https://anthony-dong.github.io/media/js/prism.js"></script>
</body>
</html>